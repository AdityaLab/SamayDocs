{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Samay: Time-series Foundational Models Library","text":"A Unified Interface for Multiple Time-Series Foundational Models"},{"location":"#welcome-to-samay","title":"Welcome to Samay","text":"<p>Samay is a comprehensive Python library that provides a unified, easy-to-use interface for training and evaluating state-of-the-art time-series foundational models. Whether you're working on forecasting, classification, anomaly detection, or imputation tasks, Samay simplifies the process of leveraging powerful pre-trained models.</p>"},{"location":"#key-features","title":"\u2728 Key Features","text":"<ul> <li>Unified Interface: Work with multiple foundational models through a consistent API</li> <li>Pre-trained Models: Access state-of-the-art pre-trained models ready for zero-shot forecasting</li> <li>Fine-tuning Support: Easily fine-tune models on your custom datasets</li> <li>Multiple Tasks: Support for forecasting, classification, anomaly detection, and imputation</li> <li>Flexible Data Handling: Built-in dataset classes for common time-series formats</li> <li>Easy Integration: Simple pip installation and minimal code to get started</li> </ul>"},{"location":"#supported-models","title":"\ud83d\ude80 Supported Models","text":"<p>Samay currently supports the following foundational models:</p> Model Paper Strengths LPTM Large Pre-trained Time Series Models General-purpose forecasting with segmentation MOMENT MOMENT: A Family of Open Time-series Foundation Models Multi-task learning (forecasting, classification, anomaly detection) TimesFM A decoder-only foundation model for time-series forecasting Decoder-only architecture by Google Research Chronos Chronos: Learning the Language of Time Series Language model-based approach MOIRAI Unified Training of Universal Time Series Forecasting Transformers Universal transformer by Salesforce TinyTimeMixer TinyTimeMixer: Fast Pre-trained Models for Time Series Lightweight and efficient"},{"location":"#quick-installation","title":"\ud83d\udce6 Quick Installation","text":"<p>Install Samay directly from GitHub:</p> <pre><code>pip install git+https://github.com/AdityaLab/Samay.git\n</code></pre>"},{"location":"#quick-start","title":"\ud83d\udd25 Quick Start","text":"<p>Here's a simple example using LPTM for time-series forecasting:</p> <pre><code>from samay.model import LPTMModel\nfrom samay.dataset import LPTMDataset\n\n# Configure the model\nconfig = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\n# Load the pre-trained model\nmodel = LPTMModel(config)\n\n# Load your dataset\ntrain_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n)\n\n# Fine-tune the model\nfinetuned_model = model.finetune(train_dataset)\n\n# Evaluate on test data\ntest_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    horizon=192,\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\nprint(f\"Average Loss: {avg_loss}\")\n</code></pre>"},{"location":"#whats-next","title":"\ud83d\udcda What's Next?","text":"<ul> <li>Getting Started: Detailed installation and first steps</li> <li>Model Guides: In-depth guides for each supported model</li> <li>API Reference: Complete API documentation</li> <li>Examples: Real-world examples and use cases</li> </ul>"},{"location":"#use-cases","title":"\ud83c\udfaf Use Cases","text":"<p>Samay is perfect for:</p> <ul> <li>Time-Series Forecasting: Predict future values from historical data</li> <li>Anomaly Detection: Identify unusual patterns in time-series data</li> <li>Classification: Classify time-series sequences into categories</li> <li>Data Imputation: Fill missing values in time-series data</li> <li>Transfer Learning: Leverage pre-trained models for your domain-specific tasks</li> </ul>"},{"location":"#why-samay","title":"\ud83d\udca1 Why Samay?","text":"<p>Traditional time-series modeling requires extensive expertise and computational resources. Samay democratizes access to state-of-the-art foundational models by:</p> <ol> <li>Providing a unified interface across multiple model architectures</li> <li>Offering pre-trained models that work out-of-the-box</li> <li>Enabling easy fine-tuning with minimal code</li> <li>Supporting multiple tasks with the same infrastructure</li> </ol>"},{"location":"#community-and-support","title":"\ud83e\udd1d Community and Support","text":"<ul> <li>GitHub: AdityaLab/Samay</li> <li>Issues: Report bugs or request features on GitHub Issues</li> <li>Email: hkamarthi3@gatech.edu, badityap@cc.gatech.edu</li> </ul>"},{"location":"#citation","title":"\ud83d\udcdd Citation","text":"<p>If you use Samay in your research, please cite:</p> <pre><code>@inproceedings{\nkamarthi2024large,\ntitle={Large Pre-trained time series models for cross-domain Time series analysis tasks},\nauthor={Harshavardhan Kamarthi and B. Aditya Prakash},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=vMMzjCr5Zj}\n}\n</code></pre>"},{"location":"#system-requirements","title":"\ud83d\udccb System Requirements","text":"<ul> <li>Python: 3.11-3.13</li> <li>OS: Linux (CPU + GPU), macOS (CPU)</li> <li>GPU: NVIDIA GPUs supported</li> </ul> <p>Platform Support</p> <p>Windows and Apple Silicon GPU support is planned for future releases.</p>"},{"location":"examples/","title":"Examples","text":"<p>This page provides complete, working examples for using Samay with different models and tasks.</p>"},{"location":"examples/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Basic Forecasting with LPTM</li> <li>Zero-Shot Forecasting with TimesFM</li> <li>Multi-Task Learning with MOMENT</li> <li>Probabilistic Forecasting with Chronos</li> <li>Universal Forecasting with MOIRAI</li> <li>Fast Forecasting with TinyTimeMixer</li> <li>Anomaly Detection</li> <li>Time Series Classification</li> <li>Multi-Horizon Forecasting</li> <li>Cross-Domain Transfer Learning</li> </ol>"},{"location":"examples/#basic-forecasting-with-lptm","title":"Basic Forecasting with LPTM","text":"<p>A complete example of loading data, fine-tuning, and evaluating LPTM.</p> <pre><code>from samay.model import LPTMModel\nfrom samay.dataset import LPTMDataset\nfrom samay.metric import mse, mae, mape\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Step 1: Configure the model\nconfig = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n    \"head_dropout\": 0.1,\n}\n\n# Step 2: Load the model\nprint(\"Loading LPTM model...\")\nmodel = LPTMModel(config)\n\n# Step 3: Load training data\nprint(\"Loading training data...\")\ntrain_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n    batchsize=16,\n)\n\n# Step 4: Fine-tune the model\nprint(\"Fine-tuning model...\")\nfinetuned_model = model.finetune(\n    train_dataset,\n    epochs=10,\n    learning_rate=1e-4,\n)\n\n# Step 5: Load test data\nprint(\"Loading test data...\")\ntest_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    horizon=192,\n)\n\n# Step 6: Evaluate\nprint(\"Evaluating model...\")\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\n# Step 7: Calculate metrics\ntrues = np.array(trues)\npreds = np.array(preds)\nhistories = np.array(histories)\n\nprint(\"\\n=== Evaluation Results ===\")\nprint(f\"Average Loss: {avg_loss:.4f}\")\nprint(f\"MSE: {mse(trues, preds):.4f}\")\nprint(f\"MAE: {mae(trues, preds):.4f}\")\nprint(f\"MAPE: {mape(trues, preds):.4f}%\")\n\n# Step 8: Visualize results\nchannel_idx = 0\ntime_index = 0\n\nhistory = histories[time_index, channel_idx, :]\ntrue = trues[time_index, channel_idx, :]\npred = preds[time_index, channel_idx, :]\n\nplt.figure(figsize=(14, 5))\nplt.plot(range(len(history)), history, label=\"History (512 steps)\", linewidth=2)\nplt.plot(\n    range(len(history), len(history) + len(true)),\n    true,\n    label=\"Ground Truth (192 steps)\",\n    linestyle=\"--\",\n    linewidth=2,\n    color=\"green\"\n)\nplt.plot(\n    range(len(history), len(history) + len(pred)),\n    pred,\n    label=\"Prediction (192 steps)\",\n    linewidth=2,\n    color=\"red\"\n)\nplt.axvline(x=len(history), color='gray', linestyle=':', alpha=0.5)\nplt.legend()\nplt.title(\"LPTM Time Series Forecasting\")\nplt.xlabel(\"Time Step\")\nplt.ylabel(\"Value\")\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.savefig(\"lptm_forecast.png\", dpi=300)\nplt.show()\n\nprint(\"\\nForecast plot saved as 'lptm_forecast.png'\")\n</code></pre>"},{"location":"examples/#zero-shot-forecasting-with-timesfm","title":"Zero-Shot Forecasting with TimesFM","text":"<p>Example of using TimesFM without any training.</p> <pre><code>from samay.model import TimesfmModel\nfrom samay.dataset import TimesfmDataset\nfrom samay.metric import mse, mae\nimport numpy as np\n\n# Configure TimesFM\nrepo = \"google/timesfm-1.0-200m-pytorch\"\nconfig = {\n    \"context_len\": 512,\n    \"horizon_len\": 192,\n    \"backend\": \"gpu\",\n    \"per_core_batch_size\": 32,\n    \"input_patch_len\": 32,\n    \"output_patch_len\": 128,\n    \"num_layers\": 20,\n    \"model_dims\": 1280,\n    \"quantiles\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n}\n\nprint(\"Loading TimesFM model...\")\ntfm = TimesfmModel(config=config, repo=repo)\n\n# Load test data (no training needed!)\nprint(\"Loading test data...\")\ntest_dataset = TimesfmDataset(\n    name=\"ett\",\n    datetime_col='date',\n    path='data/ETTh1.csv',\n    mode='test',\n    context_len=config[\"context_len\"],\n    horizon_len=config[\"horizon_len\"],\n    freq=\"h\",\n)\n\n# Zero-shot evaluation\nprint(\"Running zero-shot evaluation...\")\navg_loss, trues, preds, histories = tfm.evaluate(test_dataset)\n\n# Calculate metrics\ntrues = np.array(trues)\npreds = np.array(preds)\n\nprint(\"\\n=== Zero-Shot Results ===\")\nprint(f\"Average Loss: {avg_loss:.4f}\")\nprint(f\"MSE: {mse(trues, preds):.4f}\")\nprint(f\"MAE: {mae(trues, preds):.4f}\")\n</code></pre>"},{"location":"examples/#multi-task-learning-with-moment","title":"Multi-Task Learning with MOMENT","text":"<p>Example showing forecasting and anomaly detection with the same model.</p> <pre><code>from samay.model import MomentModel\nfrom samay.dataset import MomentDataset\nimport numpy as np\n\n# ===== Task 1: Forecasting =====\nprint(\"=== Task 1: Forecasting ===\\n\")\n\nconfig_forecast = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\nmodel = MomentModel(config_forecast)\n\ntrain_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon_len=192,\n    task_name=\"forecasting\",\n)\n\nprint(\"Fine-tuning for forecasting...\")\nmodel.finetune(train_dataset, epochs=10)\n\ntest_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    horizon_len=192,\n    task_name=\"forecasting\",\n)\n\navg_loss, trues, preds, _ = model.evaluate(test_dataset)\nprint(f\"Forecasting Loss: {avg_loss:.4f}\\n\")\n\n# ===== Task 2: Anomaly Detection =====\nprint(\"=== Task 2: Anomaly Detection ===\\n\")\n\nconfig_detection = {\n    \"task_name\": \"detection\",\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\n# Update model for new task\nmodel.update_config(config_detection)\n\nanomaly_train = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ecg_anomaly.csv\",\n    mode=\"train\",\n    task_name=\"detection\",\n)\n\nprint(\"Fine-tuning for anomaly detection...\")\nmodel.finetune(anomaly_train, epochs=10)\n\nanomaly_test = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ecg_anomaly.csv\",\n    mode=\"test\",\n    task_name=\"detection\",\n)\n\navg_loss, labels, scores, _ = model.evaluate(anomaly_test)\n\n# Calculate ROC-AUC\nfrom sklearn.metrics import roc_auc_score\nauc = roc_auc_score(labels, scores)\nprint(f\"Anomaly Detection AUC: {auc:.4f}\")\n</code></pre>"},{"location":"examples/#probabilistic-forecasting-with-chronos","title":"Probabilistic Forecasting with Chronos","text":"<p>Example of generating prediction intervals with Chronos.</p> <pre><code>from samay.model import ChronosModel\nfrom samay.dataset import ChronosDataset\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Configure for probabilistic forecasting\nconfig = {\n    \"model_size\": \"small\",\n    \"context_length\": 512,\n    \"prediction_length\": 96,\n    \"num_samples\": 100,  # Generate 100 samples\n    \"temperature\": 1.0,\n}\n\nprint(\"Loading Chronos model...\")\nmodel = ChronosModel(config)\n\n# Load test data\ntest_dataset = ChronosDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    config=config,\n)\n\n# Generate probabilistic forecasts\nprint(\"Generating probabilistic forecasts...\")\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\n# Calculate statistics across samples\nmean_pred = np.mean(preds, axis=-1)\nstd_pred = np.std(preds, axis=-1)\nlower_10 = np.percentile(preds, 10, axis=-1)\nlower_25 = np.percentile(preds, 25, axis=-1)\nupper_75 = np.percentile(preds, 75, axis=-1)\nupper_90 = np.percentile(preds, 90, axis=-1)\n\n# Visualize with prediction intervals\nsample_idx = 0\nchannel_idx = 0\n\nhistory = histories[sample_idx, channel_idx, :]\ntrue = trues[sample_idx, channel_idx, :]\npred_mean = mean_pred[sample_idx, channel_idx, :]\npred_lower_10 = lower_10[sample_idx, channel_idx, :]\npred_lower_25 = lower_25[sample_idx, channel_idx, :]\npred_upper_75 = upper_75[sample_idx, channel_idx, :]\npred_upper_90 = upper_90[sample_idx, channel_idx, :]\n\nplt.figure(figsize=(14, 6))\n\n# Plot history\nplt.plot(range(len(history)), history, label=\"History\", linewidth=2, color='blue')\n\n# Plot ground truth\nforecast_range = range(len(history), len(history) + len(true))\nplt.plot(forecast_range, true, label=\"Ground Truth\", linestyle=\"--\", linewidth=2, color='green')\n\n# Plot mean prediction\nplt.plot(forecast_range, pred_mean, label=\"Mean Prediction\", linewidth=2, color='red')\n\n# Plot prediction intervals\nplt.fill_between(\n    forecast_range,\n    pred_lower_10,\n    pred_upper_90,\n    alpha=0.2,\n    color='red',\n    label=\"80% Prediction Interval\"\n)\nplt.fill_between(\n    forecast_range,\n    pred_lower_25,\n    pred_upper_75,\n    alpha=0.3,\n    color='red',\n    label=\"50% Prediction Interval\"\n)\n\nplt.axvline(x=len(history), color='gray', linestyle=':', alpha=0.5)\nplt.legend()\nplt.title(\"Chronos Probabilistic Forecasting with Prediction Intervals\")\nplt.xlabel(\"Time Step\")\nplt.ylabel(\"Value\")\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.savefig(\"chronos_probabilistic.png\", dpi=300)\nplt.show()\n\nprint(\"\\nPrediction interval plot saved as 'chronos_probabilistic.png'\")\n</code></pre>"},{"location":"examples/#universal-forecasting-with-moirai","title":"Universal Forecasting with MOIRAI","text":"<p>Example of using MOIRAI across different frequencies.</p> <pre><code>from samay.model import MoiraiTSModel\nfrom samay.dataset import MoiraiDataset\nimport numpy as np\n\n# Configure MOIRAI\nrepo = \"Salesforce/moirai-1.0-R-small\"\nconfig = {\n    \"context_len\": 128,\n    \"horizon_len\": 64,\n    \"model_type\": \"moirai\",\n    \"model_size\": \"small\",\n}\n\nprint(\"Loading MOIRAI model...\")\nmoirai_model = MoiraiTSModel(repo=repo, config=config)\n\n# Test on different frequencies\nfrequencies = [\n    (\"Hourly\", \"h\", \"data/hourly.csv\"),\n    (\"Daily\", \"d\", \"data/daily.csv\"),\n    (\"Weekly\", \"w\", \"data/weekly.csv\"),\n]\n\nresults = {}\n\nfor freq_name, freq_code, data_path in frequencies:\n    print(f\"\\n=== Testing on {freq_name} Data ===\")\n\n    test_dataset = MoiraiDataset(\n        mode=\"test\",\n        path=data_path,\n        datetime_col=\"date\",\n        freq=freq_code,\n        context_len=128,\n        horizon_len=64,\n    )\n\n    eval_results, trues, preds, histories = moirai_model.evaluate(\n        test_dataset,\n        metrics=[\"MSE\", \"MAE\", \"MASE\"]\n    )\n\n    results[freq_name] = eval_results\n\n    print(f\"Results for {freq_name}:\")\n    for metric, value in eval_results.items():\n        print(f\"  {metric}: {value:.4f}\")\n\n# Summary\nprint(\"\\n=== Summary Across Frequencies ===\")\nfor freq_name, metrics in results.items():\n    print(f\"{freq_name}: MAE = {metrics['MAE']:.4f}\")\n</code></pre>"},{"location":"examples/#fast-forecasting-with-tinytimemixer","title":"Fast Forecasting with TinyTimeMixer","text":"<p>Example emphasizing speed and efficiency.</p> <pre><code>from samay.model import TinyTimeMixerModel\nfrom samay.dataset import TinyTimeMixerDataset\nimport time\nimport numpy as np\n\n# Configure for speed\nconfig = {\n    \"context_len\": 512,\n    \"horizon_len\": 96,\n    \"model_size\": \"tiny\",\n}\n\nprint(\"Loading TinyTimeMixer model...\")\nmodel = TinyTimeMixerModel(config)\n\n# Load data with large batch size\ntrain_dataset = TinyTimeMixerDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    context_len=512,\n    horizon_len=96,\n    batch_size=256,  # Large batch for speed\n)\n\n# Fast training\nprint(\"Training (10 epochs)...\")\nstart_time = time.time()\nmodel.finetune(train_dataset, epochs=10)\ntrain_time = time.time() - start_time\nprint(f\"Training time: {train_time:.2f}s\")\n\n# Fast inference\ntest_dataset = TinyTimeMixerDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    context_len=512,\n    horizon_len=96,\n    batch_size=256,\n)\n\nprint(\"Running inference...\")\nstart_time = time.time()\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\ninference_time = time.time() - start_time\n\nprint(f\"\\n=== Performance Summary ===\")\nprint(f\"Training time: {train_time:.2f}s\")\nprint(f\"Inference time: {inference_time:.2f}s\")\nprint(f\"Test Loss: {avg_loss:.4f}\")\n</code></pre>"},{"location":"examples/#anomaly-detection","title":"Anomaly Detection","text":"<p>Complete anomaly detection example with visualization.</p> <pre><code>from samay.model import MomentModel\nfrom samay.dataset import MomentDataset\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Configure for anomaly detection\nconfig = {\n    \"task_name\": \"detection\",\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\nprint(\"Loading MOMENT for anomaly detection...\")\nmodel = MomentModel(config)\n\n# Load training data\ntrain_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ecg_anomaly.csv\",\n    mode=\"train\",\n    task_name=\"detection\",\n)\n\nprint(\"Training anomaly detector...\")\nmodel.finetune(train_dataset, epochs=15)\n\n# Load test data\ntest_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ecg_anomaly.csv\",\n    mode=\"test\",\n    task_name=\"detection\",\n)\n\n# Detect anomalies\nprint(\"Detecting anomalies...\")\navg_loss, true_labels, anomaly_scores, sequences = model.evaluate(test_dataset)\n\n# Calculate metrics\nauc = roc_auc_score(true_labels, anomaly_scores)\nprecision, recall, thresholds = precision_recall_curve(true_labels, anomaly_scores)\n\nprint(f\"\\n=== Anomaly Detection Results ===\")\nprint(f\"ROC-AUC: {auc:.4f}\")\n\n# Find optimal threshold\nf1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\noptimal_idx = np.argmax(f1_scores)\noptimal_threshold = thresholds[optimal_idx]\nprint(f\"Optimal Threshold: {optimal_threshold:.4f}\")\nprint(f\"Best F1 Score: {f1_scores[optimal_idx]:.4f}\")\n\n# Visualize results\nfig, axes = plt.subplots(3, 1, figsize=(14, 10))\n\n# Plot time series with anomalies\naxes[0].plot(sequences[0], label=\"Time Series\", linewidth=1)\nanomaly_indices = np.where(true_labels[0] == 1)[0]\naxes[0].scatter(\n    anomaly_indices,\n    sequences[0][anomaly_indices],\n    color='red',\n    s=100,\n    label='True Anomalies',\n    zorder=5\n)\naxes[0].set_title(\"Time Series with True Anomalies\")\naxes[0].set_xlabel(\"Time Step\")\naxes[0].set_ylabel(\"Value\")\naxes[0].legend()\naxes[0].grid(alpha=0.3)\n\n# Plot anomaly scores\naxes[1].plot(anomaly_scores[0], label=\"Anomaly Score\", color='orange')\naxes[1].axhline(\n    y=optimal_threshold,\n    color='r',\n    linestyle='--',\n    label=f'Threshold ({optimal_threshold:.2f})'\n)\naxes[1].set_title(\"Anomaly Scores\")\naxes[1].set_xlabel(\"Time Step\")\naxes[1].set_ylabel(\"Anomaly Score\")\naxes[1].legend()\naxes[1].grid(alpha=0.3)\n\n# Plot precision-recall curve\naxes[2].plot(recall, precision, linewidth=2)\naxes[2].scatter(\n    recall[optimal_idx],\n    precision[optimal_idx],\n    color='red',\n    s=100,\n    zorder=5,\n    label=f'Optimal Point (F1={f1_scores[optimal_idx]:.3f})'\n)\naxes[2].set_title(\"Precision-Recall Curve\")\naxes[2].set_xlabel(\"Recall\")\naxes[2].set_ylabel(\"Precision\")\naxes[2].legend()\naxes[2].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(\"anomaly_detection.png\", dpi=300)\nplt.show()\n\nprint(\"\\nAnomal detection plot saved as 'anomaly_detection.png'\")\n</code></pre>"},{"location":"examples/#time-series-classification","title":"Time Series Classification","text":"<p>Example of classifying time series sequences.</p> <pre><code>from samay.model import MomentModel\nfrom samay.dataset import MomentDataset\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Configure for classification\nconfig = {\n    \"task_name\": \"classification\",\n    \"num_classes\": 5,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\nprint(\"Loading MOMENT for classification...\")\nmodel = MomentModel(config)\n\n# Load training data\ntrain_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ecg_classification.csv\",\n    mode=\"train\",\n    task_name=\"classification\",\n    label_col=\"label\",\n)\n\nprint(\"Training classifier...\")\nmodel.finetune(train_dataset, epochs=20)\n\n# Load test data\ntest_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ecg_classification.csv\",\n    mode=\"test\",\n    task_name=\"classification\",\n    label_col=\"label\",\n)\n\n# Classify\nprint(\"Classifying test data...\")\navg_loss, true_labels, predictions, _ = model.evaluate(test_dataset)\n\n# Calculate metrics\naccuracy = accuracy_score(true_labels, predictions)\nprint(f\"\\n=== Classification Results ===\")\nprint(f\"Accuracy: {accuracy:.4f}\\n\")\n\nprint(\"Classification Report:\")\nprint(classification_report(true_labels, predictions))\n\n# Confusion matrix\ncm = confusion_matrix(true_labels, predictions)\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt='d',\n    cmap='Blues',\n    xticklabels=[f'Class {i}' for i in range(config[\"num_classes\"])],\n    yticklabels=[f'Class {i}' for i in range(config[\"num_classes\"])]\n)\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.tight_layout()\nplt.savefig(\"classification_confusion_matrix.png\", dpi=300)\nplt.show()\n\nprint(\"\\nConfusion matrix saved as 'classification_confusion_matrix.png'\")\n</code></pre>"},{"location":"examples/#multi-horizon-forecasting","title":"Multi-Horizon Forecasting","text":"<p>Example of forecasting at different horizons.</p> <pre><code>from samay.model import LPTMModel\nfrom samay.dataset import LPTMDataset\nfrom samay.metric import mae\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Test different forecast horizons\nhorizons = [96, 192, 336, 720]\nresults = {}\n\nfor horizon in horizons:\n    print(f\"\\n=== Testing Horizon: {horizon} ===\")\n\n    # Configure model\n    config = {\n        \"task_name\": \"forecasting\",\n        \"forecast_horizon\": horizon,\n        \"freeze_encoder\": True,\n        \"freeze_embedder\": True,\n        \"freeze_head\": False,\n    }\n\n    model = LPTMModel(config)\n\n    # Load data\n    train_dataset = LPTMDataset(\n        datetime_col=\"date\",\n        path=\"./data/ETTh1.csv\",\n        mode=\"train\",\n        horizon=horizon,\n    )\n\n    test_dataset = LPTMDataset(\n        datetime_col=\"date\",\n        path=\"./data/ETTh1.csv\",\n        mode=\"test\",\n        horizon=horizon,\n    )\n\n    # Train and evaluate\n    model.finetune(train_dataset, epochs=10)\n    avg_loss, trues, preds, _ = model.evaluate(test_dataset)\n\n    # Calculate MAE\n    mae_score = mae(np.array(trues), np.array(preds))\n    results[horizon] = mae_score\n\n    print(f\"MAE for horizon {horizon}: {mae_score:.4f}\")\n\n# Visualize results\nplt.figure(figsize=(10, 6))\nplt.plot(list(results.keys()), list(results.values()), marker='o', linewidth=2, markersize=8)\nplt.xlabel(\"Forecast Horizon\")\nplt.ylabel(\"MAE\")\nplt.title(\"Forecasting Performance vs. Horizon Length\")\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.savefig(\"multi_horizon_results.png\", dpi=300)\nplt.show()\n\nprint(\"\\nMulti-horizon results saved as 'multi_horizon_results.png'\")\n</code></pre>"},{"location":"examples/#cross-domain-transfer-learning","title":"Cross-Domain Transfer Learning","text":"<p>Example of transferring knowledge across domains.</p> <pre><code>from samay.model import LPTMModel\nfrom samay.dataset import LPTMDataset\nfrom samay.metric import mae\nimport numpy as np\n\n# Step 1: Train on source domain\nprint(\"=== Step 1: Training on Source Domain ===\")\n\nconfig = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": False,  # Train all layers\n    \"freeze_embedder\": False,\n    \"freeze_head\": False,\n}\n\nmodel = LPTMModel(config)\n\nsource_train = LPTMDataset(\n    datetime_col=\"date\",\n    path=\"./data/source_domain.csv\",\n    mode=\"train\",\n    horizon=192,\n)\n\nprint(\"Training on source domain...\")\nmodel.finetune(source_train, epochs=20)\n\n# Evaluate on source domain\nsource_test = LPTMDataset(\n    datetime_col=\"date\",\n    path=\"./data/source_domain.csv\",\n    mode=\"test\",\n    horizon=192,\n)\n\n_, trues, preds, _ = model.evaluate(source_test)\nsource_mae = mae(np.array(trues), np.array(preds))\nprint(f\"Source domain MAE: {source_mae:.4f}\")\n\n# Step 2: Transfer to target domain\nprint(\"\\n=== Step 2: Transferring to Target Domain ===\")\n\n# Freeze encoder and embedder, only train head\nconfig[\"freeze_encoder\"] = True\nconfig[\"freeze_embedder\"] = True\nconfig[\"freeze_head\"] = False\n\nmodel.update_config(config)\n\ntarget_train = LPTMDataset(\n    datetime_col=\"date\",\n    path=\"./data/target_domain.csv\",\n    mode=\"train\",\n    horizon=192,\n)\n\nprint(\"Fine-tuning on target domain...\")\nmodel.finetune(target_train, epochs=5)\n\n# Evaluate on target domain\ntarget_test = LPTMDataset(\n    datetime_col=\"date\",\n    path=\"./data/target_domain.csv\",\n    mode=\"test\",\n    horizon=192,\n)\n\n_, trues, preds, _ = model.evaluate(target_test)\ntarget_mae = mae(np.array(trues), np.array(preds))\nprint(f\"Target domain MAE: {target_mae:.4f}\")\n\n# Step 3: Compare with training from scratch\nprint(\"\\n=== Step 3: Training from Scratch on Target ===\")\n\nconfig_scratch = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": False,\n    \"freeze_embedder\": False,\n    \"freeze_head\": False,\n}\n\nmodel_scratch = LPTMModel(config_scratch)\n\nprint(\"Training from scratch on target domain...\")\nmodel_scratch.finetune(target_train, epochs=5)\n\n_, trues_scratch, preds_scratch, _ = model_scratch.evaluate(target_test)\nscratch_mae = mae(np.array(trues_scratch), np.array(preds_scratch))\nprint(f\"From-scratch MAE: {scratch_mae:.4f}\")\n\n# Summary\nprint(\"\\n=== Transfer Learning Summary ===\")\nprint(f\"Source domain MAE: {source_mae:.4f}\")\nprint(f\"Target with transfer: {target_mae:.4f}\")\nprint(f\"Target from scratch: {scratch_mae:.4f}\")\nimprovement = ((scratch_mae - target_mae) / scratch_mae) * 100\nprint(f\"Improvement from transfer learning: {improvement:.2f}%\")\n</code></pre>"},{"location":"examples/#additional-resources","title":"Additional Resources","text":"<p>For more examples, check out:</p> <ul> <li>Jupyter Notebooks in the repository</li> <li>Model Guides for model-specific examples</li> <li>API Reference for detailed method documentation</li> </ul>"},{"location":"examples/#tips-for-examples","title":"Tips for Examples","text":"<ol> <li>Start Simple: Begin with basic forecasting before trying advanced tasks</li> <li>Visualize Results: Always plot your predictions to verify they make sense</li> <li>Monitor Training: Watch for overfitting by tracking validation loss</li> <li>Experiment: Try different model configurations and hyperparameters</li> <li>Save Models: Save checkpoints of well-performing models for reuse</li> </ol>"},{"location":"examples/#need-help","title":"Need Help?","text":"<p>If you encounter issues with these examples:</p> <ul> <li>Check the Getting Started guide for setup</li> <li>Review Model Guides for model-specific details</li> <li>Open an issue on GitHub</li> <li>Contact us at hkamarthi3@gatech.edu or badityap@cc.gatech.edu</li> </ul>"},{"location":"getting-started/","title":"Getting Started with Samay","text":"<p>This guide will help you install Samay and run your first time-series forecasting model.</p>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#standard-installation","title":"Standard Installation","text":"<p>Install Samay directly from GitHub using pip:</p> <pre><code>pip install git+https://github.com/AdityaLab/Samay.git\n</code></pre> <p>This will install Samay and all its dependencies.</p>"},{"location":"getting-started/#development-installation","title":"Development Installation","text":"<p>If you want to contribute to Samay or modify the code, follow these steps:</p> <pre><code># Clone the repository\ngit clone https://github.com/AdityaLab/Samay.git\ncd Samay\n\n# Install uv package manager\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Install dependencies\nuv sync --reinstall\n</code></pre>"},{"location":"getting-started/#system-requirements","title":"System Requirements","text":"<ul> <li>Python Version: 3.11, 3.12, or 3.13</li> <li>Operating Systems:<ul> <li>Linux (CPU and GPU)</li> <li>macOS (CPU only)</li> </ul> </li> <li>GPU Support: NVIDIA GPUs (CUDA-enabled)</li> </ul> <p>Platform Limitations</p> <p>Windows and Apple Silicon GPU support is currently under development.</p>"},{"location":"getting-started/#your-first-forecasting-model","title":"Your First Forecasting Model","text":"<p>Let's start with a simple example using the LPTM model to forecast time-series data.</p>"},{"location":"getting-started/#step-1-import-libraries","title":"Step 1: Import Libraries","text":"<pre><code>from samay.model import LPTMModel\nfrom samay.dataset import LPTMDataset\n</code></pre>"},{"location":"getting-started/#step-2-configure-the-model","title":"Step 2: Configure the Model","text":"<pre><code>config = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,  # Predict 192 time steps ahead\n    \"freeze_encoder\": True,   # Keep encoder frozen\n    \"freeze_embedder\": True,  # Keep embedder frozen\n    \"freeze_head\": False,     # Train the forecasting head\n}\n</code></pre>"},{"location":"getting-started/#step-3-load-the-pre-trained-model","title":"Step 3: Load the Pre-trained Model","text":"<pre><code>model = LPTMModel(config)\n</code></pre> <p>The model is automatically downloaded from the Hugging Face Hub on first use.</p>"},{"location":"getting-started/#step-4-prepare-your-dataset","title":"Step 4: Prepare Your Dataset","text":"<p>Samay expects your data in CSV format with: - A datetime column - One or more value columns</p> <p>Example data format (<code>ETTh1.csv</code>):</p> <pre><code>date,HUFL,HULL,MUFL,MULL,LUFL,LULL,OT\n2016-07-01 00:00:00,5.827,2.009,1.599,0.462,5.677,2.009,6.082\n2016-07-01 01:00:00,5.693,2.076,1.492,0.426,5.485,1.942,5.947\n...\n</code></pre>"},{"location":"getting-started/#step-5-load-the-dataset","title":"Step 5: Load the Dataset","text":"<pre><code>train_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n)\n</code></pre>"},{"location":"getting-started/#step-6-fine-tune-the-model-optional","title":"Step 6: Fine-tune the Model (Optional)","text":"<pre><code>finetuned_model = model.finetune(train_dataset)\n</code></pre> <p>During fine-tuning, you'll see training progress:</p> <pre><code>Epoch 0: Train loss: 0.594\nEpoch 1: Train loss: 0.504\nEpoch 2: Train loss: 0.479\n...\n</code></pre>"},{"location":"getting-started/#step-7-evaluate-the-model","title":"Step 7: Evaluate the Model","text":"<pre><code>test_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    horizon=192,\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\nprint(f\"Average Test Loss: {avg_loss}\")\n</code></pre>"},{"location":"getting-started/#step-8-visualize-results","title":"Step 8: Visualize Results","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Convert to numpy arrays\ntrues = np.array(trues)\npreds = np.array(preds)\nhistories = np.array(histories)\n\n# Pick a random example\nchannel_idx = 0\ntime_index = 0\n\nhistory = histories[time_index, channel_idx, :]\ntrue = trues[time_index, channel_idx, :]\npred = preds[time_index, channel_idx, :]\n\nplt.figure(figsize=(12, 4))\nplt.plot(range(len(history)), history, label=\"History\", c=\"darkblue\")\nplt.plot(\n    range(len(history), len(history) + len(true)),\n    true,\n    label=\"Ground Truth\",\n    color=\"green\",\n    linestyle=\"--\",\n)\nplt.plot(\n    range(len(history), len(history) + len(pred)),\n    pred,\n    label=\"Prediction\",\n    color=\"red\",\n)\nplt.legend()\nplt.title(\"Time Series Forecasting with LPTM\")\nplt.xlabel(\"Time Step\")\nplt.ylabel(\"Value\")\nplt.show()\n</code></pre>"},{"location":"getting-started/#complete-example","title":"Complete Example","text":"<p>Here's the complete code in one place:</p> <pre><code>from samay.model import LPTMModel\nfrom samay.dataset import LPTMDataset\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Configure model\nconfig = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\n# Load model\nmodel = LPTMModel(config)\n\n# Load datasets\ntrain_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n)\n\ntest_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    horizon=192,\n)\n\n# Fine-tune\nfinetuned_model = model.finetune(train_dataset)\n\n# Evaluate\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\nprint(f\"Average Test Loss: {avg_loss}\")\n\n# Visualize\ntrues = np.array(trues)\npreds = np.array(preds)\nhistories = np.array(histories)\n\nchannel_idx = 0\ntime_index = 0\n\nhistory = histories[time_index, channel_idx, :]\ntrue = trues[time_index, channel_idx, :]\npred = preds[time_index, channel_idx, :]\n\nplt.figure(figsize=(12, 4))\nplt.plot(range(len(history)), history, label=\"History\")\nplt.plot(range(len(history), len(history) + len(true)), true, label=\"Ground Truth\", linestyle=\"--\")\nplt.plot(range(len(history), len(history) + len(pred)), pred, label=\"Prediction\")\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"getting-started/#zero-shot-forecasting","title":"Zero-Shot Forecasting","text":"<p>You can also use pre-trained models directly without fine-tuning:</p> <pre><code># Skip the finetune step\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n</code></pre> <p>This is called zero-shot forecasting, where the pre-trained model makes predictions without any task-specific training.</p>"},{"location":"getting-started/#dataset-boundaries","title":"Dataset Boundaries","text":"<p>By default, Samay splits your data into: - Training: First 60% of data - Validation: Next 20% of data - Testing: Last 20% of data</p> <p>You can customize these boundaries:</p> <pre><code>train_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n    boundaries=[0, 10000, 15000],  # Custom split points\n)\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Now that you've run your first model, explore:</p> <ul> <li>Model Guides: Learn about other models (TimesFM, MOMENT, Chronos, etc.)</li> <li>API Reference: Detailed API documentation</li> <li>Examples: More advanced use cases</li> </ul>"},{"location":"getting-started/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/#cuda-out-of-memory","title":"CUDA Out of Memory","text":"<p>If you encounter GPU memory issues:</p> <pre><code>config = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 96,  # Reduce horizon\n    # ... other configs\n}\n\ntrain_dataset = LPTMDataset(\n    # ...\n    batchsize=8,  # Reduce batch size\n)\n</code></pre>"},{"location":"getting-started/#missing-dependencies","title":"Missing Dependencies","text":"<p>If you encounter import errors, ensure all dependencies are installed:</p> <pre><code>pip install --upgrade git+https://github.com/AdityaLab/Samay.git\n</code></pre>"},{"location":"getting-started/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: You're reading it!</li> <li>Examples: Check the examples section</li> <li>GitHub Issues: Report bugs</li> <li>Email: hkamarthi3@gatech.edu, badityap@cc.gatech.edu</li> </ul>"},{"location":"api/datasets/","title":"Datasets API Reference","text":"<p>This page provides detailed API documentation for all dataset classes in Samay.</p>"},{"location":"api/datasets/#lptmdataset","title":"LPTMDataset","text":"<p>Dataset class for LPTM model.</p>"},{"location":"api/datasets/#samay.dataset.LPTMDataset","title":"<code>LPTMDataset(name=None, datetime_col=None, path=None, batchsize=16, mode='train', boundaries=[0, 0, 0], horizon=0, task_name='forecasting', label_col=None, stride=10, seq_len=512, **kwargs)</code>","text":"<p>               Bases: <code>BaseDataset</code></p> <p>Dataset class for Moment model Data Format: Dict with keys: input_ts: np.ndarray, historical time series data actual_ts: np.ndarray, actual time series data</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def __init__(\n    self,\n    name=None,\n    datetime_col=None,\n    path=None,\n    batchsize=16,\n    mode=\"train\",\n    boundaries=[0, 0, 0],\n    horizon=0,\n    task_name=\"forecasting\",\n    label_col=None,\n    stride=10,\n    seq_len=512,\n    **kwargs,\n):\n    super().__init__(\n        name=name,\n        datetime_col=datetime_col,\n        path=path,\n        batchsize=batchsize,\n        mode=mode,\n    )\n    self.task_name = task_name\n    self.label_col = \"label\" if label_col is None else label_col\n\n    self.seq_len = seq_len\n    self.stride = stride\n    self.forecast_horizon = horizon\n    self.boundaries = boundaries\n\n    self.max_col_num = 64\n    self.pad = False\n    self._read_data()\n\n    self.one_chunk_num = (\n        self.length_timeseries - self.seq_len - self.forecast_horizon\n    ) // self.stride + 1\n</code></pre>"},{"location":"api/datasets/#timesfmdataset","title":"TimesfmDataset","text":"<p>Dataset class for TimesFM model.</p>"},{"location":"api/datasets/#samay.dataset.TimesfmDataset","title":"<code>TimesfmDataset(name=None, datetime_col='ds', path=None, batchsize=4, mode='train', boundaries=(0, 0, 0), context_len=128, horizon_len=32, freq='h', normalize=False, stride=10, **kwargs)</code>","text":"<p>               Bases: <code>BaseDataset</code></p> <p>Dataset class for TimesFM model Data Format: Dict with keys: input_ts: np.ndarray, historical time series data actual_ts: np.ndarray, actual time series data</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def __init__(\n    self,\n    name=None,\n    datetime_col=\"ds\",\n    path=None,\n    batchsize=4,\n    mode=\"train\",\n    boundaries=(0, 0, 0),\n    context_len=128,\n    horizon_len=32,\n    freq=\"h\",\n    normalize=False,\n    stride=10,\n    **kwargs,\n):\n    super().__init__(\n        name=name,\n        datetime_col=datetime_col,\n        path=path,\n        batchsize=batchsize,\n        mode=mode,\n    )\n    self.context_len = context_len\n    self.horizon_len = horizon_len\n    self.freq = freq\n    self.normalize = normalize\n    self.stride = stride\n    self.data = pd.read_csv(self.data_path)\n    if boundaries == (0, 0, 0):\n        # Default boundaries: train 50%, val 20%, test 30%\n        self.boundaries = [\n            int(len(self.data) * 0.5),\n            int(len(self.data) * 0.7),\n            len(self.data) - 1,\n        ]\n    elif boundaries == (-1, -1, -1):\n        # use all data for training\n        self.boundaries = [0, 0, len(self.data) - 1]\n    else:\n        self.boundaries = boundaries\n    self.horizon_len = min(self.horizon_len, int(0.3 * len(self.data) + 1))\n    self.ts_cols = [col for col in self.data.columns if col != self.datetime_col]\n    tfdtl = TimeSeriesdata(\n        data_path=self.data_path,\n        datetime_col=self.datetime_col,\n        num_cov_cols=None,\n        cat_cov_cols=None,\n        ts_cols=np.array(self.ts_cols),\n        train_range=[0, self.boundaries[0]],\n        val_range=[self.boundaries[0], self.boundaries[1]],\n        test_range=[self.boundaries[1], self.boundaries[2]],\n        hist_len=self.context_len,\n        pred_len=self.horizon_len,\n        batch_size=64,\n        freq=self.freq,\n        normalize=self.normalize,\n        epoch_len=None,\n        holiday=False,\n        permute=False,\n    )\n    if self.normalize:\n        self.scaler = tfdtl.scaler\n    self.num_ts = len(self.ts_cols)\n    if self.mode == \"train\":\n        tfset = tfdtl.torch_dataset(mode=\"train\", shift=self.stride)\n    else:\n        tfset = tfdtl.torch_dataset(mode=\"test\", shift=self.horizon_len)\n    self.dataset = tfset\n</code></pre>"},{"location":"api/datasets/#momentdataset","title":"MomentDataset","text":"<p>Dataset class for MOMENT model supporting multiple tasks.</p>"},{"location":"api/datasets/#samay.dataset.MomentDataset","title":"<code>MomentDataset(name=None, datetime_col=None, path=None, batchsize=64, mode='train', boundaries=[0, 0, 0], horizon_len=0, task_name='forecasting', label_col=None, stride=10, **kwargs)</code>","text":"<p>               Bases: <code>BaseDataset</code></p> <p>Dataset class for Moment model Data Format: Dict with keys: input_ts: np.ndarray, historical time series data actual_ts: np.ndarray, actual time series data</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def __init__(\n    self,\n    name=None,\n    datetime_col=None,\n    path=None,\n    batchsize=64,\n    mode=\"train\",\n    boundaries=[0, 0, 0],\n    horizon_len=0,\n    task_name=\"forecasting\",\n    label_col=None,\n    stride=10,\n    **kwargs,\n):\n    super().__init__(\n        name=name,\n        datetime_col=datetime_col,\n        path=path,\n        batchsize=batchsize,\n        mode=mode,\n    )\n    self.task_name = task_name\n    self.label_col = \"label\" if label_col is None else label_col\n    self.mode = mode\n\n    self.seq_len = 512\n    self.stride = (\n        stride if (self.mode == \"train\" or horizon_len == 0) else horizon_len\n    )\n    self.forecast_horizon = horizon_len\n    self.boundaries = boundaries\n    self.max_col_num = 64\n\n    self.pad = False\n    self._read_data()\n\n    self.one_chunk_num = (\n        self.length_timeseries - self.seq_len - self.forecast_horizon\n    ) // self.stride + 1\n</code></pre>"},{"location":"api/datasets/#chronosdataset","title":"ChronosDataset","text":"<p>Dataset class for Chronos model with tokenization.</p>"},{"location":"api/datasets/#samay.dataset.ChronosDataset","title":"<code>ChronosDataset(name=None, datetime_col='ds', path=None, boundaries=[0, 0, 0], batch_size=16, mode=None, stride=10, tokenizer_class='MeanScaleUniformBins', drop_prob=0.2, min_past=64, np_dtype=np.float32, config=None)</code>","text":"<p>               Bases: <code>BaseDataset</code></p> <p>Dataset class for Chronos model Data Format: Dict with keys: input_ts: np.ndarray, historical time series data actual_ts: np.ndarray, actual time series data</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def __init__(\n    self,\n    name=None,\n    datetime_col=\"ds\",\n    path=None,\n    boundaries=[0, 0, 0],\n    batch_size=16,\n    mode=None,\n    stride=10,\n    tokenizer_class=\"MeanScaleUniformBins\",\n    drop_prob=0.2,\n    min_past=64,\n    np_dtype=np.float32,\n    config=None,\n):\n    super().__init__(\n        name=name,\n        datetime_col=datetime_col,\n        path=path,\n        batchsize=batch_size,\n        mode=mode,\n    )\n    # Todo: implement ChronosDataset\n    assert tokenizer_class is not None, \"Tokenizer is required for ChronosDataset\"\n\n    if not config:\n        self.config = ChronosConfig(\n            tokenizer_class=\"MeanScaleUniformBins\",\n            tokenizer_kwargs={\"low_limit\": -15.0, \"high_limit\": 15.0},\n            n_tokens=4096,\n            n_special_tokens=2,\n            pad_token_id=0,\n            eos_token_id=1,\n            use_eos_token=True,\n            model_type=\"seq2seq\",\n            context_length=512,\n            prediction_length=64,\n            num_samples=20,\n            temperature=1.0,\n            top_k=50,\n            top_p=1.0,\n        )\n    else:\n        self.config = ChronosConfig(**config)\n    assert type(self.config) == ChronosConfig, (\n        \"Config must be an instance of ChronosConfig\"\n    )\n    assert self.config.model_type in (\"seq2seq\", \"causal\"), (\n        \"Model type must be either 'seq2seq' or 'causal'\"\n    )\n\n    self.context_len = self.config.context_length\n    self.horizon_len = self.config.prediction_length\n    self.drop_prob = drop_prob if self.config.model_type == \"seq2seq\" else 0.0\n    self.min_past = min_past or self.config.prediction_length\n    self.model_type = self.config.model_type\n    self.mode = mode\n    self.np_dtype = np_dtype\n    self.boundaries = boundaries\n    self.stride = stride\n    self.batchsize = batch_size\n    self.max_col_num = 16\n\n    self.pad = False\n    self._read_data()\n    self.preprocess()\n\n    self.one_chunk_num = (\n        self.length_timeseries - self.context_len - self.horizon_len\n    ) // self.stride + 1\n</code></pre>"},{"location":"api/datasets/#moiraidataset","title":"MoiraiDataset","text":"<p>Dataset class for MOIRAI model with frequency support.</p>"},{"location":"api/datasets/#samay.dataset.MoiraiDataset","title":"<code>MoiraiDataset(name=None, datetime_col='date', path=None, boundaries=(0, 0, 0), context_len=128, horizon_len=32, patch_size=16, batch_size=16, freq=None, start_date=None, end_date=None, operation='mean', normalize=True, mode='train', htune=False, data_config=None, **kwargs)</code>","text":"<p>               Bases: <code>BaseDataset</code></p> <p>Dataset class for Moirai model. It ingests data in the form of a (num_variates x num_timesteps) matrix.</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def __init__(\n    self,\n    name=None,\n    datetime_col=\"date\",\n    path=None,\n    boundaries=(0, 0, 0),\n    context_len=128,\n    horizon_len=32,\n    patch_size=16,\n    batch_size=16,\n    freq=None,\n    start_date=None,\n    end_date=None,\n    operation=\"mean\",\n    normalize=True,\n    mode=\"train\",\n    htune=False,  # hyperparameter tuning\n    data_config=None,\n    **kwargs,\n):\n    super().__init__(\n        name=name,\n        datetime_col=datetime_col,\n        path=path,\n        batchsize=batch_size,\n        mode=mode,\n    )\n    self.context_len = context_len\n    self.horizon_len = horizon_len\n    self.patch_size = patch_size\n    self.batch_size = batch_size\n    self.mode = mode\n    self.htune = htune\n    self.boundaries = boundaries\n    self.normalize = normalize\n    self.kwargs = kwargs\n    if data_config:\n        self.target_dim = data_config.get(\"target_dim\", 1)\n        self.feat_dynamic_real_dim = data_config.get(\"feat_dynamic_real_dim\", 0)\n        self.past_feat_dynamic_real_dim = data_config.get(\n            \"past_feat_dynamic_real_dim\", 0\n        )\n    else:\n        self.target_dim = 1\n        self.feat_dynamic_real_dim = 0\n        self.past_feat_dynamic_real_dim = 0\n\n    self._read_data()  # read from path into a pandas dataframe\n    # Preprocess the data - infer freq, take subset or normalize\n    self._preprocess(\n        start_date=start_date, end_date=end_date, freq=freq, operation=operation\n    )\n    self.start_date = self.dataset.index[0]\n    self.train_transforms = self.default_transforms()\n    self.test_transforms = self.default_transforms()\n\n    # Split the dataset into train, val, test\n    if self.mode == \"train\":  # no windowing\n        self.dataset = self.dataset[: self.boundaries[0]]\n        self.gen_train_val_data()\n    elif self.mode == \"val\":  # no windowing\n        self.dataset = self.dataset[self.boundaries[0] : self.boundaries[1]]\n        self.gen_train_val_data()\n    elif self.mode == \"test\":\n        # whole dataset sent\n        self.gen_test_data()\n    else:\n        raise ValueError(f\"Unsupported mode: {self.mode}\")\n</code></pre>"},{"location":"api/datasets/#samay.dataset.MoiraiDataset.add_past_fields","title":"<code>add_past_fields(data: dict, ts_fields: list = [], past_ts_fields: list = [], dummy_val: float = 0.0, lead_time: int = 0, target_field: str = 'target', is_pad_field: str = 'is_pad', observed_value_field: str = 'observed_target', start_field: str = 'start', forecast_start_field: str = 'forecast_start', output_NTC: bool = True, mode='train')</code>","text":"<p>Add the following fields: (a) past_target: The past target data (b) past_observed_target: The past target data with missing values indicator (c) past_is_pad: Indicates if the added value was a padding value (d) past_feat_dynamic_real: The past dynamic real features (e) past_observed_feat_dynamic_real: The past dynamic real features with missing values indicator</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def add_past_fields(\n    self,\n    data: dict,\n    ts_fields: list = [],\n    past_ts_fields: list = [],\n    dummy_val: float = 0.0,\n    lead_time: int = 0,\n    target_field: str = \"target\",\n    is_pad_field: str = \"is_pad\",\n    observed_value_field: str = \"observed_target\",\n    start_field: str = \"start\",\n    forecast_start_field: str = \"forecast_start\",\n    output_NTC: bool = True,\n    mode=\"train\",\n):\n    \"\"\"Add the following fields:\n    (a) past_target: The past target data\n    (b) past_observed_target: The past target data with missing values indicator\n    (c) past_is_pad: Indicates if the added value was a padding value\n    (d) past_feat_dynamic_real: The past dynamic real features\n    (e) past_observed_feat_dynamic_real: The past dynamic real features with missing values indicator\n    \"\"\"\n    pred_len = self.horizon_len\n    target = data[target_field]\n    num_windows = 1 + ((target.shape[-1] - self.past_length) // pred_len)\n\n    # Sample indices from the target field using the instance sampler\n    if mode == \"train\":\n        sampled_indices = [\n            self.past_length + i * pred_len for i in range(num_windows + 1)\n        ]\n    elif mode == \"test\":\n        sampled_indices = custom_train_instance_split(target)\n    else:\n        raise ValueError(f\"Unsupported mode: {mode}\")\n\n    # Columns to be sliced\n    slice_cols = ts_fields + past_ts_fields + [target_field, observed_value_field]\n\n    transformed_data = []\n    # Iterate over the sampled indices\n    for i in range(len(sampled_indices)):\n        idx = sampled_indices[i]\n        # Calculate the padding length if the index is less than past_length\n        d = data.copy()\n        pad_length = max(\n            0,\n            self.past_length\n            - d[target_field][..., (idx - self.past_length) : idx].shape[-1],\n        )\n\n        # Iterate over the fields to be sliced\n        for field in slice_cols:\n            # Slice the past piece of the field\n            if pad_length == 0:\n                past_piece = d[field][..., (idx - self.past_length) : idx]\n            else:\n                pad_block = np.full(\n                    shape=d[field].shape[:-1] + (pad_length,),\n                    fill_value=dummy_val,\n                    dtype=d[field].dtype,\n                )\n                past_piece = np.concatenate(\n                    [pad_block, d[field][..., (idx - self.past_length) : idx]],\n                    axis=-1,\n                )\n\n            # # Slice the future piece of the field\n            # future_piece = d[field][..., (idx + lead_time) : (idx + lead_time + pred_len)]\n            future_piece = np.full(\n                shape=d[field].shape[:-1] + (pred_len,),\n                fill_value=dummy_val,\n                dtype=d[field].dtype,\n            )\n\n            # If the field is in time series fields, concatenate past and future pieces\n            if field in ts_fields:\n                piece = np.concatenate([past_piece, future_piece], axis=-1)\n                if output_NTC:\n                    piece = piece.transpose()\n                d[field] = piece\n            else:\n                if output_NTC:\n                    past_piece = past_piece.transpose()\n                    # future_piece = future_piece.transpose()\n                if field not in past_ts_fields:\n                    d[\"past_\" + field] = past_piece\n                    # d[\"future_\" + field] = future_piece\n                    del d[field]\n                else:\n                    d[field] = past_piece\n\n        # Create a padding indicator for the past piece\n        pad_indicator = np.zeros(self.past_length)\n        if pad_length &gt; 0:\n            pad_indicator[:pad_length] = 1\n        d[\"past_\" + (is_pad_field)] = pad_indicator\n\n        # Set the forecast start field\n        d[forecast_start_field] = (d[start_field] + idx + lead_time).to_timestamp()\n\n        # Append the transformed data\n        transformed_data.append(d)\n\n    # Return the transformed data\n    return transformed_data\n</code></pre>"},{"location":"api/datasets/#samay.dataset.MoiraiDataset.default_transforms","title":"<code>default_transforms() -&gt; transforms.Compose</code>","text":"<p>Default transformations for the dataset</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def default_transforms(self) -&gt; transforms.Compose:\n    \"\"\"Default transformations for the dataset\"\"\"\n    transforms_list = []\n\n    # Convert the target data to numpy array\n    transforms_list.append(\n        AsNumpy(\n            field=\"target\",\n            expected_ndim=1 if self.target_dim == 1 else 2,\n            dtype=np.float32,\n        )\n    )\n\n    if self.target_dim == 1:\n        # Fix missing values\n        transforms_list.append(\n            AddObservedValues(\n                target_field=\"target\",\n                output_field=\"observed_target\",\n                imputation_method=CausalMeanNaNFix(),\n                dtype=bool,\n            )\n        )\n\n        # Add dimension to target\n        transforms_list.append(ArrExpandDims(field=\"target\", axis=0))\n        transforms_list.append(ArrExpandDims(field=\"observed_target\", axis=0))\n    else:\n        transforms_list.append(\n            AddObservedValues(\n                target_field=\"target\",\n                output_field=\"observed_target\",\n                dtype=bool,\n            )\n        )\n\n    if self.feat_dynamic_real_dim &gt; 0:\n        transforms_list.append(\n            AsNumpy(\n                field=\"feat_dynamic_real\",\n                expected_ndim=2,\n                dtype=np.float32,\n            )\n        )\n        transforms_list.append(\n            AddObservedValues(\n                target_field=\"feat_dynamic_real\",\n                output_field=\"observed_feat_dynamic_real\",\n                dtype=bool,\n            )\n        )\n\n    if self.past_feat_dynamic_real_dim &gt; 0:\n        transforms_list.append(\n            AsNumpyArray(\n                field=\"past_feat_dynamic_real\",\n                expected_ndim=2,\n                dtype=np.float32,\n            )\n        )\n        transforms_list.append(\n            AddObservedValuesIndicator(\n                target_field=\"past_feat_dynamic_real\",\n                output_field=\"past_observed_feat_dynamic_real\",\n                dtype=bool,\n            )\n        )\n\n    # Convert list of tranforms to a single transformation\n    comp_transform = transforms.Compose(transforms_list)\n\n    return comp_transform\n</code></pre>"},{"location":"api/datasets/#samay.dataset.MoiraiDataset.gen_test_data","title":"<code>gen_test_data()</code>","text":"<p>Generates test data based on the boundaries</p> <p>Returns:</p> Type Description <p>np.ndarray: Test data</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def gen_test_data(self):\n    \"\"\"Generates test data based on the boundaries\n\n    Returns:\n        np.ndarray: Test data\n    \"\"\"\n    data = []\n    num_windows = (\n        1\n        if (self.dataset.shape[0] - self.boundaries[1]) &lt; self.horizon_len + self.context_len\n        else (self.dataset.shape[0] - self.boundaries[1] - self.context_len) // self.horizon_len\n    )\n    for i in range(self.dataset.shape[1]):\n        for j in range(num_windows):\n            if j == num_windows - 1:\n                start_idx = self.dataset.shape[0] - self.horizon_len\n            else:\n                start_idx = self.boundaries[1] + self.context_len + j * self.horizon_len\n            end_idx = start_idx + self.horizon_len\n            data.append(\n                (\n                    {  # input\n                        \"start\": Period(self.start_date, freq=freq_mapping(self.freq)),\n                        \"target\": self.dataset.iloc[max(0, start_idx-self.context_len):start_idx, i].values,\n                        \"item_id\": self.dataset.columns[i],\n                    },\n                    {  # label\n                        \"start\": Period(self.start_date, freq=freq_mapping(self.freq)),\n                        \"target\": self.dataset.iloc[start_idx:end_idx, i].values,\n                        \"item_id\": self.dataset.columns[i],\n                    },\n                )\n            )\n\n    self.dataset = MoiraiTorch(data)\n    self.data = data\n</code></pre>"},{"location":"api/datasets/#samay.dataset.MoiraiDataset.gen_train_val_data","title":"<code>gen_train_val_data()</code>","text":"<p>Generates training and validation data based on the boundaries</p> <p>Returns:</p> Type Description <p>np.ndarray: Training and Validation data</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def gen_train_val_data(self):\n    \"\"\"Generates training and validation data based on the boundaries\n\n    Returns:\n        np.ndarray: Training and Validation data\n    \"\"\"\n    data = []\n    # Each column is a separate time series\n    # Each time series is appended to the data list\n    for i in range(self.dataset.shape[1]):\n        data.append(\n            {\n                \"start\": Period(self.start_date, freq=freq_mapping(self.freq)),\n                \"target\": self.dataset.iloc[:, i].values,\n                \"item_id\": self.dataset.columns[i],\n            }\n        )\n\n    self.dataset = MoiraiTorch(data)\n    self.data = data\n</code></pre>"},{"location":"api/datasets/#samay.dataset.MoiraiDataset.get_dataloader","title":"<code>get_dataloader()</code>","text":"<p>Returns the iterator for data batches for the dataset based on the mode</p> <p>Returns:</p> Type Description <p>torch.utils.data.DataLoader: Depends on the mode</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def get_dataloader(self):\n    \"\"\"Returns the iterator for data batches for the dataset based on the mode\n\n    Returns:\n        torch.utils.data.DataLoader: Depends on the mode\n    \"\"\"\n    if self.mode == \"train\":\n        self.prep_train_test_data(mode=\"train\")\n        if self.kwargs:\n            batch_size = self.kwargs.get(\"batch_size\", self.batch_size)\n            num_workers = self.kwargs.get(\"num_workers\", 0)\n            pin_memory = self.kwargs.get(\"pin_memory\", False)\n            persistent_workers = self.kwargs.get(\"persistent_workers\", False)\n\n            return DataLoader(\n                self.batched_data,\n                batch_size=batch_size,\n                shuffle=True,\n                num_workers=num_workers,\n                pin_memory=pin_memory,\n                persistent_workers=persistent_workers,\n            )\n        return DataLoader(\n            self.batched_data, batch_size=self.batch_size, shuffle=True\n        )\n    else:\n        self.prep_train_test_data(mode=\"test\")\n        return DataLoader(\n            self.batched_data, batch_size=self.batch_size, shuffle=False\n        )\n</code></pre>"},{"location":"api/datasets/#samay.dataset.MoiraiDataset.prep_train_test_data","title":"<code>prep_train_test_data(mode='train')</code>","text":"<p>Apply transforms on the data and add the past fields (past target, past observed target, etc)</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def prep_train_test_data(self, mode=\"train\"):\n    \"\"\"Apply transforms on the data and add the past fields (past target, past observed target, etc)\"\"\"\n    ts_fields = []\n    if self.feat_dynamic_real_dim &gt; 0:\n        ts_fields.append(\"feat_dynamic_real\")\n        ts_fields.append(\"observed_feat_dynamic_real\")\n    past_ts_fields = []\n    if self.past_feat_dynamic_real_dim &gt; 0:\n        past_ts_fields.append(\"past_feat_dynamic_real\")\n        past_ts_fields.append(\"past_observed_feat_dynamic_real\")\n\n    if mode == \"train\":\n        # STEP 1: Apply the transforms on the data\n        while self.train_transforms.transforms:\n            t = self.train_transforms.transforms.pop(0)\n            self.data = [t(x) for x in self.data]\n        # STEP 2: Linearize the data and add the required fields\n        transformed_data = []\n        for x in self.data:\n            transformed_data.extend(\n                self.add_past_fields(\n                    data=x,\n                    mode=\"train\",\n                    ts_fields=ts_fields,\n                    past_ts_fields=past_ts_fields,\n                )\n            )\n        self.data = transformed_data\n        # STEP 3: Convert the data to a MoiraiTorch object\n        self.batched_data = MoiraiTorch(self.data)\n\n    elif mode == \"test\":\n        # STEP 1: Apply the transforms on the data\n        data = [x[0] for x in self.data]  # only input part\n        while self.test_transforms.transforms:\n            t = self.test_transforms.transforms.pop(0)\n            data = [t(x) for x in data]\n        # STEP 2: Linearize the data and add the required fields\n        transformed_data = []\n        for x in data:\n            transformed_data.extend(\n                self.add_past_fields(\n                    data=x,\n                    mode=\"test\",\n                    ts_fields=ts_fields,\n                    past_ts_fields=past_ts_fields,\n                )\n            )\n        # STEP 3: Convert the data to a MoiraiTorch object\n        self.batched_data = MoiraiTorch(transformed_data)\n</code></pre>"},{"location":"api/datasets/#tinytimemixerdataset","title":"TinyTimeMixerDataset","text":"<p>Dataset class for TinyTimeMixer model.</p>"},{"location":"api/datasets/#samay.dataset.TinyTimeMixerDataset","title":"<code>TinyTimeMixerDataset(name=None, datetime_col='ds', path=None, boundaries=[0, 0, 0], batch_size=128, mode=None, stride=10, context_len=512, horizon_len=64)</code>","text":"<p>               Bases: <code>BaseDataset</code></p> <p>Dataset class for ChronosBolt model Data Format: Dict with keys: input_ts: np.ndarray, historical time series data actual_ts: np.ndarray, actual time series data</p> Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def __init__(\n    self,\n    name=None,\n    datetime_col=\"ds\",\n    path=None,\n    boundaries=[0, 0, 0],\n    batch_size=128,\n    mode=None,\n    stride=10,\n    context_len=512,\n    horizon_len=64,\n):\n    super().__init__(\n        name=name,\n        datetime_col=datetime_col,\n        path=path,\n        batchsize=batch_size,\n        mode=mode,\n    )\n    # Todo: implement ChronosDataset\n\n    self.context_len = context_len\n    self.horizon_len = horizon_len\n    self.mode = mode\n    self.boundaries = boundaries\n    self.stride = stride\n    self.batchsize = batch_size\n    self.max_col_num = 64\n\n    self.pad = False\n    self._read_data()\n\n    self.one_chunk_num = (\n        self.length_timeseries - self.context_len - self.horizon_len\n    ) // self.stride + 1\n</code></pre>"},{"location":"api/datasets/#basedataset","title":"BaseDataset","text":"<p>All datasets inherit from the base dataset class:</p>"},{"location":"api/datasets/#samay.dataset.BaseDataset","title":"<code>BaseDataset(name=None, datetime_col=None, path=None, batchsize=8, mode='train', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <p>str, dataset name</p> <code>None</code> <code>target</code> <p>np.ndarray, target data</p> required Source code in <code>Samay\\src\\samay\\dataset.py</code> <pre><code>def __init__(\n    self,\n    name=None,\n    datetime_col=None,\n    path=None,\n    batchsize=8,\n    mode=\"train\",\n    **kwargs,\n):\n    \"\"\"\n    Args:\n        name: str, dataset name\n        target: np.ndarray, target data\n    \"\"\"\n    self.name = name\n    self.datetime_col = datetime_col\n    self.batchsize = batchsize\n    self.mode = mode\n    if path:\n        self.data_path = path\n    else:\n        data_func = globals()[f\"get_{self.name}_dataset\"]\n        self.data_path = data_func()\n</code></pre>"},{"location":"api/datasets/#usage-examples","title":"Usage Examples","text":""},{"location":"api/datasets/#loading-a-dataset","title":"Loading a Dataset","text":"<pre><code>from samay.dataset import LPTMDataset\n\ntrain_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n    batchsize=16,\n)\n</code></pre>"},{"location":"api/datasets/#custom-data-splits","title":"Custom Data Splits","text":"<pre><code># Specify exact boundaries\ndataset = LPTMDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n    boundaries=[0, 10000, 15000],  # Train: 0-10k, Val: 10k-15k, Test: 15k-end\n)\n</code></pre>"},{"location":"api/datasets/#getting-data-loader","title":"Getting Data Loader","text":"<pre><code># Get PyTorch DataLoader\ntrain_loader = train_dataset.get_data_loader()\n\nfor batch in train_loader:\n    # Process batch\n    pass\n</code></pre>"},{"location":"api/datasets/#accessing-dataset-properties","title":"Accessing Dataset Properties","text":"<pre><code># Dataset length\nprint(f\"Dataset size: {len(dataset)}\")\n\n# Get a single item\nsample = dataset[0]\n\n# Number of channels\nprint(f\"Number of channels: {dataset.n_channels}\")\n\n# Sequence length\nprint(f\"Sequence length: {dataset.seq_len}\")\n</code></pre>"},{"location":"api/datasets/#denormalizing-predictions","title":"Denormalizing Predictions","text":"<pre><code># If dataset normalizes data\nnormalized_preds = model.evaluate(dataset)[2]\n\n# Denormalize for interpretation\ndenormalized_preds = dataset._denormalize_data(normalized_preds)\n</code></pre>"},{"location":"api/datasets/#common-parameters","title":"Common Parameters","text":"<p>Most dataset classes share these common parameters:</p> Parameter Type Default Description <code>name</code> str <code>None</code> Dataset name (for metadata) <code>datetime_col</code> str Varies Name of the datetime column in CSV <code>path</code> str Required Path to CSV file <code>mode</code> str <code>\"train\"</code> Mode: <code>\"train\"</code> or <code>\"test\"</code> <code>batchsize</code> int Varies Batch size for DataLoader <code>boundaries</code> list <code>[0, 0, 0]</code> Custom train/val/test split indices <code>stride</code> int <code>10</code> Stride for sliding window"},{"location":"api/datasets/#data-format-requirements","title":"Data Format Requirements","text":""},{"location":"api/datasets/#csv-structure","title":"CSV Structure","text":"<p>All datasets expect CSV files with: 1. A datetime column (configurable name) 2. One or more value columns</p> <p>Example: <pre><code>date,HUFL,HULL,MUFL,MULL,LUFL,LULL,OT\n2016-07-01 00:00:00,5.827,2.009,1.599,0.462,5.677,2.009,6.082\n2016-07-01 01:00:00,5.693,2.076,1.492,0.426,5.485,1.942,5.947\n...\n</code></pre></p>"},{"location":"api/datasets/#datetime-formats","title":"Datetime Formats","text":"<p>Supported datetime formats: - ISO 8601: <code>2016-07-01 00:00:00</code> - Date only: <code>2016-07-01</code> - Custom formats (parsed by pandas)</p>"},{"location":"api/datasets/#missing-values","title":"Missing Values","text":"<ul> <li>Some datasets handle missing values automatically</li> <li>Others require preprocessing</li> <li>Check individual dataset documentation</li> </ul>"},{"location":"api/datasets/#model-specific-dataset-features","title":"Model-Specific Dataset Features","text":""},{"location":"api/datasets/#lptmdataset_1","title":"LPTMDataset","text":"<ul> <li>Supports forecasting, classification, and detection</li> <li>Configurable sequence length (default: 512)</li> <li>Adaptive segmentation</li> </ul> <pre><code>dataset = LPTMDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n    seq_len=512,  # Configurable\n    task_name=\"forecasting\",\n)\n</code></pre>"},{"location":"api/datasets/#timesfmdataset_1","title":"TimesfmDataset","text":"<ul> <li>Frequency specification</li> <li>Optional normalization</li> <li>Patch-based processing</li> </ul> <pre><code>dataset = TimesfmDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    context_len=512,\n    horizon_len=192,\n    freq=\"h\",  # Frequency\n    normalize=True,  # Optional normalization\n)\n</code></pre>"},{"location":"api/datasets/#momentdataset_1","title":"MomentDataset","text":"<ul> <li>Multi-task support</li> <li>Task-specific preprocessing</li> <li>Label handling for classification</li> </ul> <pre><code># Forecasting\ndataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon_len=192,\n    task_name=\"forecasting\",\n)\n\n# Classification\ndataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/classification.csv\",\n    mode=\"train\",\n    task_name=\"classification\",\n    label_col=\"label\",\n)\n</code></pre>"},{"location":"api/datasets/#chronosdataset_1","title":"ChronosDataset","text":"<ul> <li>Tokenization support</li> <li>Configurable vocab size</li> <li>Drop probability for training</li> </ul> <pre><code>from samay.models.chronosforecasting.chronos import ChronosConfig\n\nconfig = ChronosConfig(\n    context_length=512,\n    prediction_length=64,\n    # ... other configs\n)\n\ndataset = ChronosDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    config=config,\n)\n</code></pre>"},{"location":"api/datasets/#moiraidataset_1","title":"MoiraiDataset","text":"<ul> <li>Frequency specification (required)</li> <li>Date range filtering</li> <li>Built-in normalization</li> </ul> <pre><code>dataset = MoiraiDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    freq=\"h\",  # Required\n    context_len=128,\n    horizon_len=64,\n    start_date=\"2016-01-01\",  # Optional\n    end_date=\"2017-12-31\",    # Optional\n    normalize=True,\n)\n</code></pre>"},{"location":"api/datasets/#tinytimemixerdataset_1","title":"TinyTimeMixerDataset","text":"<ul> <li>Large batch support</li> <li>Efficient windowing</li> <li>Fast data loading</li> </ul> <pre><code>dataset = TinyTimeMixerDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    context_len=512,\n    horizon_len=96,\n    batch_size=128,  # Supports large batches\n)\n</code></pre>"},{"location":"api/datasets/#common-methods","title":"Common Methods","text":"<p>All datasets implement these methods:</p>"},{"location":"api/datasets/#__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of samples in the dataset.</p>"},{"location":"api/datasets/#__getitem__idx","title":"<code>__getitem__(idx)</code>","text":"<p>Returns a single sample at the given index.</p>"},{"location":"api/datasets/#get_data_loader","title":"<code>get_data_loader()</code>","text":"<p>Returns a PyTorch DataLoader for the dataset.</p> <p>Returns: - <code>torch.utils.data.DataLoader</code></p>"},{"location":"api/datasets/#_denormalize_datadata","title":"<code>_denormalize_data(data)</code>","text":"<p>Denormalizes data (if normalization was applied).</p> <p>Parameters: - <code>data</code> (np.ndarray): Normalized data</p> <p>Returns: - <code>np.ndarray</code>: Denormalized data</p>"},{"location":"api/datasets/#data-split-strategies","title":"Data Split Strategies","text":""},{"location":"api/datasets/#default-split","title":"Default Split","text":"<p>When <code>boundaries=[0, 0, 0]</code>: - Train: 60% of data - Validation: 20% of data - Test: 20% of data</p>"},{"location":"api/datasets/#custom-split","title":"Custom Split","text":"<pre><code># Specify exact indices\ndataset = LPTMDataset(\n    boundaries=[0, 10000, 15000],\n    # Train: 0-10000\n    # Val: 10000-15000\n    # Test: 15000-end\n)\n</code></pre>"},{"location":"api/datasets/#use-all-data","title":"Use All Data","text":"<pre><code># Use entire dataset for training\ndataset = LPTMDataset(\n    boundaries=[-1, -1, -1],\n)\n</code></pre>"},{"location":"api/datasets/#performance-tips","title":"Performance Tips","text":""},{"location":"api/datasets/#1-batch-size","title":"1. Batch Size","text":"<p>Larger batch sizes improve throughput: <pre><code>dataset = LPTMDataset(\n    batchsize=64,  # Larger batch\n    # ...\n)\n</code></pre></p>"},{"location":"api/datasets/#2-stride","title":"2. Stride","text":"<p>Smaller stride creates more samples but is slower: <pre><code># More samples (slower)\ndataset = LPTMDataset(\n    stride=1,\n    # ...\n)\n\n# Fewer samples (faster)\ndataset = LPTMDataset(\n    stride=96,\n    # ...\n)\n</code></pre></p>"},{"location":"api/datasets/#3-normalization","title":"3. Normalization","text":"<p>Enable normalization for better performance: <pre><code>dataset = TimesfmDataset(\n    normalize=True,\n    # ...\n)\n</code></pre></p>"},{"location":"api/datasets/#see-also","title":"See Also","text":"<ul> <li>Models API: Model classes</li> <li>Metrics API: Evaluation metrics</li> <li>Getting Started: Basic usage guide</li> </ul>"},{"location":"api/metrics/","title":"Metrics API Reference","text":"<p>This page provides detailed API documentation for evaluation metrics in Samay.</p>"},{"location":"api/metrics/#overview","title":"Overview","text":"<p>Samay provides a comprehensive set of metrics for evaluating time-series forecasting models. These metrics help assess prediction accuracy, error patterns, and model performance.</p>"},{"location":"api/metrics/#samay.metric","title":"<code>metric</code>","text":""},{"location":"api/metrics/#samay.metric.CRPS","title":"<code>CRPS(y_true: np.ndarray, y_pred: np.ndarray, quantiles: np.ndarray)</code>","text":"<p>Continuous ranked probability score y_true: (num_seq, n_var, seq_len) y_pred: (q, num_seq, n_var, seq_len) quantiles: (q, )</p> Source code in <code>Samay\\src\\samay\\metric.py</code> <pre><code>def CRPS(y_true: np.ndarray, y_pred: np.ndarray, quantiles: np.ndarray):\n    \"\"\"\n    Continuous ranked probability score\n    y_true: (num_seq, n_var, seq_len)\n    y_pred: (q, num_seq, n_var, seq_len)\n    quantiles: (q, )\n    \"\"\"\n    y_true = np.expand_dims(y_true, axis=0)  # (1, num_seq, n_var, seq_len)\n    diff = y_true - y_pred  # (q, num_seq, n_var, seq_len)\n    quantiles = np.expand_dims(\n        np.expand_dims(np.expand_dims(quantiles, axis=-1), axis=-1), axis=-1\n    )  # (q, 1, 1, 1)\n    pinball = np.maximum(quantiles * diff, (quantiles - 1) * diff)  # (num_seq, n_var, seq_len, q)\n    return np.mean(pinball)\n</code></pre>"},{"location":"api/metrics/#samay.metric.MAE","title":"<code>MAE(y_true: np.ndarray, y_pred: np.ndarray)</code>","text":"<p>Mean absolute error</p> Source code in <code>Samay\\src\\samay\\metric.py</code> <pre><code>def MAE(y_true: np.ndarray, y_pred: np.ndarray):\n    \"\"\"Mean absolute error\"\"\"\n    return np.mean(np.abs(y_true - y_pred))\n</code></pre>"},{"location":"api/metrics/#samay.metric.MAPE","title":"<code>MAPE(y_true: np.ndarray, y_pred: np.ndarray)</code>","text":"<p>Mean absolute percentage error</p> Source code in <code>Samay\\src\\samay\\metric.py</code> <pre><code>def MAPE(y_true: np.ndarray, y_pred: np.ndarray):\n    \"\"\"Mean absolute percentage error\"\"\"\n    return np.mean(np.abs(y_true - y_pred) / (y_true + 1e-5))\n</code></pre>"},{"location":"api/metrics/#samay.metric.MASE","title":"<code>MASE(y_true: np.ndarray, y_pred: np.ndarray, freq: str = 'h')</code>","text":"<p>Mean absolute scaled error</p> Source code in <code>Samay\\src\\samay\\metric.py</code> <pre><code>def MASE(y_true: np.ndarray, y_pred: np.ndarray, freq: str = \"h\"):\n    \"\"\"Mean absolute scaled error\"\"\"\n    DEFAULT_SEASONALITIES = {\n        \"S\": 3600,  # 1 hour\n        \"s\": 3600,  # 1 hour\n        \"T\": 1440,  # 1 day\n        \"min\": 1440,  # 1 day\n        \"H\": 24,  # 1 day\n        \"h\": 24,  # 1 day\n        \"D\": 1,  # 1 day\n        \"W\": 1,  # 1 week\n        \"M\": 12,\n        \"ME\": 12,\n        \"B\": 5,\n        \"Q\": 4,\n        \"QE\": 4,\n    }\n    # seasonality = DEFAULT_SEASONALITIES[freq]\n    if len(y_true.shape) == 3:  # num_batch, bs, seq_len\n        y_t = y_true[:, :, 1:] - y_true[:, :, :-1]\n    else:  # num_seq, seq_len\n        y_t = y_true[:, 1:] - y_true[:, :-1]\n    return np.mean(np.abs(y_true - y_pred) / (np.mean(np.abs(y_t)) + 1e-5))\n</code></pre>"},{"location":"api/metrics/#samay.metric.MSE","title":"<code>MSE(y_true: np.ndarray, y_pred: np.ndarray)</code>","text":"<p>Mean squared error</p> Source code in <code>Samay\\src\\samay\\metric.py</code> <pre><code>def MSE(y_true: np.ndarray, y_pred: np.ndarray):\n    \"\"\"Mean squared error\"\"\"\n    return np.mean((y_true - y_pred) ** 2)\n</code></pre>"},{"location":"api/metrics/#samay.metric.MSIS","title":"<code>MSIS(y_true: np.ndarray, y_pred: np.ndarray, alpha: float = 0.05)</code>","text":"<p>Mean scaled interval score</p> Source code in <code>Samay\\src\\samay\\metric.py</code> <pre><code>def MSIS(y_true: np.ndarray, y_pred: np.ndarray, alpha: float = 0.05):\n    \"\"\"Mean scaled interval score\"\"\"\n    q1 = np.percentile(y_true, 100 * alpha / 2)\n    q2 = np.percentile(y_true, 100 * (1 - alpha / 2))\n    denominator = q2 - q1\n    penalties = 2 * ((y_true &lt; q1) * (q1 - y_pred) + (y_true &gt; q2) * (y_pred - q2))\n    return np.mean(np.abs(y_true - y_pred) / (denominator + 1e-5)) + np.mean(\n        penalties / (denominator + 1e-5)\n    )\n</code></pre>"},{"location":"api/metrics/#samay.metric.MWSQ","title":"<code>MWSQ(y_true: np.ndarray, y_pred: np.ndarray, quantiles: np.ndarray)</code>","text":"<p>Mean weighted squared quantile loss y_true: (num_seq, n_var, seq_len) y_pred: (q, num_seq, n_var, seq_len) quantiles: (q, )</p> Source code in <code>Samay\\src\\samay\\metric.py</code> <pre><code>def MWSQ(y_true: np.ndarray, y_pred: np.ndarray, quantiles: np.ndarray):\n    \"\"\"\n    Mean weighted squared quantile loss\n    y_true: (num_seq, n_var, seq_len)\n    y_pred: (q, num_seq, n_var, seq_len)\n    quantiles: (q, )\n    \"\"\"\n\n    y_true = np.expand_dims(y_true, axis=0)  # (1, num_seq, n_var, seq_len)\n    diff = y_true - y_pred  # (q, num_seq, n_var, seq_len)\n    quantiles = np.expand_dims(\n        np.expand_dims(np.expand_dims(quantiles, axis=-1), axis=-1), axis=-1\n    )  # (q, 1, 1, 1)\n    pinball = np.maximum(quantiles * diff, (quantiles - 1) * diff)  # (num_seq, n_var, seq_len, q)\n    mwsq = np.mean(pinball ** 2)  # (num_seq, n_var, seq_len)\n    return mwsq\n</code></pre>"},{"location":"api/metrics/#samay.metric.ND","title":"<code>ND(y_true: np.ndarray, y_pred: np.ndarray)</code>","text":"<p>Normalized deviation</p> Source code in <code>Samay\\src\\samay\\metric.py</code> <pre><code>def ND(y_true: np.ndarray, y_pred: np.ndarray):\n    \"\"\"Normalized deviation\"\"\"\n    return np.mean(np.abs(y_true - y_pred)) / (np.mean(y_true) + 1e-5)\n</code></pre>"},{"location":"api/metrics/#samay.metric.NRMSE","title":"<code>NRMSE(y_true: np.ndarray, y_pred: np.ndarray)</code>","text":"<p>Normalized root mean squared error</p> Source code in <code>Samay\\src\\samay\\metric.py</code> <pre><code>def NRMSE(y_true: np.ndarray, y_pred: np.ndarray):\n    \"\"\"Normalized root mean squared error\"\"\"\n    return RMSE(y_true, y_pred) / (np.max(y_true) - np.min(y_true) + 1e-5)\n</code></pre>"},{"location":"api/metrics/#samay.metric.RMSE","title":"<code>RMSE(y_true: np.ndarray, y_pred: np.ndarray)</code>","text":"<p>Root mean squared error</p> Source code in <code>Samay\\src\\samay\\metric.py</code> <pre><code>def RMSE(y_true: np.ndarray, y_pred: np.ndarray):\n    \"\"\"Root mean squared error\"\"\"\n    return np.sqrt(MSE(y_true, y_pred))\n</code></pre>"},{"location":"api/metrics/#samay.metric.SMAPE","title":"<code>SMAPE(y_true: np.ndarray, y_pred: np.ndarray)</code>","text":"<p>Symmetric mean absolute percentage error</p> Source code in <code>Samay\\src\\samay\\metric.py</code> <pre><code>def SMAPE(y_true: np.ndarray, y_pred: np.ndarray):\n    \"\"\"Symmetric mean absolute percentage error\"\"\"\n    return np.mean(\n        2.0 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred) + 1e-5)\n    )\n</code></pre>"},{"location":"api/metrics/#available-metrics","title":"Available Metrics","text":""},{"location":"api/metrics/#mean-squared-error-mse","title":"Mean Squared Error (MSE)","text":"<p>Measures the average squared difference between predictions and ground truth.</p> <pre><code>from samay.metric import mse\n\nloss = mse(y_true, y_pred)\n</code></pre> <p>Formula: $MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$</p> <p>Properties: - Range: [0, \u221e) - Lower is better - Sensitive to outliers - Same units as squared target variable</p>"},{"location":"api/metrics/#root-mean-squared-error-rmse","title":"Root Mean Squared Error (RMSE)","text":"<p>Square root of MSE, providing error in original units.</p> <pre><code>from samay.metric import rmse\n\nloss = rmse(y_true, y_pred)\n</code></pre> <p>Formula: $RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$</p> <p>Properties: - Range: [0, \u221e) - Lower is better - Same units as target variable - Interpretable in original scale</p>"},{"location":"api/metrics/#mean-absolute-error-mae","title":"Mean Absolute Error (MAE)","text":"<p>Measures the average absolute difference between predictions and ground truth.</p> <pre><code>from samay.metric import mae\n\nloss = mae(y_true, y_pred)\n</code></pre> <p>Formula: $MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$</p> <p>Properties: - Range: [0, \u221e) - Lower is better - Less sensitive to outliers than MSE - Same units as target variable</p>"},{"location":"api/metrics/#mean-absolute-percentage-error-mape","title":"Mean Absolute Percentage Error (MAPE)","text":"<p>Measures the average percentage error.</p> <pre><code>from samay.metric import mape\n\nloss = mape(y_true, y_pred)\n</code></pre> <p>Formula: $MAPE = \\frac{100\\%}{n}\\sum_{i=1}^{n}\\left|\\frac{y_i - \\hat{y}_i}{y_i}\\right|$</p> <p>Properties: - Range: [0, \u221e) - Lower is better - Scale-independent - Undefined when $y_i = 0$</p>"},{"location":"api/metrics/#symmetric-mean-absolute-percentage-error-smape","title":"Symmetric Mean Absolute Percentage Error (sMAPE)","text":"<p>A symmetric version of MAPE that handles zero values better.</p> <pre><code>from samay.metric import smape\n\nloss = smape(y_true, y_pred)\n</code></pre> <p>Formula: $sMAPE = \\frac{100\\%}{n}\\sum_{i=1}^{n}\\frac{|y_i - \\hat{y}_i|}{(|y_i| + |\\hat{y}_i|)/2}$</p> <p>Properties: - Range: [0, 200%] - Lower is better - More robust than MAPE - Symmetric treatment of over/under predictions</p>"},{"location":"api/metrics/#mean-absolute-scaled-error-mase","title":"Mean Absolute Scaled Error (MASE)","text":"<p>Scale-independent metric that compares forecast to a naive baseline.</p> <pre><code>from samay.metric import mase\n\nloss = mase(y_true, y_pred, y_train)\n</code></pre> <p>Formula: $MASE = \\frac{\\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}i|}{\\frac{1}{n-1}\\sum$}^{n}|y_i - y_{i-1}|</p> <p>Properties: - Range: [0, \u221e) - Lower is better - Scale-independent - Values &lt; 1 indicate better than naive forecast</p>"},{"location":"api/metrics/#r2-score-coefficient-of-determination","title":"R\u00b2 Score (Coefficient of Determination)","text":"<p>Measures the proportion of variance explained by the model.</p> <pre><code>from samay.metric import r2_score\n\nscore = r2_score(y_true, y_pred)\n</code></pre> <p>Formula: $R^2 = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}i)^2}{\\sum$}^{n}(y_i - \\bar{y})^2</p> <p>Properties: - Range: (-\u221e, 1] - Higher is better - 1 = perfect predictions - 0 = as good as mean baseline</p>"},{"location":"api/metrics/#usage-examples","title":"Usage Examples","text":""},{"location":"api/metrics/#basic-usage","title":"Basic Usage","text":"<pre><code>from samay.metric import mse, mae, mape\nimport numpy as np\n\n# Get predictions from model\navg_loss, y_true, y_pred, histories = model.evaluate(test_dataset)\n\n# Convert to numpy arrays\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# Calculate metrics\nmse_score = mse(y_true, y_pred)\nmae_score = mae(y_true, y_pred)\nmape_score = mape(y_true, y_pred)\n\nprint(f\"MSE: {mse_score:.4f}\")\nprint(f\"MAE: {mae_score:.4f}\")\nprint(f\"MAPE: {mape_score:.4f}%\")\n</code></pre>"},{"location":"api/metrics/#multiple-metrics","title":"Multiple Metrics","text":"<pre><code>from samay.metric import mse, mae, rmse, mape, r2_score\n\nmetrics = {\n    \"MSE\": mse(y_true, y_pred),\n    \"MAE\": mae(y_true, y_pred),\n    \"RMSE\": rmse(y_true, y_pred),\n    \"MAPE\": mape(y_true, y_pred),\n    \"R\u00b2\": r2_score(y_true, y_pred),\n}\n\nprint(\"Evaluation Results:\")\nfor metric_name, value in metrics.items():\n    print(f\"  {metric_name}: {value:.4f}\")\n</code></pre>"},{"location":"api/metrics/#per-channel-metrics","title":"Per-Channel Metrics","text":"<pre><code>import numpy as np\n\n# y_true and y_pred shape: (num_samples, num_channels, horizon)\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# Calculate metrics per channel\nnum_channels = y_true.shape[1]\n\nprint(\"Per-Channel Results:\")\nfor ch in range(num_channels):\n    y_true_ch = y_true[:, ch, :]\n    y_pred_ch = y_pred[:, ch, :]\n\n    mse_ch = mse(y_true_ch, y_pred_ch)\n    mae_ch = mae(y_true_ch, y_pred_ch)\n\n    print(f\"  Channel {ch}:\")\n    print(f\"    MSE: {mse_ch:.4f}\")\n    print(f\"    MAE: {mae_ch:.4f}\")\n</code></pre>"},{"location":"api/metrics/#per-horizon-metrics","title":"Per-Horizon Metrics","text":"<pre><code># Calculate metrics at each forecast step\nhorizon_len = y_true.shape[-1]\n\nmse_per_step = []\nfor t in range(horizon_len):\n    y_true_t = y_true[:, :, t]\n    y_pred_t = y_pred[:, :, t]\n    mse_t = mse(y_true_t, y_pred_t)\n    mse_per_step.append(mse_t)\n\n# Plot error over forecast horizon\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, horizon_len + 1), mse_per_step)\nplt.xlabel(\"Forecast Step\")\nplt.ylabel(\"MSE\")\nplt.title(\"Error Over Forecast Horizon\")\nplt.grid(alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"api/metrics/#metric-selection-guide","title":"Metric Selection Guide","text":""},{"location":"api/metrics/#choose-msermse-when","title":"Choose MSE/RMSE when:","text":"<ul> <li>You want to penalize large errors more heavily</li> <li>Working with continuous variables</li> <li>Outliers are important to detect</li> </ul>"},{"location":"api/metrics/#choose-mae-when","title":"Choose MAE when:","text":"<ul> <li>You want a robust metric less sensitive to outliers</li> <li>All errors should be weighted equally</li> <li>Interpretability is important</li> </ul>"},{"location":"api/metrics/#choose-mape-when","title":"Choose MAPE when:","text":"<ul> <li>You need scale-independent comparison</li> <li>Percentage errors are more meaningful</li> <li>Target values are never zero</li> </ul>"},{"location":"api/metrics/#choose-mase-when","title":"Choose MASE when:","text":"<ul> <li>Comparing across different scales</li> <li>Need scale-independent metric</li> <li>Want to compare against naive baseline</li> </ul>"},{"location":"api/metrics/#choose-r2-when","title":"Choose R\u00b2 when:","text":"<ul> <li>Want to know proportion of variance explained</li> <li>Comparing model performance</li> <li>Need a normalized metric</li> </ul>"},{"location":"api/metrics/#custom-metrics","title":"Custom Metrics","text":"<p>You can define custom metrics:</p> <pre><code>import numpy as np\n\ndef custom_metric(y_true, y_pred):\n    \"\"\"\n    Custom evaluation metric.\n\n    Args:\n        y_true: Ground truth values\n        y_pred: Predicted values\n\n    Returns:\n        Metric value\n    \"\"\"\n    # Your custom logic\n    error = np.abs(y_true - y_pred)\n    return np.mean(error)\n\n# Use custom metric\nscore = custom_metric(y_true, y_pred)\nprint(f\"Custom Metric: {score:.4f}\")\n</code></pre>"},{"location":"api/metrics/#aggregation-strategies","title":"Aggregation Strategies","text":""},{"location":"api/metrics/#mean-aggregation","title":"Mean Aggregation","text":"<pre><code># Average across all samples and channels\noverall_mse = np.mean((y_true - y_pred) ** 2)\n</code></pre>"},{"location":"api/metrics/#median-aggregation","title":"Median Aggregation","text":"<pre><code># Median (robust to outliers)\nmedian_ae = np.median(np.abs(y_true - y_pred))\n</code></pre>"},{"location":"api/metrics/#weighted-aggregation","title":"Weighted Aggregation","text":"<pre><code># Weight recent predictions more\nhorizon_len = y_true.shape[-1]\nweights = np.linspace(0.5, 1.0, horizon_len)  # Increasing weights\nweighted_error = np.average(\n    np.abs(y_true - y_pred),\n    axis=-1,\n    weights=weights\n)\n</code></pre>"},{"location":"api/metrics/#metric-visualization","title":"Metric Visualization","text":""},{"location":"api/metrics/#error-distribution","title":"Error Distribution","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\nerrors = y_true - y_pred\n\nplt.figure(figsize=(12, 5))\n\n# Histogram\nplt.subplot(1, 2, 1)\nplt.hist(errors.flatten(), bins=50, alpha=0.7, edgecolor='black')\nplt.xlabel(\"Prediction Error\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Error Distribution\")\nplt.axvline(x=0, color='r', linestyle='--', label='Zero Error')\nplt.legend()\n\n# Box plot per channel\nplt.subplot(1, 2, 2)\nplt.boxplot([errors[:, ch, :].flatten() for ch in range(errors.shape[1])])\nplt.xlabel(\"Channel\")\nplt.ylabel(\"Prediction Error\")\nplt.title(\"Error Distribution by Channel\")\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"api/metrics/#metric-comparison","title":"Metric Comparison","text":"<pre><code>import matplotlib.pyplot as plt\n\nmetric_names = ['MSE', 'MAE', 'RMSE', 'MAPE']\nmetric_values = [\n    mse(y_true, y_pred),\n    mae(y_true, y_pred),\n    rmse(y_true, y_pred),\n    mape(y_true, y_pred),\n]\n\n# Normalize for comparison\nnormalized_values = [v / max(metric_values) for v in metric_values]\n\nplt.figure(figsize=(10, 5))\nplt.bar(metric_names, normalized_values)\nplt.ylabel(\"Normalized Value\")\nplt.title(\"Metric Comparison (Normalized)\")\nplt.grid(axis='y', alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"api/metrics/#see-also","title":"See Also","text":"<ul> <li>Models API: Model classes and evaluation methods</li> <li>Datasets API: Dataset classes</li> <li>Examples: Complete evaluation examples</li> </ul>"},{"location":"api/models/","title":"Models API Reference","text":"<p>This page provides detailed API documentation for all model classes in Samay.</p>"},{"location":"api/models/#lptmmodel","title":"LPTMModel","text":"<p>Large Pre-trained Time Series Model for forecasting, classification, and anomaly detection.</p>"},{"location":"api/models/#samay.model.LPTMModel","title":"<code>LPTMModel(config=None)</code>","text":"<p>               Bases: <code>Basemodel</code></p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def __init__(self, config=None):\n    super().__init__(config=config, repo=None)\n    # config[\"patch_len\"] = config[\"max_patch\"]\n    self.model = LPTMPipeline.from_pretrained(\n        \"kage08/lptm-large2\", model_kwargs=self.config\n    )\n\n    self.model.init()\n</code></pre>"},{"location":"api/models/#timesfmmodel","title":"TimesfmModel","text":"<p>Google's Time Series Foundation Model for zero-shot forecasting.</p>"},{"location":"api/models/#samay.model.TimesfmModel","title":"<code>TimesfmModel(config=None, repo=None, ckpt=None, **kwargs)</code>","text":"<p>               Bases: <code>Basemodel</code></p> <p>Parameters:</p> Name Type Description Default <code>config</code> <p>dict, model configuration</p> <code>None</code> <code>repo</code> <p>str, Huggingface model repository id</p> <code>None</code> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def __init__(self, config=None, repo=None, ckpt=None, **kwargs):\n    \"\"\"\n    Args:\n        config: dict, model configuration\n        repo: str, Huggingface model repository id\n    \"\"\"\n    super().__init__(config=config, repo=repo)\n    hparams = tfm.TimesFmHparams(**self.config)\n    if repo:\n        try:\n            ckpt = tfm.TimesFmCheckpoint(huggingface_repo_id=repo)\n        except:\n            ckpt = None\n            raise ValueError(f\"Repository {repo} not found\")\n\n    self.model = tfm.TimesFm(hparams=hparams, checkpoint=ckpt)\n</code></pre>"},{"location":"api/models/#samay.model.TimesfmModel.evaluate","title":"<code>evaluate(dataset, **kwargs)</code>","text":"<p>Evaluate the model. Args:     dataset: dataset for evaluation, call get_data_loader() to get the dataloader Returns:     Dict[str, float]: evaluation metrics, including mse, mae, mase, mape, rmse, nrmse, smape, msis, nd, mwsq, crps</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def evaluate(self, dataset, **kwargs):\n    \"\"\"\n    Evaluate the model.\n    Args:\n        dataset: dataset for evaluation, call get_data_loader() to get the dataloader\n    Returns:\n        Dict[str, float]: evaluation metrics, including mse, mae, mase, mape, rmse, nrmse, smape, msis, nd, mwsq, crps\n    \"\"\"\n    dataloader = dataset.get_data_loader()\n    trues, preds, histories, quantiles, losses = [], [], [], [], []\n\n    with torch.no_grad():\n        for i, (inputs) in enumerate(dataloader):\n            inputs = dataset.preprocess(inputs)\n            input_ts = inputs[\"input_ts\"]\n            input_ts = np.squeeze(input_ts, axis=0)\n            actual_ts = inputs[\"actual_ts\"].detach().cpu().numpy()\n            actual_ts = np.squeeze(actual_ts, axis=0)\n\n            output, quantile_output = self.model.forecast(input_ts)\n            output = output[:, 0 : actual_ts.shape[1]]\n            quantile_output = quantile_output[:, 0 : actual_ts.shape[1], 1:].transpose(2, 0, 1)  # q, b, h\n\n            loss = np.mean((output - actual_ts) ** 2)\n            losses.append(loss.item())\n            trues.append(actual_ts)\n            preds.append(output)\n            histories.append(input_ts)\n            quantiles.append(quantile_output)\n\n    losses = np.array(losses)\n    average_loss = np.average(losses)\n    trues = np.concatenate(trues, axis=0).reshape(\n        -1, dataset.num_ts, trues[-1].shape[-1]\n    )\n    preds = np.concatenate(preds, axis=0).reshape(\n        -1, dataset.num_ts, preds[-1].shape[-1]\n    )\n    histories = np.concatenate(histories, axis=0).reshape(\n        -1, dataset.num_ts, histories[-1].shape[-1]\n    )\n    quantiles = np.concatenate(quantiles, axis=1).reshape(\n        quantiles[-1].shape[0], -1, dataset.num_ts, quantiles[-1].shape[-1]\n    )\n\n    # denormalize\n    if dataset.normalize:\n        trues = dataset._denormalize_data(trues)\n        preds = dataset._denormalize_data(preds)\n        histories = dataset._denormalize_data(histories)\n        new_quantiles = []\n        for i in range(quantiles.shape[0]):\n            new_quantiles.append(dataset._denormalize_data(quantiles[i]))\n        quantiles = np.array(new_quantiles)\n\n    mse = MSE(trues, preds)\n    mae = MAE(trues, preds)\n    mase = MASE(trues, preds)\n    mape = MAPE(trues, preds)\n    rmse = RMSE(trues, preds)\n    nrmse = NRMSE(trues, preds)\n    smape = SMAPE(trues, preds)\n    msis = MSIS(trues, preds)\n    nd = ND(trues, preds)\n    mwsq = MWSQ(trues, quantiles, self.config[\"quantiles\"])\n    crps = CRPS(trues, quantiles, self.config[\"quantiles\"])\n\n    return {\n        \"mse\": mse,\n        \"mae\": mae,\n        \"mase\": mase,\n        \"mape\": mape,\n        \"rmse\": rmse,\n        \"nrmse\": nrmse,\n        \"smape\": smape,\n        \"msis\": msis,\n        \"nd\": nd,\n        \"mwsq\": mwsq,\n        \"crps\": crps,\n    }\n</code></pre>"},{"location":"api/models/#samay.model.TimesfmModel.finetune","title":"<code>finetune(dataset, freeze_transformer=True, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>dataset</code> <p>dataset for finetuning, call get_data_loader() to get the dataloader</p> required <code>freeze_transformer</code> <p>bool, whether to freeze the transformer layers</p> <code>True</code> <p>Returns:     FinetuneModel: ppd.PatchedDecoderFinetuneModel, finetuned model</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def finetune(self, dataset, freeze_transformer=True, **kwargs):\n    \"\"\"\n    Args:\n        dataset: dataset for finetuning, call get_data_loader() to get the dataloader\n        freeze_transformer: bool, whether to freeze the transformer layers\n    Returns:\n        FinetuneModel: ppd.PatchedDecoderFinetuneModel, finetuned model\n    \"\"\"\n    lr = 1e-4 if \"lr\" not in kwargs else kwargs[\"lr\"]\n    epoch = 5 if \"epoch\" not in kwargs else kwargs[\"epoch\"]\n\n    core_layer_tpl = self.model._model\n    # Todo: whether add freq\n    FinetunedModel = ppd.PatchedDecoderFinetuneModel(core_layer_tpl=core_layer_tpl)\n    if freeze_transformer:\n        for param in FinetunedModel.core_layer.stacked_transformer.parameters():\n            param.requires_grad = False\n    FinetunedModel.to(self.device)\n    FinetunedModel.train()\n    dataloader = dataset.get_data_loader()\n    optimizer = torch.optim.Adam(FinetunedModel.parameters(), lr=lr)\n\n    for epoch in range(epoch):\n        avg_loss = 0\n        for i, (inputs) in enumerate(dataloader):\n            inputs = dataset.preprocess(inputs)\n            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n            optimizer.zero_grad()\n            outputs = FinetunedModel.compute_predictions(\n                inputs, train_horizon_len=self.config[\"horizon_len\"]\n            )  # b, n, seq_len, 1+quantiles\n            loss = FinetunedModel.compute_loss(outputs, inputs)\n            loss.backward()\n            optimizer.step()\n            avg_loss += loss.item()\n        avg_loss /= len(dataloader)\n        print(f\"Epoch {epoch}, Loss: {avg_loss}\")\n\n    self.model._model = FinetunedModel.core_layer\n    return self.model\n</code></pre>"},{"location":"api/models/#samay.model.TimesfmModel.forecast","title":"<code>forecast(input, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>input</code> <p>torch.Tensor, input data</p> required <p>Returns:     Tuple[torch.Tensor, torch.Tensor]:         - the mean forecast of size (# inputs, # forecast horizon),         - the full forecast (mean + quantiles) of size         (# inputs,  # forecast horizon, 1 + # quantiles).</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def forecast(self, input, **kwargs):\n    \"\"\"\n    Args:\n        input: torch.Tensor, input data\n    Returns:\n        Tuple[torch.Tensor, torch.Tensor]:\n            - the mean forecast of size (# inputs, # forecast horizon),\n            - the full forecast (mean + quantiles) of size\n            (# inputs,  # forecast horizon, 1 + # quantiles).\n    \"\"\"\n    return self.model.forecast(input)\n</code></pre>"},{"location":"api/models/#samay.model.TimesfmModel.plot","title":"<code>plot(dataset, **kwargs)</code>","text":"<p>Plot the forecast results. Args:     dataset: dataset for plotting, call get_data_loader() to get the dataloader</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def plot(self, dataset, **kwargs):\n    \"\"\"\n    Plot the forecast results.\n    Args:\n        dataset: dataset for plotting, call get_data_loader() to get the dataloader\n    \"\"\"\n    dataloader = dataset.get_data_loader()\n    trues, preds, histories, losses, quantiles = [], [], [], [], []\n    with torch.no_grad():\n        for i, (inputs) in enumerate(dataloader):\n            inputs = dataset.preprocess(inputs)\n            input_ts = inputs[\"input_ts\"]\n            input_ts = np.squeeze(input_ts, axis=0)\n            actual_ts = inputs[\"actual_ts\"].detach().cpu().numpy()\n            actual_ts = np.squeeze(actual_ts, axis=0)\n\n            output, quantile_output = self.model.forecast(input_ts)\n            output = output[:, 0 : actual_ts.shape[1]]\n\n            quantile_output = quantile_output.transpose(2, 0, 1)  # q, b, h\n            quantile_output = quantile_output[..., 0 : actual_ts.shape[1]]\n\n            loss = np.mean((output - actual_ts) ** 2)\n            losses.append(loss.item())\n            trues.append(actual_ts)\n            preds.append(output)\n            histories.append(input_ts)\n            quantiles.append(quantile_output)\n\n    losses = np.array(losses)\n    average_loss = np.average(losses)\n    trues = np.concatenate(trues, axis=0).reshape(\n        -1, dataset.num_ts, trues[-1].shape[-1]\n    )\n    preds = np.concatenate(preds, axis=0).reshape(\n        -1, dataset.num_ts, preds[-1].shape[-1]\n    )\n    histories = np.concatenate(histories, axis=0).reshape(\n        -1, dataset.num_ts, histories[-1].shape[-1]\n    )\n    quantiles = np.concatenate(quantiles, axis=1).reshape(\n        quantiles[-1].shape[0], -1, dataset.num_ts, quantiles[-1].shape[-1]\n    )\n\n    # denormalize\n    if dataset.normalize:\n        trues = dataset._denormalize_data(trues.reshape(-1, 1)).reshape(trues.shape)\n        preds = dataset._denormalize_data(preds.reshape(-1, 1)).reshape(preds.shape)\n        histories = dataset._denormalize_data(histories.reshape(-1, 1)).reshape(histories.shape)\n        quantiles = dataset._denormalize_data(quantiles.reshape(-1, 1)).reshape(quantiles.shape)\n\n    visualize(\n        task_name=\"forecasting\",\n        trues=trues,\n        preds=preds,\n        history=histories,\n        quantiles=quantiles,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/models/#momentmodel","title":"MomentModel","text":"<p>Multi-task time-series foundation model supporting forecasting, classification, detection, and imputation.</p>"},{"location":"api/models/#samay.model.MomentModel","title":"<code>MomentModel(config=None, repo=None)</code>","text":"<p>               Bases: <code>Basemodel</code></p> <p>Parameters:</p> Name Type Description Default <code>config</code> <p>dict, model configuration</p> <code>None</code> <code>repo</code> <p>str, Huggingface model repository id</p> <code>None</code> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def __init__(self, config=None, repo=None):\n    \"\"\"\n    Args:\n        config: dict, model configuration\n        repo: str, Huggingface model repository id\n    \"\"\"\n    super().__init__(config=config, repo=repo)\n    if not repo:\n        # raise ValueError(\"Moment model requires a repository\")\n        print(\"Initializing a new MOMENT model without pre-trained weights\")\n        base_config = json.load(\n            open(\"/nethome/sli999/TSFMProject/config/moment_base.json\", \"r\")\n        )\n        self.model = MOMENTPipeline(config=base_config, model_kwargs=self.config)\n    else:\n        print(f\"Loading MOMENT model from {repo}\")\n        self.model = MOMENTPipeline.from_pretrained(repo, model_kwargs=self.config)\n    self.model.init()\n</code></pre>"},{"location":"api/models/#samay.model.MomentModel.evaluate","title":"<code>evaluate(dataset, task_name='forecasting')</code>","text":"<p>Evaluate the model. Args:     dataset: dataset for evaluation, call get_data_loader() to get the dataloader     task_name: str, task name, forecasting, imputation, detection, classification Returns:     Dict[str, float]: evaluation metrics, including mse, mae, mase, mape, rmse, nrmse, smape, msis, nd, mwsq, crps</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def evaluate(self, dataset, task_name=\"forecasting\"):\n    \"\"\"\n    Evaluate the model.\n    Args:\n        dataset: dataset for evaluation, call get_data_loader() to get the dataloader\n        task_name: str, task name, forecasting, imputation, detection, classification\n    Returns:\n        Dict[str, float]: evaluation metrics, including mse, mae, mase, mape, rmse, nrmse, smape, msis, nd, mwsq, crps\n    \"\"\"\n    dataloader = dataset.get_data_loader()\n    self.model.to(self.device)\n    self.model.eval()\n    if task_name == \"forecasting\":\n        criterion = torch.nn.MSELoss()\n        trues, preds, histories, losses = [], [], [], []\n        with torch.no_grad():\n            for i, data in enumerate(dataloader):\n                # unpack the data\n                timeseries, input_mask, forecast = data\n                # Move the data to the GPU\n                timeseries = timeseries.float().to(self.device)\n                input_mask = input_mask.to(self.device)\n                forecast = forecast.float().to(self.device)\n\n                output = self.model(x_enc=timeseries, input_mask=input_mask)\n                loss = criterion(output.forecast, forecast)\n                losses.append(loss.item())\n                trues.append(forecast.detach().cpu().numpy())\n                preds.append(output.forecast.detach().cpu().numpy())\n                histories.append(timeseries.detach().cpu().numpy())\n\n        losses = np.array(losses)\n        trues = np.concatenate(trues, axis=0)\n        preds = np.concatenate(preds, axis=0)\n        histories = np.concatenate(histories, axis=0)\n\n        # denormalize\n        trues = dataset._denormalize_data(trues)\n        preds = dataset._denormalize_data(preds)\n        histories = dataset._denormalize_data(histories)\n        mse = MSE(trues, preds)\n        mae = MAE(trues, preds)\n        mase = MASE(trues, preds)\n        mape = MAPE(trues, preds)\n        rmse = RMSE(trues, preds)\n        nrmse = NRMSE(trues, preds)\n        smape = SMAPE(trues, preds)\n        msis = MSIS(trues, preds)\n        nd = ND(trues, preds)\n\n        return {\n            \"mse\": mse,\n            \"mae\": mae,\n            \"mase\": mase,\n            \"mape\": mape,\n            \"rmse\": rmse,\n            \"nrmse\": nrmse,\n            \"smape\": smape,\n            \"msis\": msis,\n            \"nd\": nd,\n        }\n\n    elif task_name == \"classification\":\n        accuracy = 0\n        total = 0\n        embeddings = []\n        labels = []\n        with torch.no_grad():\n            for i, data in enumerate(dataloader):\n                # unpack the data\n                timeseries, input_mask, label = data\n                timeseries = timeseries.to(self.device).float()\n                label = label.to(self.device).long()\n                labels.append(label.detach().cpu().numpy())\n                input_mask = input_mask.to(self.device).long()\n                output = self.model(x_enc=timeseries, input_mask=input_mask)\n                embedding = output.embeddings.mean(dim=1)\n                embeddings.append(embedding.detach().cpu().numpy())\n                _, predicted = torch.max(output.logits, 1)\n                total += label.size(0)\n                accuracy += (predicted == label).sum().item()\n\n        accuracy = accuracy / total\n        embeddings = np.concatenate(embeddings)\n        labels = np.concatenate(labels)\n        return accuracy, embeddings, labels\n</code></pre>"},{"location":"api/models/#samay.model.MomentModel.finetune","title":"<code>finetune(dataset, task_name='forecasting', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>dataset</code> <p>dataset for finetuning, call get_data_loader() to get the dataloader</p> required <code>task_name</code> <p>str, task name, forecasting, imputation, detection, classification</p> <code>'forecasting'</code> <p>Returns:     MOMENT model</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def finetune(self, dataset, task_name=\"forecasting\", **kwargs):\n    \"\"\"\n    Args:\n        dataset: dataset for finetuning, call get_data_loader() to get the dataloader\n        task_name: str, task name, forecasting, imputation, detection, classification\n    Returns:\n        MOMENT model\n    \"\"\"\n    # arguments\n    max_lr = 1e-4 if \"lr\" not in kwargs else kwargs[\"lr\"]\n    max_epoch = 5 if \"epoch\" not in kwargs else kwargs[\"epoch\"]\n    max_norm = 1.0 if \"norm\" not in kwargs else kwargs[\"norm\"]\n    mask_ratio = 0.25 if \"mask_ratio\" not in kwargs else kwargs[\"mask_ratio\"]\n\n    if task_name == \"imputation\" or task_name == \"detection\":\n        mask_generator = Masking(mask_ratio=mask_ratio)\n\n    dataloader = dataset.get_data_loader()\n    criterion = torch.nn.MSELoss()\n    if task_name == \"classification\":\n        criterion = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(self.model.parameters(), lr=max_lr)\n    criterion.to(self.device)\n    scaler = torch.amp.GradScaler()\n\n    total_steps = len(dataloader) * max_epoch\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer, max_lr=max_lr, total_steps=total_steps, pct_start=0.3\n    )\n    self.model.to(self.device)\n    self.model.train()\n\n    for epoch in range(max_epoch):\n        losses = []\n        for i, data in enumerate(dataloader):\n            # unpack the data\n            if task_name == \"forecasting\":\n                timeseries, input_mask, forecast = data\n                # Move the data to the GPU\n                timeseries = timeseries.float().to(self.device)\n                input_mask = input_mask.to(self.device)\n                forecast = forecast.float().to(self.device)\n                # with torch.amp.autocast(device_type='cuda'):\n                output = self.model(x_enc=timeseries, input_mask=input_mask)\n                loss = criterion(output.forecast, forecast)\n\n            elif task_name == \"imputation\":\n                timeseries, input_mask = data\n                n_channels = timeseries.shape[1]\n                # Move the data to the GPU\n                timeseries = timeseries.float().to(self.device)\n                timeseries = timeseries.reshape(-1, 1, timeseries.shape[-1])\n                input_mask = input_mask.to(self.device).long()\n                input_mask = input_mask.repeat_interleave(n_channels, axis=0)\n                mask = (\n                    mask_generator.generate_mask(\n                        x=timeseries, input_mask=input_mask\n                    )\n                    .to(self.device)\n                    .long()\n                )\n                output = self.model(\n                    x_enc=timeseries, input_mask=input_mask, mask=mask\n                )\n                # with torch.amp.autocast(device_type='cuda'):\n                recon_loss = criterion(output.reconstruction, timeseries)\n                observed_mask = input_mask * (1 - mask)\n                masked_loss = observed_mask * recon_loss\n                loss = masked_loss.nansum() / (observed_mask.nansum() + 1e-7)\n\n            elif task_name == \"detection\":\n                timeseries, input_mask, label = data\n                n_channels = timeseries.shape[1]\n                seq_len = timeseries.shape[-1]\n                timeseries = (\n                    timeseries.reshape(-1, 1, seq_len).float().to(self.device)\n                )\n                input_mask = input_mask.to(self.device).long()\n                input_mask = input_mask.repeat_interleave(n_channels, axis=0)\n                mask = (\n                    mask_generator.generate_mask(\n                        x=timeseries, input_mask=input_mask\n                    )\n                    .to(self.device)\n                    .long()\n                )\n                output = self.model(\n                    x_enc=timeseries, input_mask=input_mask, mask=mask\n                )\n                # with torch.amp.autocast(device_type='cuda'):\n                loss = criterion(output.reconstruction, timeseries)\n\n            elif task_name == \"classification\":\n                timeseries, input_mask, label = data\n                timeseries = timeseries.to(self.device).float()\n                label = label.to(self.device).long()\n                output = self.model(x_enc=timeseries)\n                # with torch.amp.autocast(device_type='cuda'):\n                loss = criterion(output.logits, label)\n\n            optimizer.zero_grad(set_to_none=True)\n            # Scales the loss for mixed precision training\n            scaler.scale(loss).backward()\n\n            # Clip gradients\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm)\n\n            scaler.step(optimizer)\n            scaler.update()\n\n            losses.append(loss.item())\n\n        losses = np.array(losses)\n        average_loss = np.average(losses)\n        print(f\"Epoch {epoch}: Train loss: {average_loss:.3f}\")\n\n        scheduler.step()\n\n    return self.model\n</code></pre>"},{"location":"api/models/#samay.model.MomentModel.plot","title":"<code>plot(dataset, task_name='forecasting')</code>","text":"<p>Plot the forecast results. Args:     dataset: dataset for plotting, call get_data_loader() to get the dataloader     task_name: str, task name, forecasting, imputation, detection, classification</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def plot(self, dataset, task_name=\"forecasting\"):\n    \"\"\"\n    Plot the forecast results.\n    Args:\n        dataset: dataset for plotting, call get_data_loader() to get the dataloader\n        task_name: str, task name, forecasting, imputation, detection, classification\n    \"\"\"\n    dataloader = dataset.get_data_loader()\n    criterion = torch.nn.MSELoss()\n    self.model.to(self.device)\n    self.model.eval()\n    if task_name == \"forecasting\":\n        trues, preds, histories, losses = [], [], [], []\n        with torch.no_grad():\n            for i, data in enumerate(dataloader):\n                # unpack the data\n                timeseries, input_mask, forecast = data\n                # Move the data to the GPU\n                timeseries = timeseries.float().to(self.device)\n                input_mask = input_mask.to(self.device)\n                forecast = forecast.float().to(self.device)\n\n                output = self.model(x_enc=timeseries, input_mask=input_mask)\n                loss = criterion(output.forecast, forecast)\n                losses.append(loss.item())\n                trues.append(forecast.detach().cpu().numpy())\n                preds.append(output.forecast.detach().cpu().numpy())\n                histories.append(timeseries.detach().cpu().numpy())\n\n        losses = np.array(losses)\n        average_loss = np.average(losses)\n        trues = np.concatenate(trues, axis=0)\n        preds = np.concatenate(preds, axis=0)\n        histories = np.concatenate(histories, axis=0)\n\n        visualize(\n            task_name=\"forecasting\", trues=trues, preds=preds, history=histories\n        )\n\n        # return average_loss, trues, preds, histories\n\n    elif task_name == \"imputation\":\n        trues, preds, masks = [], [], []\n        mask_generator = Masking(mask_ratio=0.25)\n        with torch.no_grad():\n            for i, data in enumerate(dataloader):\n                # unpack the data\n                timeseries, input_mask = data\n                trues.append(timeseries.numpy())\n                n_channels = timeseries.shape[1]\n                # Move the data to the GPU\n                timeseries = timeseries.float().to(self.device)\n                timeseries = timeseries.reshape(-1, 1, timeseries.shape[-1])\n                # print(input_mask.shape)\n                input_mask = input_mask.to(self.device).long()\n                input_mask = input_mask.repeat_interleave(n_channels, axis=0)\n                # print(timeseries.shape, input_mask.shape)\n                mask = (\n                    mask_generator.generate_mask(\n                        x=timeseries, input_mask=input_mask\n                    )\n                    .to(self.device)\n                    .long()\n                )\n                output = self.model(\n                    x_enc=timeseries, input_mask=input_mask, mask=mask\n                )\n                reconstruction = output.reconstruction.reshape(\n                    -1, n_channels, timeseries.shape[-1]\n                )\n                mask = mask.reshape(-1, n_channels, timeseries.shape[-1])\n                preds.append(reconstruction.detach().cpu().numpy())\n                masks.append(mask.detach().cpu().numpy())\n\n        trues = np.concatenate(trues, axis=0)\n        preds = np.concatenate(preds, axis=0)\n        masks = np.concatenate(masks, axis=0)\n\n        visualize(task_name=\"imputation\", trues=trues, preds=preds, masks=masks)\n\n        # return trues, preds, masks\n\n    elif task_name == \"detection\":\n        trues, preds, labels = [], [], []\n        with torch.no_grad():\n            for i, data in enumerate(dataloader):\n                # unpack the data\n                timeseries, input_mask, label = data\n                timeseries = timeseries.to(self.device).float()\n                input_mask = input_mask.to(self.device).long()\n                label = label.to(self.device).long()\n                output = self.model(x_enc=timeseries, input_mask=input_mask)\n\n                trues.append(timeseries.detach().cpu().numpy())\n                preds.append(output.reconstruction.detach().cpu().numpy())\n                labels.append(label.detach().cpu().numpy())\n\n        trues = np.concatenate(trues, axis=0).flatten()\n        preds = np.concatenate(preds, axis=0).flatten()\n        labels = np.concatenate(labels, axis=0).flatten()\n\n        visualize(task_name=\"detection\", trues=trues, preds=preds, labels=labels, pad_len=dataset.pad_len)\n</code></pre>"},{"location":"api/models/#chronosmodel","title":"ChronosModel","text":"<p>Language model-based time-series forecasting with tokenization.</p>"},{"location":"api/models/#samay.model.ChronosModel","title":"<code>ChronosModel(config=None, repo=None)</code>","text":"<p>               Bases: <code>Basemodel</code></p> <p>Parameters:</p> Name Type Description Default <code>config</code> <p>dict, model configuration</p> <code>None</code> <code>repo</code> <p>str, Huggingface model repository id</p> <code>None</code> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def __init__(self, config=None, repo=None):\n    \"\"\"\n    Args:\n        config: dict, model configuration\n        repo: str, Huggingface model repository id\n    \"\"\"\n    super().__init__(config=config, repo=repo)\n    if repo:\n        print(\"Loading Chronos model from Huggingface repository\")\n        try:\n            self.pipeline = ChronosPipeline.from_pretrained(\n                repo, device_map=self.device\n            )\n        except:\n            raise ValueError(f\"Repository {repo} not found\")\n    else:\n        print(\"Initializing a new Chronos model without pre-trained weights\")\n        self.pipeline = ChronosPipeline(config=ChronosConfig(**config))\n</code></pre>"},{"location":"api/models/#samay.model.ChronosModel.evaluate","title":"<code>evaluate(dataset, horizon_len, quantile_levels, **kwargs)</code>","text":"<p>Evaluate the model. Args:     dataset: dataset for evaluation, call get_data_loader() to get the dataloader     horizon_len: int, forecast horizon length     quantile_levels: list, list of quantile levels Returns:     Dict[str, float]: evaluation metrics, including mse, mae, mase, mape, rmse, nrmse, smape, msis, nd, mwsq, crps</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def evaluate(self, dataset, horizon_len, quantile_levels, **kwargs):\n    \"\"\"\n    Evaluate the model.\n    Args:\n        dataset: dataset for evaluation, call get_data_loader() to get the dataloader\n        horizon_len: int, forecast horizon length\n        quantile_levels: list, list of quantile levels\n    Returns:\n        Dict[str, float]: evaluation metrics, including mse, mae, mase, mape, rmse, nrmse, smape, msis, nd, mwsq, crps\n    \"\"\"\n    dataloader = dataset.get_data_loader()\n    trues, preds, histories, quantile_forecasts = [], [], [], []\n    for i, data in enumerate(dataloader):\n        input_seq = data[\"input_seq\"]\n        forecast_seq = data[\"forecast_seq\"]\n        shape = input_seq.shape\n        input_seq = input_seq.reshape(shape[0] * shape[1], shape[2])\n        input_seq = torch.tensor(input_seq)\n        quantiles, mean = self.pipeline.predict_quantiles(\n            context=input_seq,\n            prediction_length=horizon_len,\n            quantile_levels=quantile_levels,\n            limit_prediction_length=False,\n        )\n        trues.append(forecast_seq.detach().cpu().numpy())\n        mean = mean.reshape(\n            forecast_seq.shape[0], forecast_seq.shape[1], forecast_seq.shape[2]\n        )\n        preds.append(mean.detach().cpu().numpy())\n        quantiles = quantiles.reshape(\n            quantiles.shape[-1],\n            forecast_seq.shape[0],\n            forecast_seq.shape[1],\n            forecast_seq.shape[2],\n        )\n        quantile_forecasts.append(quantiles.detach().cpu().numpy())\n        input_seq = input_seq.reshape(shape[0], shape[1], shape[2])\n        histories.append(input_seq.detach().cpu().numpy())\n\n    trues = np.concatenate(trues, axis=0)\n    preds = np.concatenate(preds, axis=0)\n    histories = np.concatenate(histories, axis=0)\n    quantile_forecasts = np.concatenate(quantile_forecasts, axis=1)\n\n    mse = MSE(trues, preds)\n    mae = MAE(trues, preds)\n    mase = MASE(trues, preds)\n    mape = MAPE(trues, preds)\n    rmse = RMSE(trues, preds)\n    nrmse = NRMSE(trues, preds)\n    smape = SMAPE(trues, preds)\n    msis = MSIS(trues, preds)\n    nd = ND(trues, preds)\n    mwsq = MWSQ(trues, quantile_forecasts, quantile_levels)\n    crps = CRPS(trues, quantile_forecasts, quantile_levels)\n\n    return {\n        \"mse\": mse,\n        \"mae\": mae,\n        \"mase\": mase,\n        \"mape\": mape,\n        \"rmse\": rmse,\n        \"nrmse\": nrmse,\n        \"smape\": smape,\n        \"msis\": msis,\n        \"nd\": nd,\n        \"mwsq\": mwsq,\n        \"crps\": crps,\n    }\n</code></pre>"},{"location":"api/models/#samay.model.ChronosModel.finetune","title":"<code>finetune(dataset, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>dataset</code> <p>dataset for finetuning, call get_data_loader() to get the dataloader</p> required Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def finetune(self, dataset, **kwargs):\n    \"\"\"\n    Args:\n        dataset: dataset for finetuning, call get_data_loader() to get the dataloader\n    \"\"\"\n    # Todo: finetune model\n    finetune_model = self.pipeline.model.model\n    dataloader = dataset.get_data_loader()\n    finetune_model.to(self.device)\n    finetune_model.train()\n    optimizer = torch.optim.AdamW(finetune_model.parameters(), lr=1e-4)\n\n    avg_loss = 0\n\n    for epoch in range(5):\n        for i, data in enumerate(dataloader):\n            input_ids = data[\"input_ids\"].to(self.device)\n            ids_shape = input_ids.shape\n            input_ids = input_ids.reshape(ids_shape[0] * ids_shape[1], ids_shape[2])\n            attention_mask = data[\"attention_mask\"].to(self.device)\n            mask_shape = attention_mask.shape\n            attention_mask = attention_mask.reshape(\n                mask_shape[0] * mask_shape[1], mask_shape[2]\n            )\n            labels = data[\"labels\"].to(self.device)\n            label_shape = labels.shape\n            labels = labels.reshape(label_shape[0] * label_shape[1], label_shape[2])\n            optimizer.zero_grad()\n            output = finetune_model(\n                input_ids, attention_mask=attention_mask, labels=labels\n            )\n            loss = output.loss\n            loss.backward()\n            optimizer.step()\n            avg_loss += loss.item()\n        avg_loss /= len(dataloader)\n        print(f\"Epoch {epoch}, Loss: {avg_loss}\")\n\n    finetune_model.eval()\n</code></pre>"},{"location":"api/models/#samay.model.ChronosModel.plot","title":"<code>plot(dataset, horizon_len, quantile_levels, **kwargs)</code>","text":"<p>Plot the forecast results. Args:     dataset: dataset for plotting, call get_data_loader() to get the dataloader     horizon_len: int, forecast horizon length     quantile_levels: list, list of quantile levels</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def plot(self, dataset, horizon_len, quantile_levels, **kwargs):\n    \"\"\"\n    Plot the forecast results.\n    Args:\n        dataset: dataset for plotting, call get_data_loader() to get the dataloader\n        horizon_len: int, forecast horizon length\n        quantile_levels: list, list of quantile levels\n    \"\"\"\n    # Todo: forecast\n    dataloader = dataset.get_data_loader()\n    trues, preds, histories, quantiles = [], [], [], []\n    for i, data in enumerate(dataloader):\n        input_seq = data[\"input_seq\"]\n        forecast_seq = data[\"forecast_seq\"]\n        shape = input_seq.shape\n        input_seq = input_seq.reshape(shape[0] * shape[1], shape[2])\n        input_seq = torch.tensor(input_seq)\n        quantile_outputs, mean = self.pipeline.predict_quantiles(\n            context=input_seq,\n            prediction_length=horizon_len,\n            quantile_levels=quantile_levels,\n        )\n        trues.append(forecast_seq.detach().cpu().numpy())\n        mean = mean.reshape(\n            forecast_seq.shape[0], forecast_seq.shape[1], forecast_seq.shape[2]\n        )\n        preds.append(mean.detach().cpu().numpy())\n        input_seq = input_seq.reshape(shape[0], shape[1], shape[2])\n        histories.append(input_seq.detach().cpu().numpy())\n        quantiles.append(quantile_outputs.detach().cpu().numpy().transpose(2, 0, 1))  # q, b, h\n\n    trues = np.concatenate(trues, axis=0)\n    preds = np.concatenate(preds, axis=0)\n    histories = np.concatenate(histories, axis=0)\n    quantiles = np.concatenate(quantiles, axis=1)\n\n    visualize(\n        task_name=\"forecasting\",\n        trues=trues,\n        preds=preds,\n        history=histories,\n        quantiles=quantiles,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/models/#moiraitsmodel","title":"MoiraiTSModel","text":"<p>Salesforce's universal time series forecasting transformer.</p>"},{"location":"api/models/#samay.model.MoiraiTSModel","title":"<code>MoiraiTSModel(config=None, repo=None, model_type='moirai-moe', model_size='small', **kwargs)</code>","text":"<p>               Bases: <code>Basemodel</code></p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def __init__(\n    self,\n    config=None,\n    repo=None,\n    model_type=\"moirai-moe\",\n    model_size=\"small\",\n    **kwargs,\n):\n    super().__init__(config=config, repo=repo)\n    # config.get(&lt;key&gt;, &lt;default_value&gt; if key not found)\n    self.model_type = config.get(\"model_type\", model_type)\n    self.horizon_len = config.get(\"horizon_len\", 32)\n    self.context_len = config.get(\"context_len\", 128)\n    self.patch_size = config.get(\"patch_size\", 16)\n    self.batch_size = config.get(\"batch_size\", 16)\n    self.quantiles = config.get(\"quantiles\", [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]) if self.model_type == \"moirai2\" else []\n    self.num_samples = config.get(\"num_samples\", 100) if self.model_type != \"moirai2\" else len(self.quantiles)    # for moirai2, we regard num_samples as the number of quantiles\n    self.target_dim = config.get(\"target_dim\", 1)\n    self.feat_dynamic_real_dim = config.get(\"feat_dynamic_real_dim\", 0)\n    self.past_feat_dynamic_real_dim = config.get(\"past_feat_dynamic_real_dim\", 0)\n    self.finetuned_model = None\n\n    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    if self.model_type == \"moirai\":  # standard moirai\n        if repo is None:\n            repo = f\"Salesforce/moirai-1.1-R-{model_size}\"\n        self.repo = repo\n\n        self.model = MoiraiForecast(\n            module=MoiraiModule.from_pretrained(self.repo),\n            prediction_length=self.horizon_len,\n            context_length=self.context_len,\n            patch_size=self.patch_size,\n            num_samples=self.num_samples,\n            target_dim=self.target_dim,\n            feat_dynamic_real_dim=self.feat_dynamic_real_dim,\n            past_feat_dynamic_real_dim=self.past_feat_dynamic_real_dim,\n        )\n\n    elif self.model_type == \"moirai-moe\":  # moirai with Mixture of Experts\n        if repo is None:\n            repo = f\"Salesforce/moirai-moe-1.0-R-{model_size}\"\n        self.repo = repo\n\n        self.model = MoiraiMoEForecast(\n            module=MoiraiMoEModule.from_pretrained(self.repo),\n            prediction_length=self.horizon_len,\n            context_length=self.context_len,\n            patch_size=self.patch_size,\n            num_samples=self.num_samples,\n            target_dim=self.target_dim,\n            feat_dynamic_real_dim=self.feat_dynamic_real_dim,\n            past_feat_dynamic_real_dim=self.past_feat_dynamic_real_dim,\n        )\n\n    elif self.model_type == \"moirai2\":\n        if repo is None:\n            repo = f\"Salesforce/moirai-2.0-R-{model_size}\"\n        self.repo = repo\n\n        self.model = Moirai2Forecast(\n            module=Moirai2Module.from_pretrained(self.repo),\n            prediction_length=self.horizon_len,\n            context_length=self.context_len,\n            target_dim=self.target_dim,\n            feat_dynamic_real_dim=self.feat_dynamic_real_dim,\n            past_feat_dynamic_real_dim=self.past_feat_dynamic_real_dim,\n        )\n    self.model.to(self.device)\n</code></pre>"},{"location":"api/models/#samay.model.MoiraiTSModel.evaluate","title":"<code>evaluate(dataset: MoiraiDataset, metrics: list[str] = ['MSE'], output_transforms: transforms.Compose = None, num_sample_flag: bool = False, zero_shot: bool = True, leaderboard: bool = False, **kwargs)</code>","text":"<p>For a given test dataset, we evaluate the model using the given metrics.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>MoiraiDataset</code> <p>Dataset to evaluate the model on.</p> required <code>metrics</code> <code>list</code> <p>Metrics you want to evaluate the model on. Defaults to [\"MSE\"].</p> <code>['MSE']</code> <code>output_transforms</code> <code>Compose</code> <p>A set of transforms to be applied on the model output. Defaults to None.</p> <code>None</code> <code>num_sample_flage</code> <code>bool</code> <p>If True, the model will use number of samples to sample from the distribution for forecasting. Defaults to False.</p> required <code>zero_shot</code> <code>bool</code> <p>If True, the standard model will be used, else the finetuned model will be used. Defaults to True.</p> <code>True</code> <code>leaderboard</code> <code>bool</code> <p>If True, only the metrics will be returned. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>Any metric other than \"MSE\" or \"MASE is not supported.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Evaluation results for each column (variate).</p> <code>dict</code> <p>True values for each column (variate).</p> <code>dict</code> <p>Predictions for each column (variate).</p> <code>dict</code> <p>Histories for each column (variate).</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def evaluate(\n    self,\n    dataset: MoiraiDataset,\n    metrics: list[str] = [\"MSE\"],\n    output_transforms: transforms.Compose = None,\n    num_sample_flag: bool = False,\n    zero_shot: bool = True,\n    leaderboard: bool = False,\n    **kwargs,\n):\n    \"\"\"For a given test dataset, we evaluate the model using the given metrics.\n\n    Args:\n        dataset (MoiraiDataset): Dataset to evaluate the model on.\n        metrics (list, optional): Metrics you want to evaluate the model on. Defaults to [\"MSE\"].\n        output_transforms (transforms.Compose, optional): A set of transforms to be applied on the model output. Defaults to None.\n        num_sample_flage (bool, optional): If True, the model will use number of samples to sample from the distribution for forecasting. Defaults to False.\n        zero_shot (bool, optional): If True, the standard model will be used, else the finetuned model will be used. Defaults to True.\n        leaderboard (bool, optional): If True, only the metrics will be returned. Defaults to False.\n\n    Raises:\n        ValueError: Any metric other than \"MSE\" or \"MASE is not supported.\n\n    Returns:\n        dict: Evaluation results for each column (variate).\n        dict: True values for each column (variate).\n        dict: Predictions for each column (variate).\n        dict: Histories for each column (variate).\n    \"\"\"\n    # required fields for the forecast\n    inp_names = [\n        \"past_target\",\n        \"past_observed_target\",\n        \"past_is_pad\",\n    ]\n    if self.feat_dynamic_real_dim &gt; 0:\n        inp_names.extend([\"feat_dynamic_real\", \"observed_feat_dynamic_real\"])\n    if self.past_feat_dynamic_real_dim &gt; 0:\n        inp_names.extend(\n            [\"past_feat_dynamic_real\", \"past_observed_feat_dynamic_real\"]\n        )\n\n    # get the batched data\n    inference_loader = dataset.get_dataloader()\n\n    # set model in eval mode\n    self.model.eval()\n\n    # predict\n    forecast = []\n    with torch.no_grad():\n        for batch in inference_loader:\n            for k, v in batch.items():\n                if isinstance(v, torch.Tensor):\n                    batch[k] = v.to(self.device)\n            inputs = filter_dict(batch, inp_names)\n            if (\n                zero_shot\n            ):  # Finetune forward asks for keys like target, observed_mask, etc.\n                outputs = (\n                    self.model.forward(**inputs).detach().cpu().numpy()\n                )  # convert the tensor output to numpy array\n            elif not zero_shot and self.finetuned_model is not None:\n                # get the context and prediction token lengths\n                context_token_len = math.ceil(self.context_len / self.patch_size)\n                pred_token_len = math.ceil(self.horizon_len / self.patch_size)\n                num_context_tokens = context_token_len * self.target_dim\n                num_pred_tokens = pred_token_len * self.target_dim\n                num_token_generate = self.model.module.num_predict_token if self.model_type == 'moirai2' else 1\n\n                # prepare the inputs\n                pred_index = torch.arange(\n                    start=context_token_len - 1,\n                    end=num_context_tokens,\n                    step=context_token_len,\n                )\n                assign_index = torch.arange(\n                    start=num_context_tokens,\n                    end=num_context_tokens + num_pred_tokens,\n                    step=pred_token_len,\n                )\n\n                old_keys = list(inputs.keys())\n                inputs = self.preprocess_inputs(inputs)\n                new_keys = list(inputs.keys())\n                inputs = filter_dict(inputs, list(set(new_keys) - set(old_keys)))\n                for k, v in inputs.items():\n                    if isinstance(v, torch.Tensor):\n                        inputs[k] = v.to(self.device)\n\n                if self.model_type == \"moirai2\":\n                    quantile_prediction = repeat(\n                        inputs[\"target\"],\n                        \"... patch_size -&gt; ... num_quantiles patch_size\",\n                        num_quantiles=len(self.model.module.quantile_levels),\n                        patch_size=self.model.module.patch_size,\n                    ).clone()\n\n                # get the forecast\n                if pred_token_len &lt;= num_token_generate:\n                    if self.model_type in [\"moirai\", \"moirai-moe\"]:\n                        # old version models generate distribution outputs\n                        distr = self.finetuned_model.forward(**inputs)\n                        preds = distr.sample(torch.Size((self.num_samples,)))\n                        preds[..., assign_index, :] = preds[..., pred_index, :]\n                        outputs = self._format_preds(\n                            preds=preds,\n                            context_token_len=context_token_len,\n                            pred_token_len=pred_token_len,\n                        )\n\n                    elif self.model_type == \"moirai2\":\n                        # new version model directly generates prediction outputs\n                        preds = self.finetuned_model.forward(**inputs)  # (batch, all_pred_idx, num_tokens*quantiles*patch_size) # all_pred_idx = (c1/ps, c2/ps, ..., cN/ps, p1/ps, p2/ps, ..., pM/ps)\n                        preds, adjusted_assign_index = self.structure_multi_predict(\n                            per_var_predict_token=pred_token_len,\n                            pred_index=pred_index,\n                            assign_index=assign_index,\n                            preds=preds,\n                        )\n                        quantile_prediction[..., adjusted_assign_index, :, :] = preds\n                        outputs = self._format_preds(\n                            preds=quantile_prediction,\n                            context_token_len=context_token_len,\n                            pred_token_len=pred_token_len,\n                            quantile_prediction=True,\n                            target_dim=self.target_dim,\n                        )\n                else:\n                    if self.model_type in [\"moirai\", \"moirai-moe\"]:\n                        # old version models generate distribution outputs\n                        distr = self.finetuned_model.forward(**inputs)\n                        preds = distr.sample(torch.Size((self.num_samples,))) # (num_samples, batch, combine_seq, patch), combined_seq = all pred index\n                    elif self.model_type == \"moirai2\":\n                        # new version model directly generates prediction outputs\n                        preds = self.finetuned_model.forward(**inputs)  # (batch, all_pred_idx, num_tokens*quantiles*patch_size)\n                        preds, adjusted_assign_index = self.structure_multi_predict(\n                            self.model.module.num_predict_token,\n                            pred_index,\n                            assign_index,\n                            preds,\n                        )\n                        quantile_prediction[..., adjusted_assign_index, :, :] = preds\n\n                    expand_target = (\n                        inputs[\"target\"]\n                        .unsqueeze(0)\n                        .repeat(self.num_samples, 1, 1, 1)\n                    )\n                    if self.model_type == \"moirai2\":\n                        expand_target = expand_target.permute(1, 0, 2, 3)  # (batch, num_samples, seq_len, patch_size), here num_samples = num_quantiles\n                    expand_prediction_mask = (\n                        inputs[\"prediction_mask\"]\n                        .unsqueeze(0)\n                        .repeat(self.num_samples, 1, 1)\n                    )\n                    if self.model_type == \"moirai2\":\n                        expand_prediction_mask = expand_prediction_mask.permute(1, 0, 2)  # (batch, num_samples, seq_len), here num_samples = num_quantiles\n                    expand_observed_mask = (\n                        inputs[\"observed_mask\"]\n                        .unsqueeze(0)\n                        .expand(self.num_samples, -1, -1, -1)\n                    )\n                    if self.model_type == \"moirai2\":\n                        expand_observed_mask = expand_observed_mask.permute(1, 0, 2, 3)  # (batch, num_samples, seq_len, patch_size), here num_samples = num_quantiles\n                    expand_sample_id = (\n                        inputs[\"sample_id\"]\n                        .unsqueeze(0)\n                        .expand(self.num_samples, -1, -1)\n                    )\n                    if self.model_type == \"moirai2\":\n                        expand_sample_id = expand_sample_id.permute(1, 0, 2)  # (batch, num_samples, seq_len), here num_samples = num_quantiles\n                    expand_time_id = (\n                        inputs[\"time_id\"]\n                        .unsqueeze(0)\n                        .expand(self.num_samples, -1, -1)\n                    )\n                    if self.model_type == \"moirai2\":\n                        expand_time_id = expand_time_id.permute(1, 0, 2)  # (batch, num_samples, seq_len), here num_samples = num_quantiles\n                    expand_variate_id = (\n                        inputs[\"variate_id\"]\n                        .unsqueeze(0)\n                        .expand(self.num_samples, -1, -1)\n                    )\n                    if self.model_type == \"moirai2\":\n                        expand_variate_id = expand_variate_id.permute(1, 0, 2)  # (batch, num_samples, seq_len), here num_samples = num_quantiles\n                    expand_patch_size = (\n                        inputs[\"patch_size\"]\n                        .unsqueeze(0)\n                        .expand(self.num_samples, -1, -1)\n                    )\n\n                    if self.model_type == \"moirai2\":\n                        expand_target[..., adjusted_assign_index, :, :] = preds.permute(0, 2, 1, 3)  # (batch, num_quantiles, seq_len, patch_size)\n                        expand_prediction_mask[..., adjusted_assign_index] = False\n                    else:\n                        expand_target[..., assign_index, :] = preds[..., pred_index, :]\n                        expand_prediction_mask[..., assign_index] = False\n\n                    remain_step = pred_token_len - num_token_generate\n                    while remain_step &gt; 0:\n                        if self.model_type == \"moirai2\":\n                            preds = self.model.module(\n                                expand_target,\n                                expand_observed_mask,\n                                expand_sample_id,\n                                expand_time_id,\n                                expand_variate_id,\n                                expand_prediction_mask,\n                                training_mode=False,\n                            )\n                            pred_index = assign_index + self.model.module.num_predict_token - 1\n                            assign_index = pred_index + 1\n                            preds, adjusted_assign_index = self.structure_multi_predict(\n                                (\n                                    self.model.module.num_predict_token\n                                    if remain_step - self.model.module.num_predict_token &gt; 0\n                                    else remain_step\n                                ),\n                                pred_index,\n                                assign_index,\n                                preds,\n                            )\n                            quantile_prediction_next_step = rearrange(\n                                preds,\n                                \"... num_quantiles_prev pred_index num_quantiles patch_size -&gt; ... pred_index (num_quantiles_prev num_quantiles) patch_size\",\n                                num_quantiles=self.model.module.num_quantiles,\n                                patch_size=self.model.module.patch_size,\n                            )\n                            # compute quantile forecast based on quantile forecast from quantile samples\n                            quantile_prediction_next_step = torch.quantile(\n                                quantile_prediction_next_step,\n                                torch.tensor(\n                                    self.model.module.quantile_levels,\n                                    device=self.device,\n                                    dtype=torch.float32,\n                                ),\n                                dim=-2,\n                            )\n                            quantile_prediction[..., adjusted_assign_index, :, :] = rearrange(\n                                quantile_prediction_next_step,\n                                \"num_quantiles ... patch_size -&gt; ... num_quantiles patch_size\",\n                            )\n\n                            # choose current quantiles values as point forecast for next-step prediction\n                            expand_target[..., adjusted_assign_index, :] = rearrange(\n                                quantile_prediction_next_step,\n                                \"num_quantiles batch_size predict_token patch_size -&gt; batch_size num_quantiles predict_token patch_size\",\n                                num_quantiles=self.model.module.num_quantiles,\n                                patch_size=self.model.module.patch_size,\n                                predict_token=len(adjusted_assign_index),\n                            )\n                            expand_prediction_mask[..., adjusted_assign_index] = False\n\n                            remain_step -= self.model.module.num_predict_token\n                        else:\n                            distr = self.finetuned_model.forward(\n                                expand_target,\n                                expand_observed_mask,\n                                expand_sample_id,\n                                expand_time_id,\n                                expand_variate_id,\n                                expand_prediction_mask,\n                                expand_patch_size,\n                            )\n                            preds = distr.sample(torch.Size((1,)))\n                            _, _, bs, token, ps = preds.shape\n                            preds = preds.view(-1, bs, token, ps)\n\n                            pred_index = assign_index\n                            assign_index = assign_index + 1\n                            expand_target[..., assign_index, :] = preds[\n                                ..., pred_index, :\n                            ]\n                            expand_prediction_mask[..., assign_index] = False\n\n                            remain_step -= 1\n\n                    if self.model_type == \"moirai2\":\n                        outputs = self._format_preds(\n                            preds=quantile_prediction,\n                            context_token_len=context_token_len,\n                            pred_token_len=pred_token_len,\n                            quantile_prediction=True,\n                            target_dim=self.target_dim,\n                        )\n                    else:\n                        outputs = self._format_preds(\n                            preds=expand_target,\n                            context_token_len=context_token_len,\n                            pred_token_len=pred_token_len,\n                        )\n\n            # Apply output transforms\n            if output_transforms is not None:\n                outputs = output_transforms(outputs)\n\n            # sample if needed\n            if num_sample_flag:\n                num_collected_samples = outputs[0].shape[0]\n                collected_samples = [outputs]\n                # do so until we have enough samples\n                while num_collected_samples &lt; self.num_samples:\n                    outputs = self.model.forward(**inputs).detach().cpu().numpy()\n                    # Apply output transforms\n                    if output_transforms is not None:\n                        outputs = output_transforms(outputs)\n                    collected_samples.append(outputs)\n                    num_collected_samples += outputs[0].shape[0]\n                # stack the collected samples\n                outputs = np.stack(\n                    [\n                        np.concatenate(s)[: self.num_samples]\n                        for s in zip(*collected_samples)\n                    ]\n                )\n                # assert that we have the right number of samples\n                assert len(outputs[0]) == self.num_samples, (\n                    \"We do not have enough samples\"\n                )\n            forecast.extend([np.array(x) for x in outputs.tolist()])\n\n    # Iterators for input, label and forecast\n    print(\"Forecasting done....now testing\")\n    input_it = iter(dataset.dataset.input)\n    label_it = iter(dataset.dataset.label)\n    forecast_it = iter(forecast)\n    # Quantile levels obtained from cli/conf/eval/default.yaml of MOIRAI repository\n    if self.model_type == \"moirai2\":\n        quantile_levels = self.quantiles\n    else:\n        quantile_levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n\n    trues = {}\n    preds = {}\n    histories = {}\n    quantile_preds = {}\n    eval_windows = []\n\n    with torch.no_grad():  # No need to compute gradients\n        # Iterate over each window\n        for input, label, forecast in zip(input_it, label_it, forecast_it):\n            true_values = (\n                label[\"target\"].squeeze()\n                if isinstance(label[\"target\"], np.ndarray)\n                else np.array(label[\"target\"])\n            )\n            past_values = (\n                input[\"target\"].squeeze()\n                if isinstance(input[\"target\"], np.ndarray)\n                else np.array(input[\"target\"])\n            )\n            if self.model_type == 'moirai2':\n                quantiles = np.array(forecast)\n                if len(quantiles.shape) == 3:  # (quantiles, horizon, target_dim)\n                    quantiles = quantiles[: len(quantile_levels), : min(self.horizon_len, true_values.shape[0]), :]  # (quantiles, horizon, target_dim)\n                elif len(quantiles.shape) == 2:  # (quantiles, horizon)\n                    quantiles = quantiles[: len(quantile_levels), : min(self.horizon_len, true_values.shape[0])]  # (quantiles, horizon)\n            else:\n                quantiles = np.percentile(\n                    forecast[:, : min(self.horizon_len, true_values.shape[0])],\n                    [q * 100 for q in quantile_levels],\n                    axis=0,\n                )\n            pred_values = np.median(forecast, axis=0)[\n                : min(self.horizon_len, true_values.shape[0])\n            ]  # Median of the forecasted values\n\n            length = len(past_values)\n\n            eval = []\n            for metric in metrics:\n                if metric == \"MSE\":\n                    eval.append(mean_squared_error(true_values, pred_values))\n\n                # MASE = current model's MAE / naive model's MAE\n                elif metric == \"MASE\":\n                    forecast_error = np.mean(np.abs(true_values - pred_values))\n                    naive_error = np.mean(\n                        np.abs(true_values[1:] - true_values[:-1])\n                    )\n                    if naive_error == 0:  # Avoid division by zero\n                        eval.append(np.inf)\n                    else:\n                        eval.append(forecast_error / naive_error)\n                else:\n                    raise ValueError(f\"Unsupported metric: {metric}\")\n            eval_windows.append(eval)\n\n            # Update history, true values and predictions\n            if length not in histories.keys():\n                histories[length] = []\n                trues[length] = []\n                preds[length] = []\n                quantile_preds[length] = []\n            histories[length].append(past_values)\n            trues[length].append(true_values)\n            preds[length].append(pred_values)\n            quantile_preds[length].append(quantiles)\n\n    eval_windows = np.mean(np.array(eval_windows), axis=0)\n    eval_results = {}\n    for i in range(len(metrics)):\n        eval_results[metrics[i]] = eval_windows[i]\n\n    # Convert to numpy arrays\n    histories = [np.array(histories[key]) for key in histories.keys()]\n    trues = [np.array(trues[key]) for key in trues.keys()]\n    preds = [np.array(preds[key]) for key in preds.keys()]\n    quantile_preds = [\n        np.array(quantile_preds[key]) for key in quantile_preds.keys()\n    ]\n    quantile_preds = [np.transpose(q, (1, 0, 2)) for q in quantile_preds]\n\n    # print([h.shape for h in histories])\n    # denormalize the data\n    if dataset.normalize:\n        trues = dataset._denormalize_data(trues)\n        preds = dataset._denormalize_data(preds)\n        histories = dataset._denormalize_data(histories)\n        quantile_preds = [\n            dataset._denormalize_data(q)\n            for q in quantile_preds\n        ]\n\n    mse = np.mean(np.array([MSE(t, p) for t, p in zip(trues, preds)]), axis=0)\n    mae = np.mean(np.array([MAE(t, p) for t, p in zip(trues, preds)]), axis=0)\n    mase = np.mean(np.array([MASE(t, p) for t, p in zip(trues, preds)]), axis=0)\n    mape = np.mean(np.array([MAPE(t, p) for t, p in zip(trues, preds)]), axis=0)\n    rmse = np.mean(np.array([RMSE(t, p) for t, p in zip(trues, preds)]), axis=0)\n    nrmse = np.mean(np.array([NRMSE(t, p) for t, p in zip(trues, preds)]), axis=0)\n    smape = np.mean(np.array([SMAPE(t, p) for t, p in zip(trues, preds)]), axis=0)\n    msis = np.mean(np.array([MSIS(t, p) for t, p in zip(trues, preds)]), axis=0)\n    nd = np.mean(np.array([ND(t, p) for t, p in zip(trues, preds)]), axis=0)\n\n    mwsq = np.mean(\n        np.array([MWSQ(t, p, q) for t, p, q in zip(trues, quantile_preds, quantile_levels)],),\n        axis=0,\n    )\n    crps = np.mean(\n        np.array([CRPS(t, p, q) for t, p, q in zip(trues, quantile_preds, quantile_levels)],),\n        axis=0,\n    )\n\n    leaderboard_metrics = {\n        \"mse\": mse,\n        \"mae\": mae,\n        \"mase\": mase,\n        \"mape\": mape,\n        \"rmse\": rmse,\n        \"nrmse\": nrmse,\n        \"smape\": smape,\n        \"msis\": msis,\n        \"nd\": nd,\n        \"mwsq\": mwsq,\n        \"crps\": crps,\n    }\n\n    cleanup_dataloader(inference_loader)\n\n    if leaderboard:\n        return leaderboard_metrics\n    else:\n        return leaderboard_metrics, trues, preds, histories, quantile_preds\n</code></pre>"},{"location":"api/models/#samay.model.MoiraiTSModel.finetune","title":"<code>finetune(dataset, **kwargs)</code>","text":"<p>Finetune the model on the given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>MoiraiDataset</code> <p>Dataset containing the input data and relevant functions like dataloaders etc.</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def finetune(self, dataset, **kwargs):\n    \"\"\"Finetune the model on the given dataset.\n\n    Args:\n        dataset (MoiraiDataset): Dataset containing the input data and relevant functions like dataloaders etc.\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n    model_size = self.repo.split(\"-\")[-1]\n    if self.model_type == \"moirai\":\n        model_config = (\n            f\"../src/uni2ts/cli/conf/finetune/model/moirai_1.1_R_{model_size}.yaml\"\n        )\n    elif self.model_type == \"moirai-moe\":\n        model_config = f\"../src/uni2ts/cli/conf/finetune/model/moirai_moe_1.0_R_{model_size}.yaml\"\n    elif self.model_type == \"moirai2\":\n        # only small version is available for moirai2 for now\n        model_config = f\"../src/uni2ts/cli/conf/finetune/model/moirai_2.0_R_{model_size}.yaml\" \n\n    with open(model_config, \"r\") as file:\n        fin_model_config = yaml.load(file, Loader=yaml.FullLoader)\n\n    # lr = 1e-4 if \"lr\" not in fin_model_config else float(fin_model_config[\"lr\"])\n    lr = 5e-6\n    weight_decay = (\n        1e-1\n        if \"weight_decay\" not in fin_model_config\n        else float(fin_model_config[\"weight_decay\"])\n    )\n    self.batch_size = (\n        kwargs[\"batch_size\"] if \"batch_size\" in kwargs else self.batch_size\n    )\n    epochs = 5\n    assert epochs &lt;= kwargs[\"max_epochs\"], (\n        \"epochs should be less than or equal to max_epochs\"\n    )\n\n    # Number of batches per epoch required for calculating the number of training steps\n    num_batches = len(dataset.dataset) // self.batch_size\n    if (\n        \"num_batches_per_epoch\" in kwargs.keys()\n    ):  # If num_batches_per_epoch is provided\n        num_batches_per_epoch = kwargs[\"num_batches_per_epoch\"]\n        epochs = min(epochs, num_batches // num_batches_per_epoch)\n    else:\n        num_batches_per_epoch = num_batches // epochs\n\n    training_steps = num_batches_per_epoch * kwargs[\"max_epochs\"]\n    module_args = convert_module_kwargs(\n        fin_model_config[\"module_kwargs\"]\n    )  # remove _target_ fields\n    if self.model_type == \"moirai2\":\n        self.patch_size = self.model.module.patch_size  # update patch_size\n    else:\n        self.patch_size = self.model.module.in_proj.in_features_ls[\n            0\n        ]  # update patch_size\n\n    # Trainer configuration (from uni2ts/cli/train.py)\n    # mod_torch is the trainer configuration without _target_ fields or any key\n    # whose value is neither a list or dictionary\n    if kwargs[\"tf32\"]:\n        assert kwargs[\"mod_torch\"][\"precision\"] == 32, (\n            \"Precision should be 32 for tf32\"\n        )\n        torch.backends.cuda.matmul.allow_tf32 = True\n        torch.backends.cudnn.allow_tf32 = True\n\n    # For now, self.model.module.patch_sizes is just [16] from the config file\n    # But in finetune, we are using patch_sizes as [8,16,32,64,128]\n    # So, we need to update the patch_sizes in the model\n    # self.model.module.patch_sizes = list(module_args[\"patch_sizes\"])\n\n    # instantiate loss function\n    spec = fin_model_config[\"loss_func\"]\n    def locate(path: str):\n        \"\"\"Locate a class from a string path.\"\"\"\n        module_path, class_name = path.rsplit(\".\", 1)\n        module = importlib.import_module(module_path)\n        return getattr(module, class_name)   \n    cls = locate(spec[\"_target_\"])\n    kwargs = {k: v for k, v in spec.items() if k != \"_target_\"}\n    fin_model_config[\"loss_func\"] = cls(**kwargs)\n\n    # Load the model\n    FinetunedModel = MoiraiFinetune(\n        min_patches=fin_model_config[\"min_patches\"],\n        min_mask_ratio=fin_model_config[\"min_mask_ratio\"],\n        max_mask_ratio=fin_model_config[\"max_mask_ratio\"],\n        max_dim=fin_model_config[\"max_dim\"],\n        num_training_steps=training_steps,\n        num_warmup_steps=fin_model_config[\"num_warmup_steps\"],\n        module_kwargs=module_args,\n        beta1=fin_model_config[\"beta1\"],\n        beta2=fin_model_config[\"beta2\"],\n        val_metric=fin_model_config[\"val_metric\"],\n        weight_decay=fin_model_config[\"weight_decay\"],\n        model_type=self.model_type,\n        model_size=model_size,\n        loss_func=fin_model_config[\"loss_func\"],\n    )\n\n    # Pytorch version\n    FinetunedModel.to(self.device)\n    FinetunedModel.train()  # Set model to training mode\n\n    # Freeze the transformer layers\n    # First we finetune the whole model - Not good\n    # Freeze the last two encoder layers and param_proj\n    for mn, m in FinetunedModel.named_modules():\n        for pn, p in m.named_parameters():\n            if not p.requires_grad:\n                continue\n\n            fpn = f\"{mn}.{pn}\" if mn else pn\n            # print(f\"Checking fpn before freezing: {fpn}\")\n\n            # Freeze everything except the last 2 encoder layers and param_proj\n            if fpn.split(\".\")[1] in [\n                \"in_proj\",\n                \"res_proj\",\n                \"feat_proj\",\n            ]:  # Freeze all initial layers\n                p.requires_grad = False\n            elif fpn.split(\".\")[1] == \"encoder\":\n                if (\n                    len(fpn.split(\".\")) &gt; 3\n                    and fpn.split(\".\")[2] == \"layers\"\n                    and int(fpn.split(\".\")[3]) &lt; 5\n                ):  # Freeze all but last two encoder layers\n                    p.requires_grad = False\n\n    # Load the dataset\n    dataloader = (\n        dataset.get_dataloader()\n    )  # look at if mode==\"train\" case for more info\n\n    decay = set()\n    no_decay = set()\n\n    whitelist_params = (\n        LearnedProjection,\n        MultiInSizeLinear,\n        MultiOutSizeLinear,\n        nn.Linear,\n    )\n    blacklist_params = (\n        BinaryAttentionBias,\n        LearnedEmbedding,\n        RMSNorm,\n        nn.Embedding,\n        nn.LayerNorm,\n    )\n\n    for mn, m in FinetunedModel.named_modules():\n        for pn, p in m.named_parameters():\n            if not p.requires_grad:\n                continue\n\n            fpn = f\"{mn}.{pn}\" if mn else pn\n\n            if pn.endswith(\"bias\"):\n                no_decay.add(fpn)\n            elif pn.endswith(\"weight\") and isinstance(m, whitelist_params):\n                decay.add(fpn)\n            elif pn.endswith(\"weight\") and isinstance(m, blacklist_params):\n                no_decay.add(fpn)\n\n    # validate that we considered every parameter\n    param_dict = {\n        pn: p for pn, p in FinetunedModel.named_parameters() if p.requires_grad\n    }\n\n    optim_groups = [\n        {\n            \"params\": filter(\n                lambda p: p.requires_grad,\n                [v for k, v in param_dict.items() if k in (list(no_decay))],\n            ),\n            \"weight_decay\": weight_decay,\n        },\n        {\n            \"params\": filter(\n                lambda p: p.requires_grad,\n                [v for k, v in param_dict.items() if k not in (list(no_decay))],\n            ),\n            \"weight_decay\": 0.0,\n        },\n    ]\n    optimizer = torch.optim.AdamW(\n        optim_groups,\n        lr=lr,\n        betas=(FinetunedModel.hparams.beta1, FinetunedModel.hparams.beta2),\n        eps=1e-6,\n    )\n\n    # scheduler = get_scheduler(\n    #     SchedulerType.COSINE_WITH_RESTARTS,\n    #     optimizer,\n    #     num_warmup_steps=FinetunedModel.hparams.num_warmup_steps,\n    #     num_training_steps=FinetunedModel.hparams.num_training_steps,\n    # )\n\n    loss_vals = []\n    for epoch in range(epochs):\n        avg_loss = 0\n        for i, (inputs) in enumerate(dataloader):  # each batch is processed\n            inputs = self.preprocess_inputs(\n                inputs\n            )  # patchify and other fields added\n            for k, v in inputs.items():\n                if isinstance(v, torch.Tensor):\n                    inputs[k] = v.to(self.device)\n                    if v.dtype == torch.float32 or v.dtype == torch.float64:\n                        inputs[k] = inputs[k].requires_grad_()\n            optimizer.zero_grad()  # reset gradients\n            # distribution of predictions\n            torch.autograd.set_detect_anomaly(True)\n            outputs = FinetunedModel.forward(\n                target=inputs[\"target\"],\n                observed_mask=inputs[\"observed_mask\"],\n                sample_id=inputs[\"sample_id\"],\n                time_id=inputs[\"time_id\"],\n                variate_id=inputs[\"variate_id\"],\n                prediction_mask=inputs[\"prediction_mask\"],\n                patch_size=inputs[\"patch_size\"],\n            )\n\n            if self.model_type == \"moirai2\":\n                quantile_prediction = repeat(\n                    inputs[\"target\"],\n                    \"... patch_size -&gt; ... num_quantiles patch_size\",\n                    num_quantiles=len(self.model.module.quantile_levels),\n                    patch_size=self.model.module.patch_size,\n                ).clone()\n                context_token_len = math.ceil(self.context_len / self.patch_size)\n                pred_token_len = math.ceil(self.horizon_len / self.patch_size)\n                num_context_tokens = context_token_len * self.target_dim\n                num_pred_tokens = pred_token_len * self.target_dim\n                pred_index = torch.arange(\n                    start=context_token_len - 1,\n                    end=num_context_tokens,\n                    step=context_token_len,\n                )\n                assign_index = torch.arange(\n                    start=num_context_tokens,\n                    end=num_context_tokens + num_pred_tokens,\n                    step=pred_token_len,\n                )\n                preds, adjusted_assign_index = self.structure_multi_predict(\n                    per_var_predict_token=pred_token_len,\n                    pred_index=pred_index,\n                    assign_index=assign_index,\n                    preds=outputs,\n                )\n                quantile_prediction[..., adjusted_assign_index, :, :] = preds\n                outputs = rearrange(\n                    quantile_prediction,\n                    \"... num_quantiles patch_size -&gt; ... (num_quantiles patch_size)\",\n                )\n\n            loss = FinetunedModel.hparams.loss_func(\n                pred=outputs,\n                **{\n                    field: inputs[field]\n                    for field in [\n                        \"target\",\n                        \"prediction_mask\",\n                        \"observed_mask\",\n                        \"sample_id\",\n                        \"variate_id\",\n                    ]\n                },\n            )\n\n            loss.backward()\n            optimizer.step()\n            # scheduler.step()\n            avg_loss += loss.item()\n        avg_loss /= len(dataloader)\n        print(f\"Epoch {epoch}: Loss: {avg_loss:.3f}\")\n        loss_vals.append(avg_loss)\n    print(\"Finetuning done\")\n\n    # Plot the loss values\n    plt.grid(True)\n    plt.plot(loss_vals)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Training Loss\")\n    # plt.savefig(f\"training_loss_{epochs}_epochs_wo_scheduler.png\")\n\n    self.finetuned_model = FinetunedModel\n    print(\"Fineuned model updated\")\n    cleanup_dataloader(dataloader)\n</code></pre>"},{"location":"api/models/#samay.model.MoiraiTSModel.plot","title":"<code>plot(dataset, zero_shot=False, **kwargs)</code>","text":"<p>Plot the results of the model on the given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>MoiraiDataset</code> <p>Dataset containing the input data and relevant functions like dataloaders etc.</p> required Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def plot(self, dataset, zero_shot=False, **kwargs):\n    \"\"\"Plot the results of the model on the given dataset.\n\n    Args:\n        dataset (MoiraiDataset): Dataset containing the input data and relevant functions like dataloaders etc.\n    \"\"\"\n    _, trues, preds, history = self.evaluate(dataset, leaderboard=False, zero_shot=zero_shot)\n    visualize(\n        task_name=\"forecasting\",\n        trues=np.concatenate(trues, axis=0),\n        preds=np.concatenate(preds, axis=0),\n        history=np.concatenate(history, axis=0\n        ),\n    )\n</code></pre>"},{"location":"api/models/#samay.model.MoiraiTSModel.preprocess_inputs","title":"<code>preprocess_inputs(inputs: dict)</code>","text":"<p>Preprocess the inputs to the model - specifically adds the following fields: +--------------------+--------------------------------------+-----------------------+----------------------------------+ | FIELD              | DESCRIPTION                          | TYPE                  | SHAPE                            | +--------------------+--------------------------------------+-----------------------+----------------------------------+ | target             | Batched time series data             | torch.tensor[float]   | (batch_size, seq_len, max_patch) | | observed_mask      | Binary mask for the context part     | torch.tensor[bool]    | (batch_size, seq_len, max_patch) | | prediction_mask    | Binary mask for the prediction part  | torch.tensor[bool]    | (batch_size, seq_len)            | | time_id            | Time index                           | torch.tensor[int]     | (batch_size, seq_len)            | | sample_id          | Time index                           | torch.tensor[int]     | (batch_size, seq_len)            | | variate_id         | Index indicating the variate         | torch.tensor[int]     | (batch_size, seq_len)            | | patch_size         | Patch size the model should use      | torch.tensor[int]     | (batch_size, seq_len)            | +--------------------+--------------------------------------+-----------------------+----------------------------------+</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>dict</code> <p>Dictionary containing the input data.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Preprocessed input data.</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def preprocess_inputs(self, inputs: dict):\n    \"\"\"Preprocess the inputs to the model - specifically adds the following fields:\n    +--------------------+--------------------------------------+-----------------------+----------------------------------+\n    | FIELD              | DESCRIPTION                          | TYPE                  | SHAPE                            |\n    +--------------------+--------------------------------------+-----------------------+----------------------------------+\n    | target             | Batched time series data             | torch.tensor[float]   | (batch_size, seq_len, max_patch) |\n    | observed_mask      | Binary mask for the context part     | torch.tensor[bool]    | (batch_size, seq_len, max_patch) |\n    | prediction_mask    | Binary mask for the prediction part  | torch.tensor[bool]    | (batch_size, seq_len)            |\n    | time_id            | Time index                           | torch.tensor[int]     | (batch_size, seq_len)            |\n    | sample_id          | Time index                           | torch.tensor[int]     | (batch_size, seq_len)            |\n    | variate_id         | Index indicating the variate         | torch.tensor[int]     | (batch_size, seq_len)            |\n    | patch_size         | Patch size the model should use      | torch.tensor[int]     | (batch_size, seq_len)            |\n    +--------------------+--------------------------------------+-----------------------+----------------------------------+\n\n    Args:\n        inputs (dict): Dictionary containing the input data.\n\n    Returns:\n        dict: Preprocessed input data.\n    \"\"\"\n    (target, observed_mask, sample_id, time_id, variate_id, prediction_mask) = (\n        self.model._convert(\n            patch_size=self.patch_size,\n            past_target=inputs[\"past_target\"],\n            past_observed_target=inputs[\"past_observed_target\"],\n            past_is_pad=inputs[\"past_is_pad\"],\n        )\n    )\n    inputs[\"target\"] = target\n    inputs[\"observed_mask\"] = observed_mask\n    inputs[\"sample_id\"] = sample_id\n    inputs[\"time_id\"] = time_id\n    inputs[\"variate_id\"] = variate_id\n    inputs[\"prediction_mask\"] = prediction_mask\n    inputs[\"patch_size\"] = torch.tensor(\n        np.full(shape=sample_id.shape, fill_value=self.patch_size, dtype=np.int64),\n        dtype=torch.int64,\n    )\n\n    return inputs\n</code></pre>"},{"location":"api/models/#tinytimemixermodel","title":"TinyTimeMixerModel","text":"<p>Lightweight and efficient time-series forecasting model.</p>"},{"location":"api/models/#samay.model.TinyTimeMixerModel","title":"<code>TinyTimeMixerModel(config=None, repo=None)</code>","text":"<p>               Bases: <code>Basemodel</code></p> <p>Parameters:</p> Name Type Description Default <code>config</code> <p>dict, model configuration</p> <code>None</code> <code>repo</code> <p>str, Huggingface model repository id</p> <code>None</code> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def __init__(self, config=None, repo=None):\n    \"\"\"\n    Args:\n        config: dict, model configuration\n        repo: str, Huggingface model repository id\n    \"\"\"\n    super().__init__(config=config, repo=repo)\n    if repo:\n        context_len = config[\"context_len\"]\n        horizon_len = config[\"horizon_len\"]\n        horizon_list = [96, 192, 336, 720]\n        closest_larger_horizon = min([x for x in horizon_list if x &gt;= horizon_len])\n        if context_len == 512 and closest_larger_horizon == 96:\n            revision = \"main\"\n        else:\n            revision = f\"{context_len}-{closest_larger_horizon}-r2\"\n        self.model = TinyTimeMixerForPrediction.from_pretrained(\n            repo, revision=revision, prediction_filter_length=horizon_len\n        )\n        # self.model = self.model.to(self.device)\n    else:\n        raise ValueError(\"TinyTimeMixer model requires a repository\")\n</code></pre>"},{"location":"api/models/#samay.model.TinyTimeMixerModel.evaluate","title":"<code>evaluate(dataset, **kwargs)</code>","text":"<p>Evaluate the model. Args:     dataset: dataset for evaluation, call get_data_loader() to get the dataloader Returns:     Dict[str, float]: evaluation metrics, including mse, mae, mase, mape, rmse, nrmse, smape, msis, nd</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def evaluate(self, dataset, **kwargs):\n    \"\"\"\n    Evaluate the model.\n    Args:\n        dataset: dataset for evaluation, call get_data_loader() to get the dataloader\n    Returns:\n        Dict[str, float]: evaluation metrics, including mse, mae, mase, mape, rmse, nrmse, smape, msis, nd\n    \"\"\"\n    dataloader = dataset.get_data_loader()\n    trues, preds, histories = [], [], []\n    self.model.to(self.device)\n    self.model.eval()\n    with torch.no_grad():\n        for i, data in enumerate(dataloader):\n            context, forecast_seq = data\n            context = context.float().permute(0, 2, 1).to(self.device)\n            forecast_seq = forecast_seq.float().permute(0, 2, 1).to(self.device)\n            output = self.model(past_values=context, future_values=forecast_seq)\n            pred = output.prediction_outputs\n            trues.append(forecast_seq.permute(0, 2, 1).detach().cpu().numpy())\n            preds.append(pred.permute(0, 2, 1).detach().cpu().numpy())\n            histories.append(context.permute(0, 2, 1).detach().cpu().numpy())\n\n        trues = np.concatenate(trues, axis=0)\n        preds = np.concatenate(preds, axis=0)\n        histories = np.concatenate(histories, axis=0)\n\n    print(trues.shape, preds.shape, histories.shape)\n    mse = MSE(trues, preds)\n    mae = MAE(trues, preds)\n    mase = MASE(trues, preds)\n    mape = MAPE(trues, preds)\n    rmse = RMSE(trues, preds)\n    nrmse = NRMSE(trues, preds)\n    smape = SMAPE(trues, preds)\n    msis = MSIS(trues, preds)\n    nd = ND(trues, preds)\n\n    return {\n        \"mse\": mse,\n        \"mae\": mae,\n        \"mase\": mase,\n        \"mape\": mape,\n        \"rmse\": rmse,\n        \"nrmse\": nrmse,\n        \"smape\": smape,\n        \"msis\": msis,\n        \"nd\": nd,\n    }\n</code></pre>"},{"location":"api/models/#samay.model.TinyTimeMixerModel.finetune","title":"<code>finetune(dataset, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>dataset</code> <p>dataset for finetuning, call get_data_loader() to get the dataloader</p> required Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def finetune(self, dataset, **kwargs):\n    \"\"\"\n    Args:\n        dataset: dataset for finetuning, call get_data_loader() to get the dataloader\n    \"\"\"\n    dataloader = dataset.get_data_loader()\n    self.model.to(self.device)\n    self.model.train()\n    optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n    for epoch in range(5):\n        total_loss = 0\n        for i, data in enumerate(dataloader):\n            context, forecast_seq = data\n            context = context.float().permute(0, 2, 1).to(self.device)\n            forecast_seq = forecast_seq.float().permute(0, 2, 1).to(self.device)\n            optimizer.zero_grad()\n            output = self.model(past_values=context, future_values=forecast_seq)\n            loss = output.loss\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        avg_loss = total_loss / len(dataloader)\n        print(f\"Epoch {epoch}, Loss: {avg_loss}\")\n    self.model.eval()\n</code></pre>"},{"location":"api/models/#samay.model.TinyTimeMixerModel.plot","title":"<code>plot(dataset, **kwargs)</code>","text":"<p>Plot the forecast results. Args:     dataset: dataset for plotting, call get_data_loader() to get the dataloader</p> Source code in <code>Samay\\src\\samay\\model.py</code> <pre><code>def plot(self, dataset, **kwargs):\n    \"\"\"\n    Plot the forecast results.\n    Args:\n        dataset: dataset for plotting, call get_data_loader() to get the dataloader\n    \"\"\"\n    dataloader = dataset.get_data_loader()\n    trues, preds, histories = [], [], []\n    self.model.to(self.device)\n    self.model.eval()\n    with torch.no_grad():\n        for i, data in enumerate(dataloader):\n            context, forecast_seq = data\n            context = context.float().permute(0, 2, 1).to(self.device)\n            forecast_seq = forecast_seq.float().permute(0, 2, 1).to(self.device)\n            output = self.model(past_values=context, future_values=forecast_seq)\n            pred = output.prediction_outputs\n            trues.append(forecast_seq.permute(0, 2, 1).detach().cpu().numpy())\n            preds.append(pred.permute(0, 2, 1).detach().cpu().numpy())\n            histories.append(context.permute(0, 2, 1).detach().cpu().numpy())\n\n        trues = np.concatenate(trues, axis=0)\n        preds = np.concatenate(preds, axis=0)\n        histories = np.concatenate(histories, axis=0)\n\n    visualize(\n        task_name=\"forecasting\",\n        trues=trues,\n        preds=preds,\n        history=histories,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/models/#usage-examples","title":"Usage Examples","text":""},{"location":"api/models/#loading-a-model","title":"Loading a Model","text":"<pre><code>from samay.model import LPTMModel\n\nconfig = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\nmodel = LPTMModel(config)\n</code></pre>"},{"location":"api/models/#fine-tuning","title":"Fine-Tuning","text":"<pre><code>from samay.dataset import LPTMDataset\n\ntrain_dataset = LPTMDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n)\n\nfinetuned_model = model.finetune(train_dataset, epochs=10)\n</code></pre>"},{"location":"api/models/#evaluation","title":"Evaluation","text":"<pre><code>test_dataset = LPTMDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    horizon=192,\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n</code></pre>"},{"location":"api/models/#saving-and-loading","title":"Saving and Loading","text":"<pre><code># Save model\nmodel.save(\"model_checkpoint.pt\")\n\n# Load model\nloaded_model = LPTMModel.load(\"model_checkpoint.pt\")\n</code></pre>"},{"location":"api/models/#common-parameters","title":"Common Parameters","text":"<p>Most model classes share these common parameters:</p> Parameter Type Description <code>config</code> dict Configuration dictionary with model-specific parameters <code>device</code> str Device to run model on: <code>\"cuda\"</code> or <code>\"cpu\"</code> <code>repo</code> str Hugging Face repository for pre-trained weights (some models)"},{"location":"api/models/#common-methods","title":"Common Methods","text":"<p>All models implement these methods:</p>"},{"location":"api/models/#finetunedataset-epochs5-learning_rate1e-4-kwargs","title":"<code>finetune(dataset, epochs=5, learning_rate=1e-4, **kwargs)</code>","text":"<p>Fine-tune the model on a dataset.</p> <p>Parameters: - <code>dataset</code>: Training dataset object - <code>epochs</code> (int): Number of training epochs - <code>learning_rate</code> (float): Learning rate for optimizer - <code>**kwargs</code>: Additional training arguments</p> <p>Returns: - Trained model</p>"},{"location":"api/models/#evaluatedataset-metricsnone-kwargs","title":"<code>evaluate(dataset, metrics=None, **kwargs)</code>","text":"<p>Evaluate the model on a dataset.</p> <p>Parameters: - <code>dataset</code>: Test dataset object - <code>metrics</code> (list): List of metric names to compute - <code>**kwargs</code>: Additional evaluation arguments</p> <p>Returns: - <code>avg_loss</code> (float): Average loss - <code>trues</code> (np.ndarray): Ground truth values - <code>preds</code> (np.ndarray): Predicted values - <code>histories</code> (np.ndarray): Historical context</p>"},{"location":"api/models/#predictinput_data-kwargs","title":"<code>predict(input_data, **kwargs)</code>","text":"<p>Make predictions on new data.</p> <p>Parameters: - <code>input_data</code>: Input time series data - <code>**kwargs</code>: Additional prediction arguments</p> <p>Returns: - Predictions array</p>"},{"location":"api/models/#savepath","title":"<code>save(path)</code>","text":"<p>Save model to disk.</p> <p>Parameters: - <code>path</code> (str): Path to save model</p>"},{"location":"api/models/#loadpath-class-method","title":"<code>load(path)</code> (class method)","text":"<p>Load model from disk.</p> <p>Parameters: - <code>path</code> (str): Path to load model from</p> <p>Returns: - Loaded model instance</p>"},{"location":"api/models/#see-also","title":"See Also","text":"<ul> <li>Datasets API: Dataset classes for data loading</li> <li>Metrics API: Evaluation metrics</li> <li>Model Guides: Detailed guides for each model</li> </ul>"},{"location":"models/chronos/","title":"Chronos: Learning the Language of Time Series","text":"Language Model-Based Time-Series Forecasting"},{"location":"models/chronos/#overview","title":"Overview","text":"<p>Chronos is a novel approach to time-series forecasting that treats time series as a language. It uses transformer architectures similar to large language models (LLMs) to tokenize and predict time-series data. This innovative approach enables zero-shot forecasting across diverse domains.</p>"},{"location":"models/chronos/#paper","title":"Paper","text":"<p>Chronos: Learning the Language of Time Series</p>"},{"location":"models/chronos/#key-features","title":"Key Features","text":"<ul> <li>\u2705 Language model architecture for time series</li> <li>\u2705 Tokenization-based approach</li> <li>\u2705 Strong zero-shot capabilities</li> <li>\u2705 Multiple model sizes</li> <li>\u2705 Probabilistic forecasting</li> </ul>"},{"location":"models/chronos/#model-variants","title":"Model Variants","text":"<p>Chronos comes in several sizes:</p> Model Parameters Use Case Chronos-T5-tiny ~8M Fast inference, resource-constrained Chronos-T5-mini ~20M Balanced performance Chronos-T5-small ~46M Good accuracy Chronos-T5-base ~200M High accuracy Chronos-T5-large ~800M Best performance"},{"location":"models/chronos/#quick-start","title":"Quick Start","text":"<pre><code>from samay.model import ChronosModel\nfrom samay.dataset import ChronosDataset\n\n# Model configuration\nconfig = {\n    \"model_size\": \"small\",  # tiny, mini, small, base, large\n    \"context_length\": 512,\n    \"prediction_length\": 64,\n    \"num_samples\": 20,\n    \"temperature\": 1.0,\n    \"top_k\": 50,\n    \"top_p\": 1.0,\n}\n\n# Load model\nmodel = ChronosModel(config)\n\n# Load dataset\ntrain_dataset = ChronosDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    config=config,\n)\n\n# Evaluate (zero-shot)\ntest_dataset = ChronosDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    config=config,\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\nprint(f\"Average Loss: {avg_loss}\")\n</code></pre>"},{"location":"models/chronos/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"models/chronos/#model-configuration","title":"Model Configuration","text":"Parameter Type Default Description <code>model_size</code> str <code>\"small\"</code> Model size: <code>\"tiny\"</code>, <code>\"mini\"</code>, <code>\"small\"</code>, <code>\"base\"</code>, <code>\"large\"</code> <code>context_length</code> int <code>512</code> Length of input context <code>prediction_length</code> int <code>64</code> Forecast horizon <code>num_samples</code> int <code>20</code> Number of samples for probabilistic forecasting <code>temperature</code> float <code>1.0</code> Sampling temperature <code>top_k</code> int <code>50</code> Top-k sampling parameter <code>top_p</code> float <code>1.0</code> Nucleus sampling parameter <code>tokenizer_class</code> str <code>\"MeanScaleUniformBins\"</code> Tokenizer type <code>tokenizer_kwargs</code> dict <code>{\"low_limit\": -15.0, \"high_limit\": 15.0}</code> Tokenizer parameters"},{"location":"models/chronos/#example-configurations","title":"Example Configurations","text":""},{"location":"models/chronos/#fast-inference-tiny-model","title":"Fast Inference (Tiny Model)","text":"<pre><code>config = {\n    \"model_size\": \"tiny\",\n    \"context_length\": 256,\n    \"prediction_length\": 32,\n    \"num_samples\": 10,\n}\n</code></pre>"},{"location":"models/chronos/#balanced-performance-small-model","title":"Balanced Performance (Small Model)","text":"<pre><code>config = {\n    \"model_size\": \"small\",\n    \"context_length\": 512,\n    \"prediction_length\": 64,\n    \"num_samples\": 20,\n    \"temperature\": 1.0,\n}\n</code></pre>"},{"location":"models/chronos/#high-accuracy-base-model","title":"High Accuracy (Base Model)","text":"<pre><code>config = {\n    \"model_size\": \"base\",\n    \"context_length\": 512,\n    \"prediction_length\": 96,\n    \"num_samples\": 50,\n    \"temperature\": 0.8,\n}\n</code></pre>"},{"location":"models/chronos/#dataset","title":"Dataset","text":""},{"location":"models/chronos/#chronosdataset-parameters","title":"ChronosDataset Parameters","text":"Parameter Type Default Description <code>name</code> str <code>None</code> Dataset name <code>datetime_col</code> str <code>\"ds\"</code> Name of datetime column <code>path</code> str Required Path to CSV file <code>mode</code> str <code>None</code> <code>\"train\"</code> or <code>\"test\"</code> <code>batch_size</code> int <code>16</code> Batch size <code>boundaries</code> list <code>[0, 0, 0]</code> Custom split boundaries <code>stride</code> int <code>10</code> Stride for sliding window <code>config</code> dict <code>None</code> Model configuration (used for context/prediction length)"},{"location":"models/chronos/#data-format","title":"Data Format","text":"<p>CSV file with datetime and value columns:</p> <pre><code>date,HUFL,HULL,MUFL,MULL,LUFL,LULL,OT\n2016-07-01 00:00:00,5.827,2.009,1.599,0.462,5.677,2.009,6.082\n2016-07-01 01:00:00,5.693,2.076,1.492,0.426,5.485,1.942,5.947\n...\n</code></pre>"},{"location":"models/chronos/#zero-shot-forecasting","title":"Zero-Shot Forecasting","text":"<p>Chronos excels at zero-shot forecasting without any fine-tuning:</p> <pre><code>from samay.model import ChronosModel\nfrom samay.dataset import ChronosDataset\n\n# Load model\nconfig = {\n    \"model_size\": \"small\",\n    \"context_length\": 512,\n    \"prediction_length\": 96,\n    \"num_samples\": 20,\n}\n\nmodel = ChronosModel(config)\n\n# Load test data directly\ntest_dataset = ChronosDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    config=config,\n)\n\n# Zero-shot evaluation (no training!)\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\nprint(f\"Zero-shot Loss: {avg_loss}\")\n</code></pre>"},{"location":"models/chronos/#probabilistic-forecasting","title":"Probabilistic Forecasting","text":"<p>Chronos provides probabilistic forecasts through multiple samples:</p> <pre><code>config = {\n    \"model_size\": \"small\",\n    \"context_length\": 512,\n    \"prediction_length\": 96,\n    \"num_samples\": 100,  # Generate 100 samples\n    \"temperature\": 1.0,\n}\n\nmodel = ChronosModel(config)\n\n# The model will generate multiple forecast samples\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\n# preds shape: (num_windows, num_channels, prediction_length, num_samples)\n</code></pre>"},{"location":"models/chronos/#analyzing-prediction-uncertainty","title":"Analyzing Prediction Uncertainty","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Get all samples\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\n# Calculate statistics\nmean_pred = np.mean(preds, axis=-1)  # Mean across samples\nstd_pred = np.std(preds, axis=-1)    # Std across samples\nlower_bound = np.percentile(preds, 10, axis=-1)\nupper_bound = np.percentile(preds, 90, axis=-1)\n\n# Plot with uncertainty bands\nsample_idx = 0\nchannel_idx = 0\n\nhistory = histories[sample_idx, channel_idx, :]\ntrue = trues[sample_idx, channel_idx, :]\npred_mean = mean_pred[sample_idx, channel_idx, :]\npred_lower = lower_bound[sample_idx, channel_idx, :]\npred_upper = upper_bound[sample_idx, channel_idx, :]\n\nplt.figure(figsize=(14, 5))\nplt.plot(range(len(history)), history, label=\"History\", linewidth=2)\nplt.plot(\n    range(len(history), len(history) + len(true)),\n    true,\n    label=\"Ground Truth\",\n    linestyle=\"--\",\n    linewidth=2\n)\nplt.plot(\n    range(len(history), len(history) + len(pred_mean)),\n    pred_mean,\n    label=\"Mean Prediction\",\n    linewidth=2\n)\nplt.fill_between(\n    range(len(history), len(history) + len(pred_mean)),\n    pred_lower,\n    pred_upper,\n    alpha=0.3,\n    label=\"80% Prediction Interval\"\n)\nplt.legend()\nplt.title(\"Chronos Probabilistic Forecasting\")\nplt.grid(alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"models/chronos/#fine-tuning","title":"Fine-Tuning","text":"<p>While Chronos is designed for zero-shot forecasting, you can fine-tune it on your data:</p> <pre><code># Load model\nconfig = {\n    \"model_size\": \"small\",\n    \"context_length\": 512,\n    \"prediction_length\": 96,\n}\n\nmodel = ChronosModel(config)\n\n# Load training data\ntrain_dataset = ChronosDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    config=config,\n    batch_size=16,\n)\n\n# Fine-tune\nfinetuned_model = model.finetune(\n    train_dataset,\n    epochs=5,\n    learning_rate=1e-5,  # Small learning rate\n)\n\n# Evaluate\ntest_dataset = ChronosDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    config=config,\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n</code></pre>"},{"location":"models/chronos/#sampling-strategies","title":"Sampling Strategies","text":""},{"location":"models/chronos/#temperature-sampling","title":"Temperature Sampling","text":"<p>Control the randomness of predictions:</p> <pre><code># Lower temperature = more conservative predictions\nconfig = {\n    \"temperature\": 0.5,  # More deterministic\n    # ...\n}\n\n# Higher temperature = more diverse predictions\nconfig = {\n    \"temperature\": 1.5,  # More exploratory\n    # ...\n}\n</code></pre>"},{"location":"models/chronos/#top-k-sampling","title":"Top-K Sampling","text":"<p>Limit sampling to top-k most likely tokens:</p> <pre><code>config = {\n    \"top_k\": 10,  # Only sample from top 10 tokens\n    # ...\n}\n</code></pre>"},{"location":"models/chronos/#nucleus-top-p-sampling","title":"Nucleus (Top-P) Sampling","text":"<p>Sample from the smallest set of tokens with cumulative probability &gt; p:</p> <pre><code>config = {\n    \"top_p\": 0.9,  # Sample from top 90% probability mass\n    # ...\n}\n</code></pre>"},{"location":"models/chronos/#evaluation","title":"Evaluation","text":""},{"location":"models/chronos/#basic-evaluation","title":"Basic Evaluation","text":"<pre><code>test_dataset = ChronosDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    config=config,\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n</code></pre>"},{"location":"models/chronos/#with-custom-metrics","title":"With Custom Metrics","text":"<pre><code>from samay.metric import mse, mae, mape\nimport numpy as np\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\n# Use mean of samples for metrics\ntrues = np.array(trues)\npreds = np.mean(np.array(preds), axis=-1)  # Average across samples\n\nprint(f\"MSE: {mse(trues, preds):.4f}\")\nprint(f\"MAE: {mae(trues, preds):.4f}\")\nprint(f\"MAPE: {mape(trues, preds):.4f}\")\n</code></pre>"},{"location":"models/chronos/#advanced-usage","title":"Advanced Usage","text":""},{"location":"models/chronos/#custom-context-lengths","title":"Custom Context Lengths","text":"<pre><code># Short context for simpler patterns\nconfig = {\n    \"context_length\": 128,\n    \"prediction_length\": 32,\n    # ...\n}\n\n# Long context for complex patterns\nconfig = {\n    \"context_length\": 1024,\n    \"prediction_length\": 128,\n    # ...\n}\n</code></pre>"},{"location":"models/chronos/#multivariate-forecasting","title":"Multivariate Forecasting","text":"<p>Chronos handles multivariate data by forecasting each channel independently:</p> <pre><code># Your CSV with multiple columns\ndataset = ChronosDataset(\n    datetime_col=\"date\",\n    path=\"./data/multivariate.csv\",\n    mode=\"test\",\n    config=config,\n)\n\n# Model will forecast all channels\navg_loss, trues, preds, histories = model.evaluate(dataset)\n</code></pre>"},{"location":"models/chronos/#tokenization","title":"Tokenization","text":"<p>Chronos uses a tokenization approach similar to NLP:</p>"},{"location":"models/chronos/#mean-scale-uniform-bins","title":"Mean-Scale Uniform Bins","text":"<p>The default tokenizer normalizes values and bins them:</p> <pre><code>config = {\n    \"tokenizer_class\": \"MeanScaleUniformBins\",\n    \"tokenizer_kwargs\": {\n        \"low_limit\": -15.0,  # Lower bound for binning\n        \"high_limit\": 15.0,   # Upper bound for binning\n    },\n    # ...\n}\n</code></pre>"},{"location":"models/chronos/#custom-tokenizer","title":"Custom Tokenizer","text":"<p>You can customize the tokenization:</p> <pre><code>config = {\n    \"tokenizer_class\": \"MeanScaleUniformBins\",\n    \"tokenizer_kwargs\": {\n        \"low_limit\": -10.0,\n        \"high_limit\": 10.0,\n        \"n_tokens\": 4096,  # Vocabulary size\n    },\n}\n</code></pre>"},{"location":"models/chronos/#visualization","title":"Visualization","text":""},{"location":"models/chronos/#multiple-forecast-samples","title":"Multiple Forecast Samples","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\n# Plot multiple samples\nsample_idx = 0\nchannel_idx = 0\nnum_samples_to_plot = 10\n\nhistory = histories[sample_idx, channel_idx, :]\ntrue = trues[sample_idx, channel_idx, :]\n\nplt.figure(figsize=(14, 5))\nplt.plot(range(len(history)), history, label=\"History\", linewidth=2, color='blue')\nplt.plot(\n    range(len(history), len(history) + len(true)),\n    true,\n    label=\"Ground Truth\",\n    linestyle=\"--\",\n    linewidth=2,\n    color='green'\n)\n\n# Plot multiple forecast samples\nfor i in range(num_samples_to_plot):\n    pred_sample = preds[sample_idx, channel_idx, :, i]\n    plt.plot(\n        range(len(history), len(history) + len(pred_sample)),\n        pred_sample,\n        alpha=0.3,\n        color='red'\n    )\n\n# Plot mean prediction\npred_mean = np.mean(preds[sample_idx, channel_idx, :, :], axis=-1)\nplt.plot(\n    range(len(history), len(history) + len(pred_mean)),\n    pred_mean,\n    label=\"Mean Prediction\",\n    linewidth=2,\n    color='red'\n)\n\nplt.legend()\nplt.title(\"Chronos: Multiple Forecast Samples\")\nplt.grid(alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"models/chronos/#tips-and-best-practices","title":"Tips and Best Practices","text":""},{"location":"models/chronos/#1-model-selection","title":"1. Model Selection","text":"<ul> <li>Use tiny/mini for fast inference and experimentation</li> <li>Use small/base for production applications</li> <li>Use large for highest accuracy (if resources allow)</li> </ul>"},{"location":"models/chronos/#2-context-length","title":"2. Context Length","text":"<ul> <li>Longer context captures more patterns but is slower</li> <li>Start with 512, adjust based on your data</li> </ul>"},{"location":"models/chronos/#3-number-of-samples","title":"3. Number of Samples","text":"<ul> <li>More samples = better uncertainty estimation</li> <li>20-50 samples is usually sufficient</li> <li>Use fewer samples for faster inference</li> </ul>"},{"location":"models/chronos/#4-zero-shot-vs-fine-tuning","title":"4. Zero-Shot vs Fine-Tuning","text":"<ul> <li>Try zero-shot first (Chronos is designed for this)</li> <li>Fine-tune only if zero-shot performance is insufficient</li> <li>Use very small learning rates when fine-tuning</li> </ul>"},{"location":"models/chronos/#common-issues","title":"Common Issues","text":""},{"location":"models/chronos/#cuda-out-of-memory","title":"CUDA Out of Memory","text":"<pre><code># Use smaller model\nconfig = {\n    \"model_size\": \"tiny\",  # Instead of \"base\"\n    # ...\n}\n\n# Reduce batch size\ndataset = ChronosDataset(\n    batch_size=4,  # Instead of 16\n    # ...\n)\n\n# Reduce context length\nconfig = {\n    \"context_length\": 256,  # Instead of 512\n    # ...\n}\n</code></pre>"},{"location":"models/chronos/#slow-inference","title":"Slow Inference","text":"<pre><code># Use smaller model\nconfig = {\n    \"model_size\": \"mini\",\n    # ...\n}\n\n# Reduce number of samples\nconfig = {\n    \"num_samples\": 10,  # Instead of 50\n    # ...\n}\n</code></pre>"},{"location":"models/chronos/#poor-predictions","title":"Poor Predictions","text":"<pre><code># Try larger model\nconfig = {\n    \"model_size\": \"base\",  # Instead of \"small\"\n    # ...\n}\n\n# Increase context length\nconfig = {\n    \"context_length\": 1024,  # More context\n    # ...\n}\n\n# Adjust temperature\nconfig = {\n    \"temperature\": 0.8,  # Less randomness\n    # ...\n}\n</code></pre>"},{"location":"models/chronos/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see:</p> <ul> <li>ChronosModel API</li> <li>ChronosDataset API</li> </ul>"},{"location":"models/chronos/#examples","title":"Examples","text":"<p>See the Examples page for complete working examples.</p>"},{"location":"models/lptm/","title":"LPTM: Large Pre-trained Time Series Model","text":"Large Pre-trained Time Series Models for Cross-Domain Time Series Analysis Tasks"},{"location":"models/lptm/#overview","title":"Overview","text":"<p>LPTM (Large Pre-trained Time Series Model) is a foundational model designed for general-purpose time-series forecasting. It uses a transformer-based architecture with a unique segmentation module that adaptively identifies patterns in time-series data.</p>"},{"location":"models/lptm/#paper","title":"Paper","text":"<p>Large Pre-trained time series models for cross-domain Time series analysis tasks</p>"},{"location":"models/lptm/#key-features","title":"Key Features","text":"<ul> <li>\u2705 Pre-trained on large-scale time-series data</li> <li>\u2705 Adaptive segmentation for pattern discovery</li> <li>\u2705 Supports forecasting, classification, and anomaly detection</li> <li>\u2705 Efficient fine-tuning with frozen encoders</li> <li>\u2705 Handles multivariate time series</li> </ul>"},{"location":"models/lptm/#quick-start","title":"Quick Start","text":"<pre><code>from samay.model import LPTMModel\nfrom samay.dataset import LPTMDataset\n\n# Configure the model\nconfig = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\n# Load model\nmodel = LPTMModel(config)\n\n# Load dataset\ntrain_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n)\n\n# Fine-tune\nfinetuned_model = model.finetune(train_dataset)\n\n# Evaluate\ntest_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    horizon=192,\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n</code></pre>"},{"location":"models/lptm/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"models/lptm/#model-configuration","title":"Model Configuration","text":"Parameter Type Default Description <code>task_name</code> str <code>\"forecasting\"</code> Task type: <code>\"forecasting\"</code>, <code>\"classification\"</code>, <code>\"detection\"</code> <code>forecast_horizon</code> int <code>192</code> Number of time steps to predict <code>freeze_encoder</code> bool <code>True</code> Whether to freeze the patch embedding layer <code>freeze_embedder</code> bool <code>True</code> Whether to freeze the transformer encoder <code>freeze_head</code> bool <code>False</code> Whether to freeze the forecasting head <code>freeze_segment</code> bool <code>True</code> Whether to freeze the segmentation module <code>head_dropout</code> float <code>0.0</code> Dropout rate for the forecasting head <code>weight_decay</code> float <code>0.0</code> Weight decay for regularization <code>max_patch</code> int <code>16</code> Maximum patch size for segmentation"},{"location":"models/lptm/#example-configurations","title":"Example Configurations","text":""},{"location":"models/lptm/#zero-shot-forecasting","title":"Zero-Shot Forecasting","text":"<pre><code>config = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 96,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": True,  # Keep all layers frozen\n}\n</code></pre>"},{"location":"models/lptm/#fine-tuning-for-domain-adaptation","title":"Fine-Tuning for Domain Adaptation","text":"<pre><code>config = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,  # Only train the head\n    \"head_dropout\": 0.1,\n    \"weight_decay\": 0.001,\n}\n</code></pre>"},{"location":"models/lptm/#full-fine-tuning","title":"Full Fine-Tuning","text":"<pre><code>config = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": False,\n    \"freeze_embedder\": False,\n    \"freeze_head\": False,\n    \"head_dropout\": 0.1,\n}\n</code></pre>"},{"location":"models/lptm/#dataset","title":"Dataset","text":""},{"location":"models/lptm/#lptmdataset-parameters","title":"LPTMDataset Parameters","text":"Parameter Type Default Description <code>name</code> str <code>None</code> Dataset name (for metadata) <code>datetime_col</code> str <code>None</code> Name of the datetime column <code>path</code> str Required Path to CSV file <code>mode</code> str <code>\"train\"</code> <code>\"train\"</code> or <code>\"test\"</code> <code>horizon</code> int <code>0</code> Forecast horizon length <code>batchsize</code> int <code>16</code> Batch size for training <code>boundaries</code> list <code>[0, 0, 0]</code> Custom train/val/test split indices <code>stride</code> int <code>10</code> Stride for sliding window <code>seq_len</code> int <code>512</code> Input sequence length <code>task_name</code> str <code>\"forecasting\"</code> Task type"},{"location":"models/lptm/#data-format","title":"Data Format","text":"<p>Your CSV file should have: - A datetime column (e.g., <code>date</code>) - One or more value columns</p> <p>Example: <pre><code>date,HUFL,HULL,MUFL,MULL,LUFL,LULL,OT\n2016-07-01 00:00:00,5.827,2.009,1.599,0.462,5.677,2.009,6.082\n2016-07-01 01:00:00,5.693,2.076,1.492,0.426,5.485,1.942,5.947\n...\n</code></pre></p>"},{"location":"models/lptm/#training","title":"Training","text":""},{"location":"models/lptm/#fine-tuning","title":"Fine-Tuning","text":"<pre><code># Create training dataset\ntrain_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n    batchsize=16,\n)\n\n# Fine-tune the model\nfinetuned_model = model.finetune(\n    train_dataset,\n    epochs=5,\n    learning_rate=1e-4,\n)\n</code></pre>"},{"location":"models/lptm/#custom-training-loop","title":"Custom Training Loop","text":"<p>For more control, you can implement a custom training loop:</p> <pre><code>import torch\nfrom torch.optim import Adam\n\n# Get data loader\ntrain_loader = train_dataset.get_data_loader()\n\n# Setup optimizer\noptimizer = Adam(model.parameters(), lr=1e-4)\n\n# Training loop\nfor epoch in range(5):\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n\n        # Forward pass\n        loss = model.compute_loss(batch)\n\n        # Backward pass\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}\")\n</code></pre>"},{"location":"models/lptm/#evaluation","title":"Evaluation","text":""},{"location":"models/lptm/#basic-evaluation","title":"Basic Evaluation","text":"<pre><code>test_dataset = LPTMDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    horizon=192,\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\nprint(f\"Average Test Loss: {avg_loss}\")\n</code></pre>"},{"location":"models/lptm/#custom-metrics","title":"Custom Metrics","text":"<pre><code>from samay.metric import mse, mae, mape\n\n# Get predictions\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\n# Calculate custom metrics\nimport numpy as np\ntrues = np.array(trues)\npreds = np.array(preds)\n\nmse_score = mse(trues, preds)\nmae_score = mae(trues, preds)\nmape_score = mape(trues, preds)\n\nprint(f\"MSE: {mse_score:.4f}\")\nprint(f\"MAE: {mae_score:.4f}\")\nprint(f\"MAPE: {mape_score:.4f}\")\n</code></pre>"},{"location":"models/lptm/#tasks","title":"Tasks","text":""},{"location":"models/lptm/#1-forecasting","title":"1. Forecasting","text":"<p>Predict future values:</p> <pre><code>config = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\nmodel = LPTMModel(config)\n</code></pre>"},{"location":"models/lptm/#2-anomaly-detection","title":"2. Anomaly Detection","text":"<p>Detect anomalies in time series:</p> <pre><code>config = {\n    \"task_name\": \"detection\",\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\nmodel = LPTMModel(config)\n\ndataset = LPTMDataset(\n    name=\"ecg\",\n    datetime_col=\"date\",\n    path=\"./data/ECG5000.csv\",\n    mode=\"train\",\n    task_name=\"detection\",\n)\n</code></pre>"},{"location":"models/lptm/#3-classification","title":"3. Classification","text":"<p>Classify time series:</p> <pre><code>config = {\n    \"task_name\": \"classification\",\n    \"num_classes\": 5,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\nmodel = LPTMModel(config)\n</code></pre>"},{"location":"models/lptm/#advanced-usage","title":"Advanced Usage","text":""},{"location":"models/lptm/#handling-multivariate-time-series","title":"Handling Multivariate Time Series","text":"<p>LPTM naturally handles multivariate data:</p> <pre><code># Your CSV with multiple columns\n# date,sensor1,sensor2,sensor3,...\ntrain_dataset = LPTMDataset(\n    datetime_col=\"date\",\n    path=\"./data/multivariate.csv\",\n    mode=\"train\",\n    horizon=192,\n)\n</code></pre>"},{"location":"models/lptm/#custom-data-splits","title":"Custom Data Splits","text":"<pre><code># Specify exact boundaries\ntrain_dataset = LPTMDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon=192,\n    boundaries=[0, 10000, 15000],  # Train: 0-10000, Val: 10000-15000, Test: 15000-end\n)\n</code></pre>"},{"location":"models/lptm/#denormalizing-predictions","title":"Denormalizing Predictions","text":"<pre><code># Get normalized predictions\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\n# Denormalize using the dataset's scaler\ndenormalized_preds = test_dataset._denormalize_data(preds)\ndenormalized_trues = test_dataset._denormalize_data(trues)\n</code></pre>"},{"location":"models/lptm/#visualization","title":"Visualization","text":""},{"location":"models/lptm/#plotting-forecasts","title":"Plotting Forecasts","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Get predictions\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\ntrues = np.array(trues)\npreds = np.array(preds)\nhistories = np.array(histories)\n\n# Plot a specific channel and time window\nchannel_idx = 0\ntime_index = 0\n\nhistory = histories[time_index, channel_idx, :]\ntrue = trues[time_index, channel_idx, :]\npred = preds[time_index, channel_idx, :]\n\nplt.figure(figsize=(14, 5))\nplt.plot(range(len(history)), history, label=\"History (512 steps)\", linewidth=2)\nplt.plot(\n    range(len(history), len(history) + len(true)),\n    true,\n    label=\"Ground Truth (192 steps)\",\n    linestyle=\"--\",\n    linewidth=2,\n)\nplt.plot(\n    range(len(history), len(history) + len(pred)),\n    pred,\n    label=\"Prediction (192 steps)\",\n    linewidth=2,\n)\nplt.axvline(x=len(history), color='gray', linestyle=':', alpha=0.5)\nplt.legend()\nplt.title(\"LPTM Time Series Forecasting\")\nplt.xlabel(\"Time Step\")\nplt.ylabel(\"Value\")\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"models/lptm/#tips-and-best-practices","title":"Tips and Best Practices","text":""},{"location":"models/lptm/#1-choose-appropriate-forecast-horizons","title":"1. Choose Appropriate Forecast Horizons","text":"<ul> <li>Short-term: 24-96 steps</li> <li>Medium-term: 192-336 steps</li> <li>Long-term: 720+ steps</li> </ul>"},{"location":"models/lptm/#2-fine-tuning-strategy","title":"2. Fine-Tuning Strategy","text":"<ul> <li>Start with frozen encoder and embedder</li> <li>Only train the forecasting head</li> <li>If results are unsatisfactory, gradually unfreeze layers</li> </ul>"},{"location":"models/lptm/#3-batch-size","title":"3. Batch Size","text":"<ul> <li>Larger batch sizes (32-64) for stable training</li> <li>Smaller batch sizes (8-16) if GPU memory is limited</li> </ul>"},{"location":"models/lptm/#4-data-preprocessing","title":"4. Data Preprocessing","text":"<ul> <li>LPTM handles normalization internally</li> <li>Ensure datetime column is properly formatted</li> <li>Handle missing values before loading</li> </ul>"},{"location":"models/lptm/#common-issues","title":"Common Issues","text":""},{"location":"models/lptm/#out-of-memory","title":"Out of Memory","text":"<p>Reduce batch size or forecast horizon: <pre><code>config = {\n    \"forecast_horizon\": 96,  # Instead of 192\n}\n\ndataset = LPTMDataset(\n    batchsize=8,  # Instead of 16\n    # ...\n)\n</code></pre></p>"},{"location":"models/lptm/#poor-performance","title":"Poor Performance","text":"<p>Try full fine-tuning: <pre><code>config = {\n    \"freeze_encoder\": False,\n    \"freeze_embedder\": False,\n    \"freeze_head\": False,\n    \"head_dropout\": 0.1,\n    \"weight_decay\": 0.001,\n}\n</code></pre></p>"},{"location":"models/lptm/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see:</p> <ul> <li>LPTMModel API</li> <li>LPTMDataset API</li> </ul>"},{"location":"models/lptm/#examples","title":"Examples","text":"<p>See the Examples page for complete working examples.</p>"},{"location":"models/moirai/","title":"MOIRAI: Universal Time Series Forecasting Transformer","text":"Unified Training of Universal Time Series Forecasting Transformers by Salesforce"},{"location":"models/moirai/#overview","title":"Overview","text":"<p>MOIRAI is a universal time-series forecasting transformer developed by Salesforce Research. It's trained on a massive collection of diverse time-series data and supports various frequencies, context lengths, and prediction horizons out-of-the-box.</p>"},{"location":"models/moirai/#paper","title":"Paper","text":"<p>Unified Training of Universal Time Series Forecasting Transformers</p>"},{"location":"models/moirai/#key-features","title":"Key Features","text":"<ul> <li>\u2705 Universal architecture for diverse datasets</li> <li>\u2705 Multiple frequency support (hourly, daily, weekly, monthly, etc.)</li> <li>\u2705 Flexible context and horizon lengths</li> <li>\u2705 Mixture-of-Experts (MoE) variants</li> <li>\u2705 Strong zero-shot performance across domains</li> </ul>"},{"location":"models/moirai/#model-variants","title":"Model Variants","text":"<p>MOIRAI comes in several variants:</p> Model Size Type Repository MOIRAI Small ~12M Standard <code>Salesforce/moirai-1.0-R-small</code> MOIRAI Base ~91M Standard <code>Salesforce/moirai-1.0-R-base</code> MOIRAI Large ~311M Standard <code>Salesforce/moirai-1.0-R-large</code> MOIRAI-MoE Small ~39M MoE <code>Salesforce/moirai-moe-1.0-R-small</code> MOIRAI-MoE Base ~311M MoE <code>Salesforce/moirai-moe-1.0-R-base</code>"},{"location":"models/moirai/#quick-start","title":"Quick Start","text":"<pre><code>from samay.model import MoiraiTSModel\nfrom samay.dataset import MoiraiDataset\n\n# Model configuration\nrepo = \"Salesforce/moirai-1.0-R-small\"\nconfig = {\n    \"context_len\": 128,\n    \"horizon_len\": 64,\n    \"model_type\": \"moirai\",\n    \"model_size\": \"small\",\n}\n\n# Load model\nmoirai_model = MoiraiTSModel(repo=repo, config=config)\n\n# Load dataset\ntrain_dataset = MoiraiDataset(\n    name=\"ett\",\n    mode=\"train\",\n    path=\"data/ETTh1.csv\",\n    datetime_col=\"date\",\n    freq=\"h\",\n    context_len=config['context_len'],\n    horizon_len=config['horizon_len']\n)\n\ntest_dataset = MoiraiDataset(\n    name=\"ett\",\n    mode=\"test\",\n    path=\"data/ETTh1.csv\",\n    datetime_col=\"date\",\n    freq=\"h\",\n    context_len=config['context_len'],\n    horizon_len=config['horizon_len']\n)\n\n# Zero-shot evaluation\neval_results, trues, preds, histories = moirai_model.evaluate(\n    test_dataset,\n    metrics=[\"MSE\", \"MAE\", \"MASE\"]\n)\nprint(f\"Results: {eval_results}\")\n</code></pre>"},{"location":"models/moirai/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"models/moirai/#model-configuration","title":"Model Configuration","text":"Parameter Type Default Description <code>context_len</code> int <code>128</code> Length of historical context <code>horizon_len</code> int <code>64</code> Forecast horizon <code>model_type</code> str <code>\"moirai\"</code> Model type: <code>\"moirai\"</code> or <code>\"moirai-moe\"</code> <code>model_size</code> str <code>\"small\"</code> Model size: <code>\"small\"</code>, <code>\"base\"</code>, <code>\"large\"</code> <code>patch_size</code> int <code>16</code> Patch size for patching <code>num_layers</code> int <code>100</code> Number of transformer layers"},{"location":"models/moirai/#example-configurations","title":"Example Configurations","text":""},{"location":"models/moirai/#small-model-fast-inference","title":"Small Model (Fast Inference)","text":"<pre><code>repo = \"Salesforce/moirai-1.0-R-small\"\nconfig = {\n    \"context_len\": 128,\n    \"horizon_len\": 64,\n    \"model_type\": \"moirai\",\n    \"model_size\": \"small\",\n}\n</code></pre>"},{"location":"models/moirai/#base-model-balanced","title":"Base Model (Balanced)","text":"<pre><code>repo = \"Salesforce/moirai-1.0-R-base\"\nconfig = {\n    \"context_len\": 256,\n    \"horizon_len\": 96,\n    \"model_type\": \"moirai\",\n    \"model_size\": \"base\",\n}\n</code></pre>"},{"location":"models/moirai/#large-model-high-accuracy","title":"Large Model (High Accuracy)","text":"<pre><code>repo = \"Salesforce/moirai-1.0-R-large\"\nconfig = {\n    \"context_len\": 512,\n    \"horizon_len\": 128,\n    \"model_type\": \"moirai\",\n    \"model_size\": \"large\",\n}\n</code></pre>"},{"location":"models/moirai/#mixture-of-experts-moe","title":"Mixture-of-Experts (MoE)","text":"<pre><code>repo = \"Salesforce/moirai-moe-1.0-R-small\"\nconfig = {\n    \"context_len\": 128,\n    \"horizon_len\": 64,\n    \"model_type\": \"moirai-moe\",\n    \"model_size\": \"small\",\n}\n</code></pre>"},{"location":"models/moirai/#dataset","title":"Dataset","text":""},{"location":"models/moirai/#moiraidataset-parameters","title":"MoiraiDataset Parameters","text":"Parameter Type Default Description <code>name</code> str <code>None</code> Dataset name <code>datetime_col</code> str <code>\"date\"</code> Name of datetime column <code>path</code> str Required Path to CSV file <code>mode</code> str <code>\"train\"</code> <code>\"train\"</code>, <code>\"val\"</code>, or <code>\"test\"</code> <code>context_len</code> int <code>128</code> Length of input context <code>horizon_len</code> int <code>32</code> Forecast horizon <code>freq</code> str <code>None</code> Time frequency: <code>\"h\"</code>, <code>\"d\"</code>, <code>\"w\"</code>, <code>\"m\"</code>, <code>\"q\"</code>, <code>\"y\"</code> <code>batch_size</code> int <code>16</code> Batch size <code>normalize</code> bool <code>True</code> Whether to normalize data <code>boundaries</code> tuple <code>(0, 0, 0)</code> Custom split boundaries <code>start_date</code> str <code>None</code> Start date for subset <code>end_date</code> str <code>None</code> End date for subset"},{"location":"models/moirai/#data-format","title":"Data Format","text":"<p>CSV file with datetime and value columns:</p> <pre><code>date,HUFL,HULL,MUFL,MULL,LUFL,LULL,OT\n2016-07-01 00:00:00,5.827,2.009,1.599,0.462,5.677,2.009,6.082\n2016-07-01 01:00:00,5.693,2.076,1.492,0.426,5.485,1.942,5.947\n...\n</code></pre>"},{"location":"models/moirai/#frequency-support","title":"Frequency Support","text":"<p>MOIRAI natively supports multiple time frequencies:</p>"},{"location":"models/moirai/#hourly-data","title":"Hourly Data","text":"<pre><code>dataset = MoiraiDataset(\n    path=\"data/hourly.csv\",\n    datetime_col=\"date\",\n    freq=\"h\",  # Hourly\n    # ...\n)\n</code></pre>"},{"location":"models/moirai/#daily-data","title":"Daily Data","text":"<pre><code>dataset = MoiraiDataset(\n    path=\"data/daily.csv\",\n    datetime_col=\"date\",\n    freq=\"d\",  # Daily\n    # ...\n)\n</code></pre>"},{"location":"models/moirai/#weekly-data","title":"Weekly Data","text":"<pre><code>dataset = MoiraiDataset(\n    path=\"data/weekly.csv\",\n    datetime_col=\"date\",\n    freq=\"w\",  # Weekly\n    # ...\n)\n</code></pre>"},{"location":"models/moirai/#monthly-data","title":"Monthly Data","text":"<pre><code>dataset = MoiraiDataset(\n    path=\"data/monthly.csv\",\n    datetime_col=\"date\",\n    freq=\"m\",  # Monthly\n    # ...\n)\n</code></pre>"},{"location":"models/moirai/#quarterly-data","title":"Quarterly Data","text":"<pre><code>dataset = MoiraiDataset(\n    path=\"data/quarterly.csv\",\n    datetime_col=\"date\",\n    freq=\"q\",  # Quarterly\n    # ...\n)\n</code></pre>"},{"location":"models/moirai/#yearly-data","title":"Yearly Data","text":"<pre><code>dataset = MoiraiDataset(\n    path=\"data/yearly.csv\",\n    datetime_col=\"date\",\n    freq=\"y\",  # Yearly\n    # ...\n)\n</code></pre>"},{"location":"models/moirai/#zero-shot-forecasting","title":"Zero-Shot Forecasting","text":"<p>MOIRAI is designed for zero-shot forecasting across different domains:</p> <pre><code>from samay.model import MoiraiTSModel\nfrom samay.dataset import MoiraiDataset\n\n# Load model\nrepo = \"Salesforce/moirai-1.0-R-small\"\nconfig = {\n    \"context_len\": 128,\n    \"horizon_len\": 64,\n    \"model_type\": \"moirai\",\n    \"model_size\": \"small\",\n}\n\nmoirai_model = MoiraiTSModel(repo=repo, config=config)\n\n# Test on different domain (no training!)\ntest_dataset = MoiraiDataset(\n    name=\"new_domain\",\n    mode=\"test\",\n    path=\"data/new_domain.csv\",\n    datetime_col=\"timestamp\",\n    freq=\"h\",\n    context_len=128,\n    horizon_len=64\n)\n\n# Zero-shot evaluation\neval_results, trues, preds, histories = moirai_model.evaluate(\n    test_dataset,\n    metrics=[\"MSE\", \"MAE\"]\n)\n</code></pre>"},{"location":"models/moirai/#evaluation-metrics","title":"Evaluation Metrics","text":"<p>MOIRAI supports multiple evaluation metrics:</p> <pre><code># Evaluate with multiple metrics\neval_results, trues, preds, histories = moirai_model.evaluate(\n    test_dataset,\n    metrics=[\"MSE\", \"MAE\", \"MASE\", \"MAPE\", \"RMSE\"]\n)\n\nprint(\"Evaluation Results:\")\nfor metric, value in eval_results.items():\n    print(f\"  {metric}: {value:.4f}\")\n</code></pre>"},{"location":"models/moirai/#available-metrics","title":"Available Metrics","text":"<ul> <li>MSE: Mean Squared Error</li> <li>MAE: Mean Absolute Error</li> <li>MASE: Mean Absolute Scaled Error</li> <li>MAPE: Mean Absolute Percentage Error</li> <li>RMSE: Root Mean Squared Error</li> <li>sMAPE: Symmetric Mean Absolute Percentage Error</li> </ul>"},{"location":"models/moirai/#training-and-fine-tuning","title":"Training and Fine-Tuning","text":"<p>While MOIRAI is designed for zero-shot forecasting, you can fine-tune it:</p> <pre><code># Load model\nrepo = \"Salesforce/moirai-1.0-R-small\"\nconfig = {\n    \"context_len\": 128,\n    \"horizon_len\": 64,\n    \"model_type\": \"moirai\",\n    \"model_size\": \"small\",\n}\n\nmoirai_model = MoiraiTSModel(repo=repo, config=config)\n\n# Load training data\ntrain_dataset = MoiraiDataset(\n    name=\"ett\",\n    mode=\"train\",\n    path=\"data/ETTh1.csv\",\n    datetime_col=\"date\",\n    freq=\"h\",\n    context_len=128,\n    horizon_len=64\n)\n\n# Fine-tune\nfinetuned_model = moirai_model.finetune(\n    train_dataset,\n    epochs=10,\n    learning_rate=1e-5\n)\n\n# Evaluate\ntest_dataset = MoiraiDataset(\n    name=\"ett\",\n    mode=\"test\",\n    path=\"data/ETTh1.csv\",\n    datetime_col=\"date\",\n    freq=\"h\",\n    context_len=128,\n    horizon_len=64\n)\n\neval_results, trues, preds, histories = moirai_model.evaluate(test_dataset)\n</code></pre>"},{"location":"models/moirai/#normalization","title":"Normalization","text":"<p>MOIRAI includes built-in normalization:</p> <pre><code># With normalization (default)\ndataset = MoiraiDataset(\n    path=\"data/ETTh1.csv\",\n    datetime_col=\"date\",\n    freq=\"h\",\n    normalize=True,  # Normalize data\n    context_len=128,\n    horizon_len=64\n)\n\n# Denormalize predictions\neval_results, trues, preds, histories = moirai_model.evaluate(dataset)\ndenormalized_preds = dataset._denormalize_data(preds)\ndenormalized_trues = dataset._denormalize_data(trues)\n</code></pre>"},{"location":"models/moirai/#handling-multivariate-data","title":"Handling Multivariate Data","text":"<p>MOIRAI naturally handles multivariate time series:</p> <pre><code># Your CSV with multiple columns\ndataset = MoiraiDataset(\n    path=\"data/multivariate.csv\",\n    datetime_col=\"date\",\n    freq=\"h\",\n    context_len=128,\n    horizon_len=64\n)\n\n# Model will forecast each channel independently\neval_results, trues, preds, histories = moirai_model.evaluate(dataset)\n\n# Results shape: (num_windows, num_channels, horizon_len)\n</code></pre>"},{"location":"models/moirai/#data-subsetting","title":"Data Subsetting","text":"<p>Select specific date ranges:</p> <pre><code>dataset = MoiraiDataset(\n    path=\"data/ETTh1.csv\",\n    datetime_col=\"date\",\n    freq=\"h\",\n    start_date=\"2016-07-01\",  # Start from this date\n    end_date=\"2017-12-31\",    # End at this date\n    context_len=128,\n    horizon_len=64\n)\n</code></pre>"},{"location":"models/moirai/#visualization","title":"Visualization","text":""},{"location":"models/moirai/#single-channel-forecast","title":"Single Channel Forecast","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\neval_results, trues, preds, histories = moirai_model.evaluate(test_dataset)\n\ntrues = np.array(trues)\npreds = np.array(preds)\nhistories = np.array(histories)\n\n# Plot first channel, first window\nchannel_idx = 0\nwindow_idx = 0\n\nhistory = histories[window_idx, channel_idx, :]\ntrue = trues[window_idx, channel_idx, :]\npred = preds[window_idx, channel_idx, :]\n\nplt.figure(figsize=(14, 5))\nplt.plot(range(len(history)), history, label=\"History\", linewidth=2)\nplt.plot(\n    range(len(history), len(history) + len(true)),\n    true,\n    label=\"Ground Truth\",\n    linestyle=\"--\",\n    linewidth=2\n)\nplt.plot(\n    range(len(history), len(history) + len(pred)),\n    pred,\n    label=\"MOIRAI Prediction\",\n    linewidth=2\n)\nplt.axvline(x=len(history), color='gray', linestyle=':', alpha=0.5)\nplt.legend()\nplt.title(\"MOIRAI Time Series Forecasting\")\nplt.xlabel(\"Time Step\")\nplt.ylabel(\"Value\")\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"models/moirai/#multiple-channels","title":"Multiple Channels","text":"<pre><code>fig, axes = plt.subplots(2, 2, figsize=(16, 10))\naxes = axes.flatten()\n\nfor i in range(min(4, trues.shape[1])):\n    ax = axes[i]\n\n    history = histories[0, i, :]\n    true = trues[0, i, :]\n    pred = preds[0, i, :]\n\n    ax.plot(range(len(history)), history, label=\"History\", alpha=0.7)\n    ax.plot(\n        range(len(history), len(history) + len(true)),\n        true,\n        label=\"Ground Truth\",\n        linestyle=\"--\"\n    )\n    ax.plot(\n        range(len(history), len(history) + len(pred)),\n        pred,\n        label=\"Prediction\"\n    )\n    ax.set_title(f\"Channel {i}\")\n    ax.legend()\n    ax.grid(alpha=0.3)\n\nplt.suptitle(\"MOIRAI Multi-Channel Forecasting\")\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"models/moirai/#advanced-usage","title":"Advanced Usage","text":""},{"location":"models/moirai/#custom-boundaries","title":"Custom Boundaries","text":"<pre><code># Specify exact train/val/test split points\ndataset = MoiraiDataset(\n    path=\"data/ETTh1.csv\",\n    datetime_col=\"date\",\n    freq=\"h\",\n    boundaries=(0, 10000, 15000),  # Train: 0-10k, Val: 10k-15k, Test: 15k-end\n    context_len=128,\n    horizon_len=64\n)\n</code></pre>"},{"location":"models/moirai/#different-context-lengths","title":"Different Context Lengths","text":"<pre><code># Short context\nconfig = {\n    \"context_len\": 64,\n    \"horizon_len\": 32,\n    # ...\n}\n\n# Long context\nconfig = {\n    \"context_len\": 512,\n    \"horizon_len\": 256,\n    # ...\n}\n</code></pre>"},{"location":"models/moirai/#mixture-of-experts-models","title":"Mixture-of-Experts Models","text":"<pre><code># Use MoE variant for better performance\nrepo = \"Salesforce/moirai-moe-1.0-R-small\"\nconfig = {\n    \"context_len\": 128,\n    \"horizon_len\": 64,\n    \"model_type\": \"moirai-moe\",  # MoE type\n    \"model_size\": \"small\",\n}\n\nmoirai_moe_model = MoiraiTSModel(repo=repo, config=config)\n</code></pre>"},{"location":"models/moirai/#tips-and-best-practices","title":"Tips and Best Practices","text":""},{"location":"models/moirai/#1-model-selection","title":"1. Model Selection","text":"<ul> <li>Use Small for fast inference and experimentation</li> <li>Use Base for balanced performance</li> <li>Use Large for highest accuracy</li> <li>Use MoE variants for best performance at similar compute</li> </ul>"},{"location":"models/moirai/#2-context-length","title":"2. Context Length","text":"<ul> <li>Match context length to your data's pattern length</li> <li>Longer context captures more patterns but is slower</li> <li>Start with 128-256 and adjust based on results</li> </ul>"},{"location":"models/moirai/#3-frequency-specification","title":"3. Frequency Specification","text":"<ul> <li>Always specify the correct frequency (<code>freq</code> parameter)</li> <li>Correct frequency helps MOIRAI understand temporal patterns</li> <li>MOIRAI can auto-detect frequency but explicit is better</li> </ul>"},{"location":"models/moirai/#4-normalization","title":"4. Normalization","text":"<ul> <li>Keep normalization enabled (default) for best results</li> <li>Remember to denormalize predictions for interpretation</li> </ul>"},{"location":"models/moirai/#common-issues","title":"Common Issues","text":""},{"location":"models/moirai/#cuda-out-of-memory","title":"CUDA Out of Memory","text":"<pre><code># Use smaller model\nrepo = \"Salesforce/moirai-1.0-R-small\"\n\n# Reduce batch size\ndataset = MoiraiDataset(\n    batch_size=8,  # Instead of 16\n    # ...\n)\n\n# Reduce context/horizon length\nconfig = {\n    \"context_len\": 64,  # Instead of 128\n    \"horizon_len\": 32,  # Instead of 64\n}\n</code></pre>"},{"location":"models/moirai/#incorrect-frequency","title":"Incorrect Frequency","text":"<p>Make sure frequency matches your data: <pre><code># Check your data's datetime column\nimport pandas as pd\ndf = pd.read_csv(\"data.csv\")\ndf['date'] = pd.to_datetime(df['date'])\ninferred_freq = pd.infer_freq(df['date'])\nprint(f\"Inferred frequency: {inferred_freq}\")\n\n# Use correct frequency\ndataset = MoiraiDataset(\n    freq=inferred_freq,  # Use inferred frequency\n    # ...\n)\n</code></pre></p>"},{"location":"models/moirai/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see:</p> <ul> <li>MoiraiTSModel API</li> <li>MoiraiDataset API</li> </ul>"},{"location":"models/moirai/#examples","title":"Examples","text":"<p>See the Examples page for complete working examples.</p>"},{"location":"models/moment/","title":"MOMENT: A Family of Open Time-Series Foundation Models","text":"Multi-Task Time-Series Foundation Model"},{"location":"models/moment/#overview","title":"Overview","text":"<p>MOMENT is a family of open-source time-series foundation models designed to handle multiple tasks including forecasting, classification, anomaly detection, and imputation. It uses a masked autoencoder architecture with a focus on versatility across different time-series domains.</p>"},{"location":"models/moment/#paper","title":"Paper","text":"<p>MOMENT: A Family of Open Time-series Foundation Models</p>"},{"location":"models/moment/#key-features","title":"Key Features","text":"<ul> <li>\u2705 Multi-task learning (forecasting, classification, detection, imputation)</li> <li>\u2705 Masked autoencoder architecture</li> <li>\u2705 Pre-trained on diverse time-series datasets</li> <li>\u2705 Flexible fine-tuning strategies</li> <li>\u2705 Open-source and community-driven</li> </ul>"},{"location":"models/moment/#quick-start","title":"Quick Start","text":""},{"location":"models/moment/#forecasting","title":"Forecasting","text":"<pre><code>from samay.model import MomentModel\nfrom samay.dataset import MomentDataset\n\n# Model configuration\nconfig = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\n# Load model\nmodel = MomentModel(config)\n\n# Load dataset\ntrain_dataset = MomentDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon_len=192,\n    task_name=\"forecasting\",\n)\n\n# Fine-tune\nfinetuned_model = model.finetune(train_dataset)\n\n# Evaluate\ntest_dataset = MomentDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    horizon_len=192,\n    task_name=\"forecasting\",\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n</code></pre>"},{"location":"models/moment/#supported-tasks","title":"Supported Tasks","text":"<p>MOMENT supports four main tasks:</p>"},{"location":"models/moment/#1-forecasting","title":"1. Forecasting","text":"<p>Predict future time-series values:</p> <pre><code>config = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\nmodel = MomentModel(config)\n\ndataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon_len=192,\n    task_name=\"forecasting\",\n)\n</code></pre>"},{"location":"models/moment/#2-classification","title":"2. Classification","text":"<p>Classify time-series sequences:</p> <pre><code>config = {\n    \"task_name\": \"classification\",\n    \"num_classes\": 5,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\nmodel = MomentModel(config)\n\ndataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/classification_data.csv\",\n    mode=\"train\",\n    task_name=\"classification\",\n    label_col=\"label\",\n)\n</code></pre>"},{"location":"models/moment/#3-anomaly-detection","title":"3. Anomaly Detection","text":"<p>Detect anomalies in time series:</p> <pre><code>config = {\n    \"task_name\": \"detection\",\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\nmodel = MomentModel(config)\n\ndataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ecg_data.csv\",\n    mode=\"train\",\n    task_name=\"detection\",\n)\n</code></pre>"},{"location":"models/moment/#4-imputation","title":"4. Imputation","text":"<p>Fill missing values:</p> <pre><code>config = {\n    \"task_name\": \"imputation\",\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": False,  # May need to train encoder\n    \"freeze_head\": False,\n}\n\nmodel = MomentModel(config)\n\ndataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/incomplete_data.csv\",\n    mode=\"train\",\n    task_name=\"imputation\",\n)\n</code></pre>"},{"location":"models/moment/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"models/moment/#model-configuration","title":"Model Configuration","text":"Parameter Type Default Description <code>task_name</code> str <code>\"forecasting\"</code> Task: <code>\"forecasting\"</code>, <code>\"classification\"</code>, <code>\"detection\"</code>, <code>\"imputation\"</code> <code>forecast_horizon</code> int <code>192</code> Horizon length for forecasting <code>num_classes</code> int <code>None</code> Number of classes for classification <code>freeze_encoder</code> bool <code>True</code> Whether to freeze the encoder <code>freeze_embedder</code> bool <code>True</code> Whether to freeze the embedder <code>freeze_head</code> bool <code>False</code> Whether to freeze the task head <code>dropout</code> float <code>0.1</code> Dropout rate <code>learning_rate</code> float <code>1e-4</code> Learning rate for fine-tuning"},{"location":"models/moment/#dataset","title":"Dataset","text":""},{"location":"models/moment/#momentdataset-parameters","title":"MomentDataset Parameters","text":"Parameter Type Default Description <code>name</code> str <code>None</code> Dataset name <code>datetime_col</code> str <code>None</code> Name of datetime column <code>path</code> str Required Path to CSV file <code>mode</code> str <code>\"train\"</code> <code>\"train\"</code> or <code>\"test\"</code> <code>horizon_len</code> int <code>0</code> Forecast horizon <code>task_name</code> str <code>\"forecasting\"</code> Task type <code>label_col</code> str <code>\"label\"</code> Label column for classification <code>batchsize</code> int <code>64</code> Batch size <code>boundaries</code> list <code>[0, 0, 0]</code> Custom split boundaries <code>stride</code> int <code>10</code> Stride for sliding window"},{"location":"models/moment/#data-format","title":"Data Format","text":""},{"location":"models/moment/#forecastingimputation","title":"Forecasting/Imputation","text":"<pre><code>date,HUFL,HULL,MUFL,MULL,LUFL,LULL,OT\n2016-07-01 00:00:00,5.827,2.009,1.599,0.462,5.677,2.009,6.082\n2016-07-01 01:00:00,5.693,2.076,1.492,0.426,5.485,1.942,5.947\n...\n</code></pre>"},{"location":"models/moment/#classification","title":"Classification","text":"<pre><code>date,feature1,feature2,feature3,label\n2016-07-01 00:00:00,5.827,2.009,1.599,0\n2016-07-01 01:00:00,5.693,2.076,1.492,1\n...\n</code></pre>"},{"location":"models/moment/#anomaly-detection","title":"Anomaly Detection","text":"<pre><code>date,value,anomaly\n2016-07-01 00:00:00,5.827,0\n2016-07-01 01:00:00,5.693,0\n2016-07-01 02:00:00,12.456,1\n...\n</code></pre>"},{"location":"models/moment/#training","title":"Training","text":""},{"location":"models/moment/#forecasting_1","title":"Forecasting","text":"<pre><code>from samay.model import MomentModel\nfrom samay.dataset import MomentDataset\n\nconfig = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\nmodel = MomentModel(config)\n\ntrain_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon_len=192,\n    task_name=\"forecasting\",\n    batchsize=64,\n)\n\n# Fine-tune\nfinetuned_model = model.finetune(train_dataset, epochs=10)\n</code></pre>"},{"location":"models/moment/#classification_1","title":"Classification","text":"<pre><code>config = {\n    \"task_name\": \"classification\",\n    \"num_classes\": 5,\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\nmodel = MomentModel(config)\n\ntrain_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ecg_classification.csv\",\n    mode=\"train\",\n    task_name=\"classification\",\n    label_col=\"label\",\n    batchsize=32,\n)\n\nfinetuned_model = model.finetune(train_dataset, epochs=20)\n</code></pre>"},{"location":"models/moment/#anomaly-detection_1","title":"Anomaly Detection","text":"<pre><code>config = {\n    \"task_name\": \"detection\",\n    \"freeze_encoder\": True,\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\nmodel = MomentModel(config)\n\ntrain_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ecg_anomaly.csv\",\n    mode=\"train\",\n    task_name=\"detection\",\n    batchsize=32,\n)\n\nfinetuned_model = model.finetune(train_dataset, epochs=15)\n</code></pre>"},{"location":"models/moment/#evaluation","title":"Evaluation","text":""},{"location":"models/moment/#forecasting-evaluation","title":"Forecasting Evaluation","text":"<pre><code>test_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    horizon_len=192,\n    task_name=\"forecasting\",\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\n# Calculate metrics\nfrom samay.metric import mse, mae\nimport numpy as np\n\ntrues = np.array(trues)\npreds = np.array(preds)\n\nprint(f\"MSE: {mse(trues, preds):.4f}\")\nprint(f\"MAE: {mae(trues, preds):.4f}\")\n</code></pre>"},{"location":"models/moment/#classification-evaluation","title":"Classification Evaluation","text":"<pre><code>test_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ecg_classification.csv\",\n    mode=\"test\",\n    task_name=\"classification\",\n    label_col=\"label\",\n)\n\navg_loss, labels, predictions, _ = model.evaluate(test_dataset)\n\n# Calculate accuracy\nfrom sklearn.metrics import accuracy_score, f1_score\n\naccuracy = accuracy_score(labels, predictions)\nf1 = f1_score(labels, predictions, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n</code></pre>"},{"location":"models/moment/#anomaly-detection-evaluation","title":"Anomaly Detection Evaluation","text":"<pre><code>test_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ecg_anomaly.csv\",\n    mode=\"test\",\n    task_name=\"detection\",\n)\n\navg_loss, true_labels, anomaly_scores, _ = model.evaluate(test_dataset)\n\n# Calculate ROC-AUC\nfrom sklearn.metrics import roc_auc_score\n\nauc = roc_auc_score(true_labels, anomaly_scores)\nprint(f\"ROC-AUC: {auc:.4f}\")\n</code></pre>"},{"location":"models/moment/#advanced-usage","title":"Advanced Usage","text":""},{"location":"models/moment/#multi-task-transfer-learning","title":"Multi-Task Transfer Learning","text":"<p>Train on one task, fine-tune on another:</p> <pre><code># First, train on forecasting\nconfig_forecast = {\n    \"task_name\": \"forecasting\",\n    \"forecast_horizon\": 192,\n    \"freeze_encoder\": False,\n    \"freeze_embedder\": False,\n    \"freeze_head\": False,\n}\n\nmodel = MomentModel(config_forecast)\nforecast_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    horizon_len=192,\n    task_name=\"forecasting\",\n)\n\nmodel.finetune(forecast_dataset, epochs=10)\n\n# Now switch to classification\nconfig_class = {\n    \"task_name\": \"classification\",\n    \"num_classes\": 5,\n    \"freeze_encoder\": True,  # Freeze what we learned\n    \"freeze_embedder\": True,\n    \"freeze_head\": False,\n}\n\n# Update model config\nmodel.update_config(config_class)\n\nclass_dataset = MomentDataset(\n    datetime_col=\"date\",\n    path=\"./data/classification.csv\",\n    mode=\"train\",\n    task_name=\"classification\",\n    label_col=\"label\",\n)\n\nmodel.finetune(class_dataset, epochs=5)\n</code></pre>"},{"location":"models/moment/#custom-training-loop","title":"Custom Training Loop","text":"<pre><code>import torch\nfrom torch.optim import AdamW\n\nmodel = MomentModel(config)\ntrain_loader = train_dataset.get_data_loader()\n\noptimizer = AdamW(model.parameters(), lr=1e-4)\ncriterion = torch.nn.MSELoss()\n\nfor epoch in range(10):\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n\n        # Unpack batch based on task\n        if config[\"task_name\"] == \"forecasting\":\n            timeseries, input_mask, forecast = batch\n            predictions = model(timeseries, input_mask)\n            loss = criterion(predictions, forecast)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch}: Loss = {total_loss / len(train_loader):.4f}\")\n</code></pre>"},{"location":"models/moment/#visualization","title":"Visualization","text":""},{"location":"models/moment/#forecasting-results","title":"Forecasting Results","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\ntrues = np.array(trues)\npreds = np.array(preds)\nhistories = np.array(histories)\n\n# Plot multiple channels\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\naxes = axes.flatten()\n\nfor i in range(min(4, trues.shape[1])):\n    ax = axes[i]\n\n    history = histories[0, i, :]\n    true = trues[0, i, :]\n    pred = preds[0, i, :]\n\n    ax.plot(range(len(history)), history, label=\"History\", alpha=0.7)\n    ax.plot(\n        range(len(history), len(history) + len(true)),\n        true,\n        label=\"Ground Truth\",\n        linestyle=\"--\"\n    )\n    ax.plot(\n        range(len(history), len(history) + len(pred)),\n        pred,\n        label=\"Prediction\"\n    )\n    ax.set_title(f\"Channel {i}\")\n    ax.legend()\n    ax.grid(alpha=0.3)\n\nplt.suptitle(\"MOMENT Multi-Channel Forecasting\")\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"models/moment/#anomaly-detection-results","title":"Anomaly Detection Results","text":"<pre><code>import matplotlib.pyplot as plt\n\n# Get anomaly scores\navg_loss, true_labels, anomaly_scores, sequences = model.evaluate(test_dataset)\n\nplt.figure(figsize=(14, 6))\n\n# Plot time series\nplt.subplot(2, 1, 1)\nplt.plot(sequences[0], label=\"Time Series\")\nplt.scatter(\n    np.where(true_labels[0] == 1)[0],\n    sequences[0][true_labels[0] == 1],\n    color='red',\n    label='True Anomalies',\n    s=100\n)\nplt.legend()\nplt.title(\"Time Series with Anomalies\")\n\n# Plot anomaly scores\nplt.subplot(2, 1, 2)\nplt.plot(anomaly_scores[0], label=\"Anomaly Score\")\nplt.axhline(y=np.percentile(anomaly_scores[0], 95), color='r', linestyle='--', label='Threshold (95%)')\nplt.legend()\nplt.title(\"Anomaly Scores\")\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"models/moment/#tips-and-best-practices","title":"Tips and Best Practices","text":""},{"location":"models/moment/#1-task-selection","title":"1. Task Selection","text":"<ul> <li>Use forecasting for predicting future values</li> <li>Use classification for categorizing sequences</li> <li>Use detection for identifying anomalies</li> <li>Use imputation for filling missing data</li> </ul>"},{"location":"models/moment/#2-fine-tuning-strategy","title":"2. Fine-Tuning Strategy","text":"<ul> <li>Start with frozen encoder and embedder</li> <li>Gradually unfreeze if performance is poor</li> <li>Use higher learning rates for task heads</li> </ul>"},{"location":"models/moment/#3-sequence-length","title":"3. Sequence Length","text":"<ul> <li>MOMENT uses fixed sequence length of 512</li> <li>Longer sequences capture more context</li> <li>Shorter sequences are faster</li> </ul>"},{"location":"models/moment/#4-multi-task-learning","title":"4. Multi-Task Learning","text":"<ul> <li>Pre-train on related tasks</li> <li>Fine-tune on target task</li> <li>Freeze learned features when switching tasks</li> </ul>"},{"location":"models/moment/#common-issues","title":"Common Issues","text":""},{"location":"models/moment/#poor-classification-performance","title":"Poor Classification Performance","text":"<p>Try unfreezing more layers: <pre><code>config = {\n    \"task_name\": \"classification\",\n    \"num_classes\": 5,\n    \"freeze_encoder\": False,  # Unfreeze encoder\n    \"freeze_embedder\": False, # Unfreeze embedder\n    \"freeze_head\": False,\n}\n</code></pre></p>"},{"location":"models/moment/#high-memory-usage","title":"High Memory Usage","text":"<p>Reduce batch size: <pre><code>dataset = MomentDataset(\n    # ...\n    batchsize=16,  # Instead of 64\n)\n</code></pre></p>"},{"location":"models/moment/#missing-values","title":"Missing Values","text":"<p>MOMENT handles missing values through imputation: <pre><code>config = {\n    \"task_name\": \"imputation\",\n    # ...\n}\n</code></pre></p>"},{"location":"models/moment/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see:</p> <ul> <li>MomentModel API</li> <li>MomentDataset API</li> </ul>"},{"location":"models/moment/#examples","title":"Examples","text":"<p>See the Examples page for complete working examples of all tasks.</p>"},{"location":"models/timesfm/","title":"TimesFM: Time Series Foundation Model","text":"A Decoder-Only Foundation Model for Time-Series Forecasting by Google Research"},{"location":"models/timesfm/#overview","title":"Overview","text":"<p>TimesFM (Time Series Foundation Model) is a decoder-only  architecture developed by Google Research for time-series forecasting. It's designed for efficient zero-shot forecasting across diverse domains.</p>"},{"location":"models/timesfm/#paper","title":"Paper","text":"<p>A decoder-only foundation model for time-series forecasting</p>"},{"location":"models/timesfm/#key-features","title":"Key Features","text":"<ul> <li>\u2705 Decoder-only transformer architecture</li> <li>\u2705 Efficient zero-shot forecasting</li> <li>\u2705 Patch-based input processing</li> <li>\u2705 Multiple quantile predictions</li> <li>\u2705 Fast inference on GPU</li> </ul>"},{"location":"models/timesfm/#quick-start","title":"Quick Start","text":"<pre><code>from samay.model import TimesfmModel\nfrom samay.dataset import TimesfmDataset\n\n# Model configuration\nrepo = \"google/timesfm-1.0-200m-pytorch\"\nconfig = {\n    \"context_len\": 512,\n    \"horizon_len\": 192,\n    \"backend\": \"gpu\",\n    \"per_core_batch_size\": 32,\n    \"input_patch_len\": 32,\n    \"output_patch_len\": 128,\n    \"num_layers\": 20,\n    \"model_dims\": 1280,\n    \"quantiles\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n}\n\n# Load model\ntfm = TimesfmModel(config=config, repo=repo)\n\n# Load dataset\ntrain_dataset = TimesfmDataset(\n    name=\"ett\",\n    datetime_col='date',\n    path='data/ETTh1.csv',\n    mode='train',\n    context_len=config[\"context_len\"],\n    horizon_len=config[\"horizon_len\"]\n)\n\n# Evaluate (zero-shot)\navg_loss, trues, preds, histories = tfm.evaluate(train_dataset)\nprint(f\"Average Loss: {avg_loss}\")\n</code></pre>"},{"location":"models/timesfm/#model-variants","title":"Model Variants","text":"<p>TimesFM comes in multiple sizes:</p> Model Parameters Repository TimesFM 1.0 (200M) 200M <code>google/timesfm-1.0-200m-pytorch</code> TimesFM 2.0 (500M) 500M <code>google/timesfm-2.0-500m-pytorch</code>"},{"location":"models/timesfm/#choosing-a-model","title":"Choosing a Model","text":"<pre><code># Smaller, faster model\nrepo = \"google/timesfm-1.0-200m-pytorch\"\n\n# Larger, more accurate model\nrepo = \"google/timesfm-2.0-500m-pytorch\"\n</code></pre>"},{"location":"models/timesfm/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"models/timesfm/#model-configuration","title":"Model Configuration","text":"Parameter Type Default Description <code>context_len</code> int <code>512</code> Length of historical context <code>horizon_len</code> int <code>192</code> Forecast horizon <code>backend</code> str <code>\"gpu\"</code> Backend: <code>\"gpu\"</code> or <code>\"cpu\"</code> <code>per_core_batch_size</code> int <code>32</code> Batch size per core <code>input_patch_len</code> int <code>32</code> Length of input patches <code>output_patch_len</code> int <code>128</code> Length of output patches <code>num_layers</code> int <code>20</code> Number of transformer layers <code>model_dims</code> int <code>1280</code> Model dimension <code>quantiles</code> list <code>[0.1, ..., 0.9]</code> Quantiles for prediction intervals"},{"location":"models/timesfm/#example-configurations","title":"Example Configurations","text":""},{"location":"models/timesfm/#standard-configuration-200m-model","title":"Standard Configuration (200M Model)","text":"<pre><code>config = {\n    \"context_len\": 512,\n    \"horizon_len\": 192,\n    \"backend\": \"gpu\",\n    \"per_core_batch_size\": 32,\n    \"input_patch_len\": 32,\n    \"output_patch_len\": 128,\n    \"num_layers\": 20,\n    \"model_dims\": 1280,\n    \"quantiles\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n}\n</code></pre>"},{"location":"models/timesfm/#larger-model-500m","title":"Larger Model (500M)","text":"<pre><code>config = {\n    \"context_len\": 512,\n    \"horizon_len\": 192,\n    \"backend\": \"gpu\",\n    \"per_core_batch_size\": 32,\n    \"input_patch_len\": 32,\n    \"output_patch_len\": 128,\n    \"num_layers\": 50,  # More layers\n    \"model_dims\": 1280,\n    \"quantiles\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n}\n</code></pre>"},{"location":"models/timesfm/#cpu-inference","title":"CPU Inference","text":"<pre><code>config = {\n    \"context_len\": 512,\n    \"horizon_len\": 96,\n    \"backend\": \"cpu\",  # Use CPU\n    \"per_core_batch_size\": 8,  # Smaller batch\n    # ... other configs\n}\n</code></pre>"},{"location":"models/timesfm/#dataset","title":"Dataset","text":""},{"location":"models/timesfm/#timesfmdataset-parameters","title":"TimesfmDataset Parameters","text":"Parameter Type Default Description <code>name</code> str <code>None</code> Dataset name <code>datetime_col</code> str <code>\"ds\"</code> Name of datetime column <code>path</code> str Required Path to CSV file <code>mode</code> str <code>\"train\"</code> <code>\"train\"</code> or <code>\"test\"</code> <code>context_len</code> int <code>128</code> Length of input context <code>horizon_len</code> int <code>32</code> Forecast horizon <code>freq</code> str <code>\"h\"</code> Frequency: <code>\"h\"</code>, <code>\"d\"</code>, <code>\"w\"</code>, etc. <code>normalize</code> bool <code>False</code> Whether to normalize data <code>stride</code> int <code>10</code> Stride for sliding window <code>batchsize</code> int <code>4</code> Batch size"},{"location":"models/timesfm/#data-format","title":"Data Format","text":"<p>CSV file with datetime and value columns:</p> <pre><code>date,HUFL,HULL,MUFL,MULL,LUFL,LULL,OT\n2016-07-01 00:00:00,5.827,2.009,1.599,0.462,5.677,2.009,6.082\n2016-07-01 01:00:00,5.693,2.076,1.492,0.426,5.485,1.942,5.947\n...\n</code></pre>"},{"location":"models/timesfm/#zero-shot-forecasting","title":"Zero-Shot Forecasting","text":"<p>TimesFM excels at zero-shot forecasting:</p> <pre><code>from samay.model import TimesfmModel\nfrom samay.dataset import TimesfmDataset\n\n# Load model\nrepo = \"google/timesfm-1.0-200m-pytorch\"\nconfig = {\n    \"context_len\": 512,\n    \"horizon_len\": 192,\n    \"backend\": \"gpu\",\n    \"per_core_batch_size\": 32,\n    \"input_patch_len\": 32,\n    \"output_patch_len\": 128,\n    \"num_layers\": 20,\n    \"model_dims\": 1280,\n    \"quantiles\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n}\ntfm = TimesfmModel(config=config, repo=repo)\n\n# Load test data\ntest_dataset = TimesfmDataset(\n    name=\"ett\",\n    datetime_col='date',\n    path='data/ETTh1.csv',\n    mode='test',\n    context_len=config[\"context_len\"],\n    horizon_len=config[\"horizon_len\"]\n)\n\n# Zero-shot evaluation (no training!)\navg_loss, trues, preds, histories = tfm.evaluate(test_dataset)\nprint(f\"Zero-shot Loss: {avg_loss}\")\n</code></pre>"},{"location":"models/timesfm/#evaluation","title":"Evaluation","text":""},{"location":"models/timesfm/#basic-evaluation","title":"Basic Evaluation","text":"<pre><code>test_dataset = TimesfmDataset(\n    name=\"ett\",\n    datetime_col='date',\n    path='data/ETTh1.csv',\n    mode='test',\n    context_len=512,\n    horizon_len=192\n)\n\navg_loss, trues, preds, histories = tfm.evaluate(test_dataset)\n</code></pre>"},{"location":"models/timesfm/#with-custom-metrics","title":"With Custom Metrics","text":"<pre><code>from samay.metric import mse, mae, mape\nimport numpy as np\n\navg_loss, trues, preds, histories = tfm.evaluate(test_dataset)\n\ntrues = np.array(trues)\npreds = np.array(preds)\n\nprint(f\"MSE: {mse(trues, preds):.4f}\")\nprint(f\"MAE: {mae(trues, preds):.4f}\")\nprint(f\"MAPE: {mape(trues, preds):.4f}\")\n</code></pre>"},{"location":"models/timesfm/#quantile-predictions","title":"Quantile Predictions","text":"<p>TimesFM provides prediction intervals via quantiles:</p> <pre><code>config = {\n    # ... other configs\n    \"quantiles\": [0.1, 0.25, 0.5, 0.75, 0.9],  # 10%, 25%, median, 75%, 90%\n}\n\ntfm = TimesfmModel(config=config, repo=repo)\n\n# The model will output predictions for each quantile\navg_loss, trues, preds, histories = tfm.evaluate(test_dataset)\n\n# preds shape: (num_samples, num_channels, horizon_len, num_quantiles)\n</code></pre>"},{"location":"models/timesfm/#visualizing-prediction-intervals","title":"Visualizing Prediction Intervals","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Assuming preds has shape (num_samples, num_channels, horizon_len, num_quantiles)\nmedian_idx = 2  # Index of 0.5 quantile\nlower_idx = 0   # Index of 0.1 quantile\nupper_idx = 4   # Index of 0.9 quantile\n\nsample_idx = 0\nchannel_idx = 0\n\nhistory = histories[sample_idx, channel_idx, :]\ntrue = trues[sample_idx, channel_idx, :]\n\n# Assuming the model returns median predictions\npred_median = preds[sample_idx, channel_idx, :]\n\nplt.figure(figsize=(14, 5))\nplt.plot(range(len(history)), history, label=\"History\", linewidth=2)\nplt.plot(\n    range(len(history), len(history) + len(true)),\n    true,\n    label=\"Ground Truth\",\n    linestyle=\"--\",\n    linewidth=2\n)\nplt.plot(\n    range(len(history), len(history) + len(pred_median)),\n    pred_median,\n    label=\"Prediction (Median)\",\n    linewidth=2\n)\nplt.legend()\nplt.title(\"TimesFM Forecasting with Prediction Intervals\")\nplt.grid(alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"models/timesfm/#handling-different-frequencies","title":"Handling Different Frequencies","text":"<p>TimesFM supports various time frequencies:</p> <pre><code># Hourly data\ndataset = TimesfmDataset(\n    datetime_col='date',\n    path='data/hourly.csv',\n    freq='h',\n    # ...\n)\n\n# Daily data\ndataset = TimesfmDataset(\n    datetime_col='date',\n    path='data/daily.csv',\n    freq='d',\n    # ...\n)\n\n# Weekly data\ndataset = TimesfmDataset(\n    datetime_col='date',\n    path='data/weekly.csv',\n    freq='w',\n    # ...\n)\n\n# Monthly data\ndataset = TimesfmDataset(\n    datetime_col='date',\n    path='data/monthly.csv',\n    freq='m',\n    # ...\n)\n</code></pre>"},{"location":"models/timesfm/#normalization","title":"Normalization","text":"<p>TimesFM can optionally normalize data:</p> <pre><code># With normalization\ntrain_dataset = TimesfmDataset(\n    name=\"ett\",\n    datetime_col='date',\n    path='data/ETTh1.csv',\n    mode='train',\n    context_len=512,\n    horizon_len=192,\n    normalize=True,  # Enable normalization\n)\n\n# Denormalize predictions\navg_loss, trues, preds, histories = tfm.evaluate(train_dataset)\ndenormalized_preds = train_dataset._denormalize_data(preds)\n</code></pre>"},{"location":"models/timesfm/#advanced-usage","title":"Advanced Usage","text":""},{"location":"models/timesfm/#custom-context-lengths","title":"Custom Context Lengths","text":"<pre><code># Short context for fast inference\nconfig = {\n    \"context_len\": 128,\n    \"horizon_len\": 64,\n    # ...\n}\n\n# Long context for better accuracy\nconfig = {\n    \"context_len\": 1024,\n    \"horizon_len\": 256,\n    # ...\n}\n</code></pre>"},{"location":"models/timesfm/#batch-processing","title":"Batch Processing","text":"<pre><code># Larger batches for throughput\nconfig = {\n    \"per_core_batch_size\": 64,\n    # ...\n}\n\n# Smaller batches for memory efficiency\nconfig = {\n    \"per_core_batch_size\": 8,\n    # ...\n}\n</code></pre>"},{"location":"models/timesfm/#visualization","title":"Visualization","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\navg_loss, trues, preds, histories = tfm.evaluate(test_dataset)\n\ntrues = np.array(trues)\npreds = np.array(preds)\nhistories = np.array(histories)\n\n# Plot multiple channels\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\naxes = axes.flatten()\n\nfor i in range(4):\n    ax = axes[i]\n\n    history = histories[0, i, :]\n    true = trues[0, i, :]\n    pred = preds[0, i, :]\n\n    ax.plot(range(len(history)), history, label=\"History\", alpha=0.7)\n    ax.plot(\n        range(len(history), len(history) + len(true)),\n        true,\n        label=\"Ground Truth\",\n        linestyle=\"--\"\n    )\n    ax.plot(\n        range(len(history), len(history) + len(pred)),\n        pred,\n        label=\"Prediction\"\n    )\n    ax.set_title(f\"Channel {i}\")\n    ax.legend()\n    ax.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"models/timesfm/#tips-and-best-practices","title":"Tips and Best Practices","text":""},{"location":"models/timesfm/#1-model-selection","title":"1. Model Selection","text":"<ul> <li>Use 200M model for faster inference</li> <li>Use 500M model for higher accuracy</li> </ul>"},{"location":"models/timesfm/#2-context-length","title":"2. Context Length","text":"<ul> <li>Longer context (512-1024) for complex patterns</li> <li>Shorter context (128-256) for simpler patterns and speed</li> </ul>"},{"location":"models/timesfm/#3-zero-shot-vs-fine-tuning","title":"3. Zero-Shot vs Fine-Tuning","text":"<ul> <li>TimesFM is designed for zero-shot forecasting</li> <li>Fine-tuning is not typically required</li> </ul>"},{"location":"models/timesfm/#4-gpu-memory","title":"4. GPU Memory","text":"<ul> <li>Reduce <code>per_core_batch_size</code> if OOM</li> <li>Use CPU backend for very limited memory</li> </ul>"},{"location":"models/timesfm/#common-issues","title":"Common Issues","text":""},{"location":"models/timesfm/#cuda-out-of-memory","title":"CUDA Out of Memory","text":"<pre><code># Reduce batch size\nconfig = {\n    \"per_core_batch_size\": 8,  # Lower value\n    # ...\n}\n\n# Or use CPU\nconfig = {\n    \"backend\": \"cpu\",\n    # ...\n}\n</code></pre>"},{"location":"models/timesfm/#slow-inference","title":"Slow Inference","text":"<pre><code># Use smaller model\nrepo = \"google/timesfm-1.0-200m-pytorch\"\n\n# Reduce context length\nconfig = {\n    \"context_len\": 256,  # Instead of 512\n    # ...\n}\n</code></pre>"},{"location":"models/timesfm/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see:</p> <ul> <li>TimesfmModel API</li> <li>TimesfmDataset API</li> </ul>"},{"location":"models/timesfm/#examples","title":"Examples","text":"<p>See the Examples page for complete working examples.</p>"},{"location":"models/ttm/","title":"TinyTimeMixer: Fast Pre-trained Models for Time Series","text":"Lightweight and Efficient Time-Series Foundation Model"},{"location":"models/ttm/#overview","title":"Overview","text":"<p>TinyTimeMixer (TTM) is a compact and efficient time-series forecasting model designed for fast inference and low memory footprint. It uses a mixer-based architecture that balances performance with computational efficiency, making it ideal for resource-constrained environments.</p>"},{"location":"models/ttm/#paper","title":"Paper","text":"<p>TinyTimeMixer: Fast Pre-trained Models for Time Series</p>"},{"location":"models/ttm/#key-features","title":"Key Features","text":"<ul> <li>\u2705 Lightweight architecture (compact model size)</li> <li>\u2705 Fast inference speed</li> <li>\u2705 Low memory footprint</li> <li>\u2705 Competitive forecasting accuracy</li> <li>\u2705 Efficient training and fine-tuning</li> <li>\u2705 Multivariate time-series support</li> </ul>"},{"location":"models/ttm/#quick-start","title":"Quick Start","text":"<pre><code>from samay.model import TinyTimeMixerModel\nfrom samay.dataset import TinyTimeMixerDataset\n\n# Model configuration\nconfig = {\n    \"context_len\": 512,\n    \"horizon_len\": 96,\n    \"model_size\": \"tiny\",\n}\n\n# Load model\nmodel = TinyTimeMixerModel(config)\n\n# Load dataset\ntrain_dataset = TinyTimeMixerDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    context_len=config[\"context_len\"],\n    horizon_len=config[\"horizon_len\"],\n)\n\n# Fine-tune\nfinetuned_model = model.finetune(train_dataset, epochs=10)\n\n# Evaluate\ntest_dataset = TinyTimeMixerDataset(\n    name=\"ett\",\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    context_len=config[\"context_len\"],\n    horizon_len=config[\"horizon_len\"],\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\nprint(f\"Average Loss: {avg_loss}\")\n</code></pre>"},{"location":"models/ttm/#model-variants","title":"Model Variants","text":"<p>TinyTimeMixer comes in different sizes:</p> Variant Parameters Speed Accuracy Tiny ~1M Fastest Good Small ~5M Fast Better Base ~15M Moderate Best"},{"location":"models/ttm/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"models/ttm/#model-configuration","title":"Model Configuration","text":"Parameter Type Default Description <code>context_len</code> int <code>512</code> Length of input context <code>horizon_len</code> int <code>96</code> Forecast horizon <code>model_size</code> str <code>\"tiny\"</code> Model size: <code>\"tiny\"</code>, <code>\"small\"</code>, <code>\"base\"</code> <code>d_model</code> int <code>64</code> Model dimension <code>n_heads</code> int <code>4</code> Number of attention heads <code>n_layers</code> int <code>4</code> Number of mixer layers <code>dropout</code> float <code>0.1</code> Dropout rate"},{"location":"models/ttm/#example-configurations","title":"Example Configurations","text":""},{"location":"models/ttm/#tiny-model-fast-inference","title":"Tiny Model (Fast Inference)","text":"<pre><code>config = {\n    \"context_len\": 512,\n    \"horizon_len\": 96,\n    \"model_size\": \"tiny\",\n    \"d_model\": 64,\n    \"n_layers\": 4,\n}\n</code></pre>"},{"location":"models/ttm/#small-model-balanced","title":"Small Model (Balanced)","text":"<pre><code>config = {\n    \"context_len\": 512,\n    \"horizon_len\": 96,\n    \"model_size\": \"small\",\n    \"d_model\": 128,\n    \"n_layers\": 6,\n}\n</code></pre>"},{"location":"models/ttm/#base-model-high-accuracy","title":"Base Model (High Accuracy)","text":"<pre><code>config = {\n    \"context_len\": 512,\n    \"horizon_len\": 192,\n    \"model_size\": \"base\",\n    \"d_model\": 256,\n    \"n_layers\": 8,\n}\n</code></pre>"},{"location":"models/ttm/#dataset","title":"Dataset","text":""},{"location":"models/ttm/#tinytimemixerdataset-parameters","title":"TinyTimeMixerDataset Parameters","text":"Parameter Type Default Description <code>name</code> str <code>None</code> Dataset name <code>datetime_col</code> str <code>\"ds\"</code> Name of datetime column <code>path</code> str Required Path to CSV file <code>mode</code> str <code>None</code> <code>\"train\"</code> or <code>\"test\"</code> <code>context_len</code> int <code>512</code> Length of input context <code>horizon_len</code> int <code>64</code> Forecast horizon <code>batch_size</code> int <code>128</code> Batch size <code>boundaries</code> list <code>[0, 0, 0]</code> Custom split boundaries <code>stride</code> int <code>10</code> Stride for sliding window"},{"location":"models/ttm/#data-format","title":"Data Format","text":"<p>CSV file with datetime and value columns:</p> <pre><code>date,HUFL,HULL,MUFL,MULL,LUFL,LULL,OT\n2016-07-01 00:00:00,5.827,2.009,1.599,0.462,5.677,2.009,6.082\n2016-07-01 01:00:00,5.693,2.076,1.492,0.426,5.485,1.942,5.947\n...\n</code></pre>"},{"location":"models/ttm/#training","title":"Training","text":""},{"location":"models/ttm/#basic-training","title":"Basic Training","text":"<pre><code>from samay.model import TinyTimeMixerModel\nfrom samay.dataset import TinyTimeMixerDataset\n\n# Configure model\nconfig = {\n    \"context_len\": 512,\n    \"horizon_len\": 96,\n    \"model_size\": \"tiny\",\n}\n\nmodel = TinyTimeMixerModel(config)\n\n# Load training data\ntrain_dataset = TinyTimeMixerDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    context_len=512,\n    horizon_len=96,\n    batch_size=128,\n)\n\n# Fine-tune\nfinetuned_model = model.finetune(\n    train_dataset,\n    epochs=20,\n    learning_rate=1e-3,\n)\n</code></pre>"},{"location":"models/ttm/#training-with-validation","title":"Training with Validation","text":"<pre><code># Training dataset\ntrain_dataset = TinyTimeMixerDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"train\",\n    context_len=512,\n    horizon_len=96,\n    boundaries=[0, 10000, 15000],  # Custom split\n)\n\n# Validation dataset\nval_dataset = TinyTimeMixerDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"val\",\n    context_len=512,\n    horizon_len=96,\n    boundaries=[0, 10000, 15000],\n)\n\n# Fine-tune with validation\nfinetuned_model = model.finetune(\n    train_dataset,\n    val_dataset=val_dataset,\n    epochs=20,\n    learning_rate=1e-3,\n)\n</code></pre>"},{"location":"models/ttm/#evaluation","title":"Evaluation","text":""},{"location":"models/ttm/#basic-evaluation","title":"Basic Evaluation","text":"<pre><code>test_dataset = TinyTimeMixerDataset(\n    datetime_col=\"date\",\n    path=\"./data/ETTh1.csv\",\n    mode=\"test\",\n    context_len=512,\n    horizon_len=96,\n)\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\nprint(f\"Average Test Loss: {avg_loss}\")\n</code></pre>"},{"location":"models/ttm/#with-custom-metrics","title":"With Custom Metrics","text":"<pre><code>from samay.metric import mse, mae, mape, rmse\nimport numpy as np\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\ntrues = np.array(trues)\npreds = np.array(preds)\n\nprint(f\"MSE:  {mse(trues, preds):.4f}\")\nprint(f\"MAE:  {mae(trues, preds):.4f}\")\nprint(f\"RMSE: {rmse(trues, preds):.4f}\")\nprint(f\"MAPE: {mape(trues, preds):.4f}%\")\n</code></pre>"},{"location":"models/ttm/#zero-shot-forecasting","title":"Zero-Shot Forecasting","text":"<p>TinyTimeMixer supports zero-shot forecasting:</p> <pre><code># Load pre-trained model\nconfig = {\n    \"context_len\": 512,\n    \"horizon_len\": 96,\n    \"model_size\": \"tiny\",\n}\n\nmodel = TinyTimeMixerModel(config)\n\n# Test on new data without training\ntest_dataset = TinyTimeMixerDataset(\n    datetime_col=\"date\",\n    path=\"./data/new_domain.csv\",\n    mode=\"test\",\n    context_len=512,\n    horizon_len=96,\n)\n\n# Zero-shot evaluation\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n</code></pre>"},{"location":"models/ttm/#multivariate-forecasting","title":"Multivariate Forecasting","text":"<p>TinyTimeMixer handles multivariate data efficiently:</p> <pre><code># Your CSV with multiple value columns\ndataset = TinyTimeMixerDataset(\n    datetime_col=\"date\",\n    path=\"./data/multivariate.csv\",  # Multiple columns\n    mode=\"train\",\n    context_len=512,\n    horizon_len=96,\n)\n\n# Model forecasts all channels simultaneously\navg_loss, trues, preds, histories = model.evaluate(dataset)\n\n# Results shape: (num_windows, num_channels, horizon_len)\nprint(f\"Predictions shape: {preds.shape}\")\n</code></pre>"},{"location":"models/ttm/#advanced-usage","title":"Advanced Usage","text":""},{"location":"models/ttm/#custom-context-lengths","title":"Custom Context Lengths","text":"<pre><code># Short context for simple patterns\nconfig = {\n    \"context_len\": 256,\n    \"horizon_len\": 64,\n    \"model_size\": \"tiny\",\n}\n\n# Long context for complex patterns\nconfig = {\n    \"context_len\": 1024,\n    \"horizon_len\": 192,\n    \"model_size\": \"small\",\n}\n</code></pre>"},{"location":"models/ttm/#batch-size-tuning","title":"Batch Size Tuning","text":"<pre><code># Large batch for faster training (if memory allows)\ndataset = TinyTimeMixerDataset(\n    # ...\n    batch_size=256,\n)\n\n# Small batch for memory efficiency\ndataset = TinyTimeMixerDataset(\n    # ...\n    batch_size=32,\n)\n</code></pre>"},{"location":"models/ttm/#stride-configuration","title":"Stride Configuration","text":"<pre><code># Smaller stride for more training samples\ndataset = TinyTimeMixerDataset(\n    # ...\n    stride=1,  # Overlapping windows\n)\n\n# Larger stride for faster iteration\ndataset = TinyTimeMixerDataset(\n    # ...\n    stride=96,  # Non-overlapping windows\n)\n</code></pre>"},{"location":"models/ttm/#visualization","title":"Visualization","text":""},{"location":"models/ttm/#single-channel-forecast","title":"Single Channel Forecast","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\ntrues = np.array(trues)\npreds = np.array(preds)\nhistories = np.array(histories)\n\n# Plot first window, first channel\nwindow_idx = 0\nchannel_idx = 0\n\nhistory = histories[window_idx, channel_idx, :]\ntrue = trues[window_idx, channel_idx, :]\npred = preds[window_idx, channel_idx, :]\n\nplt.figure(figsize=(14, 5))\nplt.plot(range(len(history)), history, label=\"History (512 steps)\", linewidth=2)\nplt.plot(\n    range(len(history), len(history) + len(true)),\n    true,\n    label=\"Ground Truth (96 steps)\",\n    linestyle=\"--\",\n    linewidth=2\n)\nplt.plot(\n    range(len(history), len(history) + len(pred)),\n    pred,\n    label=\"TinyTimeMixer Prediction\",\n    linewidth=2\n)\nplt.axvline(x=len(history), color='gray', linestyle=':', alpha=0.5)\nplt.legend()\nplt.title(\"TinyTimeMixer Time Series Forecasting\")\nplt.xlabel(\"Time Step\")\nplt.ylabel(\"Value\")\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"models/ttm/#multiple-channels","title":"Multiple Channels","text":"<pre><code>fig, axes = plt.subplots(2, 2, figsize=(16, 10))\naxes = axes.flatten()\n\nfor i in range(min(4, trues.shape[1])):\n    ax = axes[i]\n\n    history = histories[0, i, :]\n    true = trues[0, i, :]\n    pred = preds[0, i, :]\n\n    ax.plot(range(len(history)), history, label=\"History\", alpha=0.7)\n    ax.plot(\n        range(len(history), len(history) + len(true)),\n        true,\n        label=\"Ground Truth\",\n        linestyle=\"--\"\n    )\n    ax.plot(\n        range(len(history), len(history) + len(pred)),\n        pred,\n        label=\"Prediction\"\n    )\n    ax.set_title(f\"Channel {i}\")\n    ax.legend()\n    ax.grid(alpha=0.3)\n\nplt.suptitle(\"TinyTimeMixer Multi-Channel Forecasting\")\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"models/ttm/#error-distribution","title":"Error Distribution","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n\ntrues = np.array(trues)\npreds = np.array(preds)\n\n# Calculate errors\nerrors = trues - preds\n\nplt.figure(figsize=(12, 5))\n\n# Error distribution\nplt.subplot(1, 2, 1)\nplt.hist(errors.flatten(), bins=50, alpha=0.7, edgecolor='black')\nplt.xlabel(\"Prediction Error\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Error Distribution\")\nplt.grid(alpha=0.3)\n\n# Error over time\nplt.subplot(1, 2, 2)\nmean_abs_errors = np.mean(np.abs(errors), axis=(0, 1))\nplt.plot(mean_abs_errors)\nplt.xlabel(\"Time Step\")\nplt.ylabel(\"Mean Absolute Error\")\nplt.title(\"Error Over Forecast Horizon\")\nplt.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"models/ttm/#performance-comparison","title":"Performance Comparison","text":""},{"location":"models/ttm/#speed-benchmark","title":"Speed Benchmark","text":"<pre><code>import time\n\nmodels = [\n    (\"Tiny\", {\"model_size\": \"tiny\", \"d_model\": 64}),\n    (\"Small\", {\"model_size\": \"small\", \"d_model\": 128}),\n    (\"Base\", {\"model_size\": \"base\", \"d_model\": 256}),\n]\n\nfor name, model_config in models:\n    config = {\n        \"context_len\": 512,\n        \"horizon_len\": 96,\n        **model_config\n    }\n\n    model = TinyTimeMixerModel(config)\n\n    # Measure inference time\n    start_time = time.time()\n    avg_loss, trues, preds, histories = model.evaluate(test_dataset)\n    elapsed_time = time.time() - start_time\n\n    print(f\"{name} Model:\")\n    print(f\"  Loss: {avg_loss:.4f}\")\n    print(f\"  Time: {elapsed_time:.2f}s\")\n    print()\n</code></pre>"},{"location":"models/ttm/#tips-and-best-practices","title":"Tips and Best Practices","text":""},{"location":"models/ttm/#1-model-selection","title":"1. Model Selection","text":"<ul> <li>Use Tiny for edge devices and real-time applications</li> <li>Use Small for balanced performance and speed</li> <li>Use Base when accuracy is more important than speed</li> </ul>"},{"location":"models/ttm/#2-context-length","title":"2. Context Length","text":"<ul> <li>Longer context captures more patterns but is slower</li> <li>Match context to your data's seasonal patterns</li> <li>Start with 512 and adjust based on results</li> </ul>"},{"location":"models/ttm/#3-batch-size","title":"3. Batch Size","text":"<ul> <li>TinyTimeMixer supports large batch sizes (128-256)</li> <li>Larger batches = faster training</li> <li>Reduce batch size if OOM errors occur</li> </ul>"},{"location":"models/ttm/#4-training-duration","title":"4. Training Duration","text":"<ul> <li>TinyTimeMixer trains quickly (10-20 epochs often sufficient)</li> <li>Monitor validation loss to avoid overfitting</li> <li>Early stopping is recommended</li> </ul>"},{"location":"models/ttm/#common-issues","title":"Common Issues","text":""},{"location":"models/ttm/#cuda-out-of-memory","title":"CUDA Out of Memory","text":"<pre><code># Use smaller model\nconfig = {\n    \"model_size\": \"tiny\",\n    \"d_model\": 64,\n    # ...\n}\n\n# Reduce batch size\ndataset = TinyTimeMixerDataset(\n    batch_size=32,  # Instead of 128\n    # ...\n)\n\n# Reduce context/horizon\nconfig = {\n    \"context_len\": 256,  # Instead of 512\n    \"horizon_len\": 48,   # Instead of 96\n}\n</code></pre>"},{"location":"models/ttm/#slow-training","title":"Slow Training","text":"<pre><code># Increase batch size (if memory allows)\ndataset = TinyTimeMixerDataset(\n    batch_size=256,  # Larger batch\n    # ...\n)\n\n# Reduce model size\nconfig = {\n    \"model_size\": \"tiny\",  # Smaller model\n    # ...\n}\n</code></pre>"},{"location":"models/ttm/#poor-accuracy","title":"Poor Accuracy","text":"<pre><code># Use larger model\nconfig = {\n    \"model_size\": \"base\",  # Larger model\n    \"d_model\": 256,\n    \"n_layers\": 8,\n}\n\n# Increase context length\nconfig = {\n    \"context_len\": 1024,  # More context\n    # ...\n}\n\n# Train longer\nmodel.finetune(train_dataset, epochs=50)  # More epochs\n</code></pre>"},{"location":"models/ttm/#efficient-deployment","title":"Efficient Deployment","text":""},{"location":"models/ttm/#cpu-inference","title":"CPU Inference","text":"<p>TinyTimeMixer is efficient on CPU:</p> <pre><code>import torch\n\n# Force CPU usage\ndevice = torch.device(\"cpu\")\nmodel = TinyTimeMixerModel(config).to(device)\n\n# Inference is still fast!\navg_loss, trues, preds, histories = model.evaluate(test_dataset)\n</code></pre>"},{"location":"models/ttm/#model-export","title":"Model Export","text":"<p>Export for production deployment:</p> <pre><code># Save model\nmodel.save(\"tinytimemixer_model.pt\")\n\n# Load model\nloaded_model = TinyTimeMixerModel.load(\"tinytimemixer_model.pt\")\n</code></pre>"},{"location":"models/ttm/#quantization-for-even-faster-inference","title":"Quantization (for even faster inference)","text":"<pre><code>import torch\n\n# Quantize model for faster inference\nquantized_model = torch.quantization.quantize_dynamic(\n    model,\n    {torch.nn.Linear},\n    dtype=torch.qint8\n)\n\n# Use quantized model\navg_loss, trues, preds, histories = quantized_model.evaluate(test_dataset)\n</code></pre>"},{"location":"models/ttm/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see:</p> <ul> <li>TinyTimeMixerModel API</li> <li>TinyTimeMixerDataset API</li> </ul>"},{"location":"models/ttm/#examples","title":"Examples","text":"<p>See the Examples page for complete working examples.</p>"},{"location":"models/ttm/#comparison-with-other-models","title":"Comparison with Other Models","text":"Feature TinyTimeMixer LPTM TimesFM MOMENT Speed \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 Memory \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 \u2b50\u2b50 \u2b50\u2b50\u2b50 Accuracy \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 Edge Deployment \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50 \u2b50\u2b50 \u2b50\u2b50\u2b50 <p>Use TinyTimeMixer when: - You need fast inference - Memory is limited - Deploying on edge devices - Real-time forecasting is required</p>"}]}